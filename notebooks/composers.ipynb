{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f2073a-9cd9-4948-b75d-6f5e92b038ce",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188fe140-c5a1-415e-910c-fa294de68935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.data.composers.chained_composer import ChainedComposer\n",
    "from pipeline.data.composers.blocks.file_filtering import *\n",
    "from pipeline.data.composers.blocks.file_preprocessing import *\n",
    "from pipeline.data.composers.blocks.file_chunking import *\n",
    "from pipeline.data.composers.blocks.chunk_ranking import *\n",
    "from pipeline.data.composers.blocks.chunk_sorting import *\n",
    "from pipeline.data.composers.blocks.chunk_harvesting import *\n",
    "from pipeline.data.composers.blocks.context_postprocessing import *\n",
    "\n",
    "import os\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba2af19-a0bb-4e15-b392-94824b7ffee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_sample = {\n",
    "    'repo': 'composers',\n",
    "    'commit_hash': 'lalala',\n",
    "    'completion_file': {\n",
    "        'filename': ...,\n",
    "        'content': ...,\n",
    "    },\n",
    "    'completion_lines': {\n",
    "        'infile': [1, 2, 3],\n",
    "        'inproject': [4, 5, 6],\n",
    "        'common': [7, 8, 9],\n",
    "        'commited': [10, 11, 12],\n",
    "        'non_informative': [13, 14, 15],\n",
    "        'random': [16, 17, 18],\n",
    "    },\n",
    "    'repo_snapshot': {\n",
    "        'filename': [],\n",
    "        'content': [],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b449dcba-b869-4ec1-ad25-53275d3c60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2pipeline = '../pipeline'\n",
    "path2configs = '../configs'\n",
    "\n",
    "for directory, _, filenames in chain(os.walk(path2pipeline), os.walk(path2configs)):\n",
    "    if '__pycache__' in directory:\n",
    "        continue\n",
    "    \n",
    "    for filename in filenames:\n",
    "        filename = os.path.join(directory, filename)\n",
    "        \n",
    "        with open(filename) as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        toy_sample['repo_snapshot']['filename'].append(filename)\n",
    "        toy_sample['repo_snapshot']['content'].append(content)\n",
    "        \n",
    "toy_sample['completion_file']['filename'] = toy_sample['repo_snapshot']['filename'].pop(0)\n",
    "toy_sample['completion_file']['content'] = toy_sample['repo_snapshot']['content'].pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a5f1055-a5ac-469a-8051-3e4a6cf97fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer_kwargs = dict(\n",
    "    pre_context_prompt=\"# {}\\n\",\n",
    "    post_context_prompt=\"\\n\\n\",\n",
    "    path_comment_template=\"# {filename}\\n{content}\",  # to format completion file\n",
    "    recalculate_random_category=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c7a08-6377-49b3-a7d3-67d3ba787f39",
   "metadata": {},
   "source": [
    "### Classical Path Distance Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18feca98-7725-4c2f-bb84-509c3344fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ChainedComposer([\n",
    "    FileGrainedChunker(),\n",
    "    NegativePathDistanceRanker(),\n",
    "    LexicographicSorter(),\n",
    "    PathCommentHarvester(chunks_sep='\\n\\n', path_comment_template='# {filename}\\n{content}'),\n",
    "],\n",
    "    **composer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e220d366-9340-498e-a137-4055e0cb175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ChainedComposer([FileGrainedChunker(), NegativePathDistanceRanker(), LexicographicSorter(), PathCommentHarvester(chunks_sep='\\n\\n', path_comment_template='# {filename}\\n{content}')], pre_context_prompt='# {}\\n', post_context_prompt='\\n\\n', path_comment_template='# {filename}\\n{content}', recalculate_random_category=False)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can access the composer initialization code by using its __repr__\n",
    "repr(composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56277c49-ce81-4bb3-8943-e159a5e0829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pre_context_prompt', 'composed_context', 'composed_completion', 'completion_lines'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "composed_sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4043a4b1-e1f5-453b-aa1e-e7cb687b8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# composers\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repo identifier\n",
    "composed_sample['pre_context_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55be451f-5eeb-4017-873a-67fb9defbec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'infile': [2, 3, 4],\n",
       " 'inproject': [5, 6, 7],\n",
       " 'common': [8, 9, 10],\n",
       " 'commited': [11, 12, 13],\n",
       " 'non_informative': [14, 15, 16],\n",
       " 'random': [17, 18, 19]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# completion lines are corrected w.r.t. pre_context_prompt length\n",
    "composed_sample['completion_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d01780-a375-4774-9726-717717594e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ../pipeline/__main__.py\n",
      "from pipeline.data.composers.init import init_composer\n",
      "from pipeline.data.dataset import train_test_split, set_transform\n",
      "from pipeline.data.preprocessors.init import init_preprocessor\n",
      "from pipeline.model.init import init_tokenizer_model\n",
      "from pipeline.outputs.checkpointers.init import init_checkpointer\n",
      "from pipeline.outputs.loggers.init import init_logger\n",
      "from pipeline.trainers.init import init_trainer\n",
      "\n",
      "import os\n",
      "import sys\n",
      "\n",
      "import hydra\n",
      "from datasets import load_dataset\n",
      "from hydra.core.hydra_config import HydraConfig\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "LCA_SOLVERS_DIR = os.path.dirname(os.path.dirname(__file__))\n",
      "\n",
      "# configs\n",
      "CONFIGS_DIR = os.path.join(LCA_SOLVERS_DIR, 'configs')\n",
      "MAIN_CONFIG = 'defaults'\n",
      "\n",
      "# run directory\n",
      "RUNS_DIR = os.path.join(LCA_SOLVERS_DIR, 'runs')\n",
      "ARGV_SH_FILE = 'run_script.sh'\n",
      "CHECKPOINTS_DIR = 'checkpoints'\n",
      "LOGS_DIR = 'logs'\n",
      "\n",
      "\n",
      "# TODO: unify init functions\n",
      "\n",
      "\n",
      "@hydra.main(config_path=CONFIGS_DIR, config_name=MAIN_CONFIG, version_base=None)\n",
      "def main(config: DictConfig) -> None:\n",
      "    argv_sh = ' \\\\\\n'.join([sys.executable] + sys.argv)\n",
      "\n",
      "    run_dir = os.path.join(RUNS_DIR, config.run_name)\n",
      "    argv_sh_file = os.path.join(run_dir, ARGV_SH_FILE)\n",
      "    checkpoints_dir = os.path.join(run_dir, CHECKPOINTS_DIR)\n",
      "    logs_dir = os.path.join(run_dir, LOGS_DIR)\n",
      "\n",
      "    if os.path.exists(run_dir):\n",
      "        with open(argv_sh_file) as stream:\n",
      "            old_argv_sh = stream.read()\n",
      "\n",
      "        if argv_sh != old_argv_sh:\n",
      "            input(f'Mismatch of script arguments with an older instance of the same run ({argv_sh_file}).\\n'\n",
      "                  'Press ENTER to continue with the new ones.')\n",
      "    else:\n",
      "        os.mkdir(run_dir)\n",
      "        os.mkdir(checkpoints_dir)\n",
      "        os.mkdir(logs_dir)\n",
      "\n",
      "        os.mknod(os.path.join(checkpoints_dir, '.gitkeep'))\n",
      "        os.mknod(os.path.join(logs_dir, '.gitkeep'))\n",
      "\n",
      "    with open(argv_sh_file, 'w') as stream:\n",
      "        stream.write(argv_sh)\n",
      "\n",
      "    config_choices = HydraConfig.get().runtime.choices\n",
      "    checkpointer_cls, logger_cls, composer_cls, preprocessor_cls, trainer_cls = [\n",
      "        os.path.dirname(config_choices.get(cfg_group))\n",
      "        for cfg_group in ('checkpointer', 'logger', 'composer', 'preprocessor', 'trainer')\n",
      "    ]\n",
      "\n",
      "    checkpointer = init_checkpointer(\n",
      "        cls_name=checkpointer_cls,\n",
      "        loaded_config=config.checkpointer,\n",
      "        directory=checkpoints_dir,\n",
      "    )\n",
      "\n",
      "    load_from = checkpointer.get_model_subdirectory()\n",
      "    tokenizer, model = init_tokenizer_model(config.model, load_from=load_from)\n",
      "\n",
      "    composer = init_composer(\n",
      "        cls_name=composer_cls,\n",
      "        loaded_config=config.composer,\n",
      "        configs_dir=CONFIGS_DIR,\n",
      "        tokenizer=tokenizer,\n",
      "    )\n",
      "    preprocessor = init_preprocessor(\n",
      "        cls_name=preprocessor_cls,\n",
      "        loaded_config=config.preprocessor,\n",
      "        tokenizer=tokenizer,\n",
      "    )\n",
      "\n",
      "    logger = init_logger(\n",
      "        cls_name=logger_cls,\n",
      "        loaded_config=config.logger,\n",
      "        directory=logs_dir,\n",
      "        checkpointer=checkpointer,\n",
      "        name=config.run_name,\n",
      "        config=dict(config) | {'config_choices': config_choices, 'composer_initialization_code': repr(composer)},\n",
      "    )\n",
      "    if load_from is None:\n",
      "        logger.message('The model is initialized from Hugging Face Hub.')\n",
      "    else:\n",
      "        logger.message(f'The model is initialized from {load_from}.')\n",
      "\n",
      "    dataset = load_dataset(**dict(config.dataset))\n",
      "    train_ds, valid_ds = train_test_split(dataset, **dict(config.split))\n",
      "    set_transform(train_ds, valid_ds, composer, preprocessor)\n",
      "\n",
      "    trainer = init_trainer(\n",
      "        cls_name=trainer_cls,\n",
      "        loaded_config=config.trainer,\n",
      "        model=model,\n",
      "        tokenizer=tokenizer,\n",
      "        train_ds=train_ds,\n",
      "        valid_ds=valid_ds,\n",
      "        checkpointer=checkpointer,\n",
      "        logger=logger)\n",
      "    trainer.train(verbose=True)\n",
      "\n",
      "    logger.message('Run successfully completed.')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default way to compose a completion part\n",
    "print(composed_sample['composed_completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea18b545-b4fb-4abe-b316-1108794a3fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ../configs/composer/chained_composer/blocks/file_preprocessing/empty_lines_removal_preprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_preprocessing/declaration_only_preprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_chunking/file_grained_chunker/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_chunking/code_segment_grained_chunker/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_harvesting/joining_harvester/double_newline.yaml\n",
      "chunks_sep: \"\\n\\n\"\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_harvesting/path_comment_harvester/empty.yaml\n",
      "chunks_sep: \"\\n\\n\"\n",
      "path_comment_template: '{content}'\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_harvesting/path_comment_harvester/standard.yaml\n",
      "chunks_sep: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_sorting/lexicographic_sorter/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/inverse_frequency_memory_postprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/partial_memory_postprocessor/half_memory.yaml\n",
      "dropout: 0.5\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/line_strip_postprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/line_length_postprocessor/10_200.yaml\n",
      "min_len: 10\n",
      "max_len: 200\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/file_extension_ranker/text_files.yaml\n",
      "ordered_groups: [[.json], [.yaml, .yml], [.sh], [.md, .txt, .rst]]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/negative_path_distance_ranker/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/function_call_ranker/absolute.yaml\n",
      "is_relative: False\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/function_call_ranker/relative.yaml\n",
      "is_relative: True\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/random_ranker/1337.yaml\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/file_length_filter/0_20k.yaml\n",
      "min_len: 0\n",
      "max_len: 20000\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/file_length_filter/no_effect.yaml\n",
      "min_len: 0\n",
      "max_len: !!float .inf\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/empty_file_filter/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/tokenized_file_length_filter/no_effect.yaml\n",
      "min_len: 0\n",
      "max_len: !!float .inf\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/inclusive_file_extension_filter/python_files.yaml\n",
      "whitelist: [.py]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/char_token_ratio_filter/3_6.yaml\n",
      "min_ratio: 3\n",
      "max_ratio: 6\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/char_token_ratio_filter/1p5_inf.yaml\n",
      "min_ratio: 1.5\n",
      "max_ratio: !!float .inf\n",
      "subsequence_len: 2048\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/exclusive_file_extension_filter/empty.yaml\n",
      "blacklist: []\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/completion_loss_preprocessor/full_completion_loss_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/completion_loss_preprocessor/no_import_and_license_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 0.9\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/completion_loss_preprocessor/debugging.yaml\n",
      "max_seq_len: 1024\n",
      "context_tokens: 512\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/lm_preprocessor/full_input_loss_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/file_level_preprocessor/full_completion_loss_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/high_lr.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 7.0e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 25\n",
      "lr_decay_iters: 600\n",
      "min_lr: 1.0e-7\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/more_workers.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 32\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/medium_lr.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/debugging.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 20\n",
      "valid_freq: 5\n",
      "checkpointing_freq: null\n",
      "gradient_accumulation_steps: 16\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/empty.yaml\n",
      "pre_context_prompt: ''\n",
      "post_context_prompt: ''\n",
      "path_comment_template: '{content}'\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/empty.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/no_long_files.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/file_length_filter/0_20k.yaml,\n",
      "  file_preprocessing/empty_lines_removal_preprocessor/no_args.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/standard.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/strip.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  context_postprocessing/line_strip_postprocessor/no_args.yaml,\n",
      "  context_postprocessing/line_length_postprocessor/10_200.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/most_absolute_callable.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/random_declarations.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "  file_preprocessing/declaration_only_preprocessor/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/random_ranker/1337.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/low_tokens_ratio_filtering.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/char_token_ratio_filter/1p5_inf.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/most_relative_callable.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/relative.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/func_calls_with_strip.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  context_postprocessing/line_strip_postprocessor/no_args.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/nearest_declarations.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "  file_preprocessing/declaration_only_preprocessor/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/half_memory.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  context_postprocessing/partial_memory_postprocessor/half_memory.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/grouped_text_files.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/file_extension_ranker/text_files.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/python_files.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/pure_func_calls.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/checkpointer/top_k_checkpointer/top_3.yaml\n",
      "init_from: resume\n",
      "main_metric: cross_entropy\n",
      "max_checkpoints_num: 3\n",
      "\n",
      "\n",
      "# ../configs/checkpointer/checkpointer/standard.yaml\n",
      "init_from: resume\n",
      "main_metric: cross_entropy\n",
      "\n",
      "\n",
      "# ../configs/logger/wandb/wandb.yaml\n",
      "train_csv: train.csv\n",
      "valid_csv: valid.csv\n",
      "stdout_file: stdout.json\n",
      "stderr_file: stderr.json\n",
      "project: LCA Context Composers\n",
      "\n",
      "\n",
      "# ../configs/logger/local/local.yaml\n",
      "train_csv: train.csv\n",
      "valid_csv: valid.csv\n",
      "stdout_file: stdout.json\n",
      "stderr_file: stderr.json\n",
      "\n",
      "\n",
      "# ../configs/logger/dummy/debugging.yaml\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/context_postprocessing.py\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "import random\n",
      "from abc import ABC\n",
      "from typing import Type\n",
      "\n",
      "\n",
      "class ContextPostprocessor(ComposerBlock, ABC):\n",
      "    last_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return ContextPostprocessor,\n",
      "\n",
      "\n",
      "class PartialMemoryPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self, dropout: float, random_seed: int | None) -> None:\n",
      "        if not 0 <= dropout <= 1:\n",
      "            raise ValueError('dropout must be selected from the interval [0, 1]. '\n",
      "                             f'Got {dropout} instead.')\n",
      "        self.dropout = dropout\n",
      "        self.generator = random.Random(random_seed)\n",
      "\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        # dropping of path comments can occasionally happen\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.generator.random() >= self.dropout)\n",
      "\n",
      "\n",
      "class LineLengthPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.min_len <= len(line) <= self.max_len)\n",
      "\n",
      "\n",
      "class LineStripPostprocessor(ContextPostprocessor):\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line.strip() for line in context.split('\\n'))\n",
      "\n",
      "\n",
      "class InverseFrequencyMemoryPostprocessor(ContextPostprocessor):\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        # TODO concerns:\n",
      "        # 1. L1 or softmax normalization?\n",
      "        # 2. Equivalence groups by line.strip() transformation?\n",
      "        return context\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_sorting.py\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "\n",
      "class ChunkSorter(ComposerBlock, ABC):\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "        return ChunkSorter, ChunkHarvester\n",
      "\n",
      "\n",
      "class LexicographicSorter(ChunkSorter):\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        return sorted(chunks, key=lambda c: c.rank)\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_harvesting.py\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "\n",
      "class ChunkHarvester(ComposerBlock, ABC):\n",
      "    last_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from pipeline.data.composers.blocks.context_postprocessing import ContextPostprocessor\n",
      "        return ContextPostprocessor,\n",
      "\n",
      "\n",
      "class JoiningHarvester(ChunkHarvester):\n",
      "    def __init__(self, chunks_sep: str) -> None:\n",
      "        self.chunks_sep = chunks_sep\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> str:\n",
      "        return self.chunks_sep.join(chunk.content for chunk in chunks)\n",
      "\n",
      "\n",
      "class PathCommentHarvester(JoiningHarvester):\n",
      "    def __init__(self, chunks_sep: str, path_comment_template: str) -> None:\n",
      "        super().__init__(chunks_sep)\n",
      "        self.path_comment_template = path_comment_template\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> str:\n",
      "        for chunk in chunks:\n",
      "            chunk.content = self.path_comment_template.format(\n",
      "                filename=chunk.file_ref.metadata['filename'], content=chunk.content)\n",
      "        return super().__call__(chunks, datapoint)\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_preprocessing.py\n",
      "from pipeline.data.composers.chain import File, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "import warnings\n",
      "\n",
      "\n",
      "class FilePreprocessor(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from pipeline.data.composers.blocks.file_chunking import FileChunker\n",
      "        from pipeline.data.composers.blocks.file_filtering import FileFilter\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "\n",
      "\n",
      "class EmptyLinesRemovalPreprocessor(FilePreprocessor):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        for file in files:\n",
      "            file.content = '\\n'.join(line for line in file.content.split('\\n') if line.strip())\n",
      "        return files\n",
      "\n",
      "\n",
      "class DeclarationOnlyPreprocessor(FilePreprocessor):\n",
      "    ENCODING = 'utf8'\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[File]:\n",
      "        for file in files:\n",
      "            if not file.metadata['filename'].endswith('.py'):\n",
      "                continue\n",
      "\n",
      "            bytecode = bytes(file.content, self.ENCODING)\n",
      "            queue = [self.parser.parse(bytecode).root_node]\n",
      "            declarations = list()\n",
      "\n",
      "            while queue:\n",
      "                node = queue.pop()\n",
      "                queue.extend(reversed(node.children))\n",
      "\n",
      "                if node.type not in ('function_definition', 'class_definition'):\n",
      "                    continue\n",
      "\n",
      "                start = bytecode[:node.start_byte].rfind(b'\\n') + 1\n",
      "                for child in node.children:\n",
      "                    if child.type == ':':\n",
      "                        end = child.end_byte\n",
      "                        break\n",
      "                else:\n",
      "                    warnings.warn(f'A corrupted {file.metadata[\"filename\"]} file structure '\n",
      "                                  f'has been detected in the {datapoint.repo} repository.')\n",
      "                    end = node.end_byte\n",
      "\n",
      "                declaration = bytecode[start:end]\n",
      "                declaration = declaration.decode('utf8') + ' ...'\n",
      "                declarations.append(declaration)\n",
      "\n",
      "            file.content = '\\n'.join(declarations)\n",
      "        return files\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_ranking.py\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "import os\n",
      "import random\n",
      "import warnings\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "\n",
      "\n",
      "class ChunkRanker(ComposerBlock, ABC):\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from pipeline.data.composers.blocks.chunk_sorting import ChunkSorter\n",
      "        return ChunkRanker, ChunkSorter\n",
      "\n",
      "\n",
      "class NegativePathDistanceRanker(ChunkRanker):\n",
      "    @staticmethod\n",
      "    def _path_distance(path_from: str, path_to: str) -> int:\n",
      "        path_from = os.path.normpath(path_from)\n",
      "        path_to = os.path.normpath(path_to)\n",
      "\n",
      "        if path_from == path_to:\n",
      "            warnings.warn(f'Data leakage: the {path_from} completion file is contained in the repo snapshot.')\n",
      "\n",
      "        divided_path_from = path_from.split(os.path.sep)\n",
      "        divided_path_to = path_to.split(os.path.sep)\n",
      "\n",
      "        common_len = 0\n",
      "        for segment_from, segment_to in zip(divided_path_from, divided_path_to):\n",
      "            if segment_from == segment_to:\n",
      "                common_len += 1\n",
      "            else:\n",
      "                break\n",
      "\n",
      "        num_residuals_from = len(divided_path_from) - common_len - 1\n",
      "        num_residuals_to = len(divided_path_to) - common_len - 1\n",
      "\n",
      "        return num_residuals_from + num_residuals_to\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        path_to = datapoint.completion_file['filename']\n",
      "        for chunk in chunks:\n",
      "            dist = self._path_distance(chunk.file_ref.metadata['filename'], path_to)\n",
      "            chunk.rank.append(-dist)\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class FileExtensionRanker(ChunkRanker):\n",
      "    def __init__(self, ordered_groups: list[list[str]]) -> None:\n",
      "        self.group_weights = {\n",
      "            extension: weight\n",
      "            for weight, group in enumerate(ordered_groups)\n",
      "            for extension in group\n",
      "        }\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        for chunk in chunks:\n",
      "            extension = '.' + chunk.file_ref.metadata['filename'].split('.')[-1]\n",
      "            chunk.rank.append(self.group_weights.get(extension, -1))\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class FunctionCallRanker(ChunkRanker):\n",
      "    ENCODING = 'utf8'\n",
      "\n",
      "    def __init__(self, is_relative: bool) -> None:\n",
      "        self.is_relative = is_relative\n",
      "\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "    def dfs_count(self, node: tree_sitter.Node) -> int:\n",
      "        return (node.type == 'call') + sum(self.dfs_count(child) for child in node.children)\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        for chunk in chunks:\n",
      "            if chunk.file_ref.metadata['filename'].endswith('.py'):\n",
      "                bytecode = bytes(chunk.content, self.ENCODING)\n",
      "                tree = self.parser.parse(bytecode)\n",
      "                num_calls = self.dfs_count(tree.root_node)\n",
      "            else:\n",
      "                num_calls = 0\n",
      "\n",
      "            if self.is_relative:\n",
      "                num_calls /= len(chunk.content)\n",
      "\n",
      "            chunk.rank.append(num_calls)\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class RandomRanker(ChunkRanker):\n",
      "    def __init__(self, random_seed: int | None) -> None:\n",
      "        self.generator = random.Random(random_seed)\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        ranks = list(range(len(chunks)))\n",
      "        self.generator.shuffle(ranks)\n",
      "        for rank, chunk in zip(ranks, chunks):\n",
      "            chunk.rank.append(rank)\n",
      "        return chunks\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/blocks_registry.py\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import (\n",
      "    JoiningHarvester,\n",
      "    PathCommentHarvester,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_ranking import (\n",
      "    NegativePathDistanceRanker,\n",
      "    FunctionCallRanker,\n",
      "    FileExtensionRanker,\n",
      "    RandomRanker,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_sorting import (\n",
      "    LexicographicSorter,\n",
      ")\n",
      "from pipeline.data.composers.blocks.context_postprocessing import (\n",
      "    PartialMemoryPostprocessor,\n",
      "    LineLengthPostprocessor,\n",
      "    LineStripPostprocessor,\n",
      "    InverseFrequencyMemoryPostprocessor,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_chunking import (\n",
      "    FileGrainedChunker,\n",
      "    CodeSegmentGrainedChunker,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_filtering import (\n",
      "    InclusiveFileExtensionFilter,\n",
      "    ExclusiveFileExtensionFilter,\n",
      "    EmptyFileFilter,\n",
      "    FileLengthFilter,\n",
      "    TokenizedFileLengthFilter,\n",
      "    CharTokenRatioFilter,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_preprocessing import (\n",
      "    EmptyLinesRemovalPreprocessor,\n",
      "    DeclarationOnlyPreprocessor,\n",
      ")\n",
      "\n",
      "BLOCKS_REGISTRY = {\n",
      "    # file_filtering\n",
      "    'inclusive_file_extension_filter': InclusiveFileExtensionFilter,\n",
      "    'exclusive_file_extension_filter': ExclusiveFileExtensionFilter,\n",
      "    'empty_file_filter': EmptyFileFilter,\n",
      "    'file_length_filter': FileLengthFilter,\n",
      "    'tokenized_file_length_filter': TokenizedFileLengthFilter,\n",
      "    'char_token_ratio_filter': CharTokenRatioFilter,\n",
      "\n",
      "    # file_preprocessing\n",
      "    'empty_lines_removal_preprocessor': EmptyLinesRemovalPreprocessor,\n",
      "    'declaration_only_preprocessor': DeclarationOnlyPreprocessor,\n",
      "\n",
      "    # file_chunking\n",
      "    'file_grained_chunker': FileGrainedChunker,\n",
      "    'code_segment_grained_chunker': CodeSegmentGrainedChunker,\n",
      "\n",
      "    # chunk_ranking\n",
      "    'negative_path_distance_ranker': NegativePathDistanceRanker,\n",
      "    'function_call_ranker': FunctionCallRanker,\n",
      "    'file_extension_ranker': FileExtensionRanker,\n",
      "    'random_ranker': RandomRanker,\n",
      "\n",
      "    # chunk_sorting\n",
      "    'lexicographic_sorter': LexicographicSorter,\n",
      "\n",
      "    # chunk_harvesting\n",
      "    'joining_harvester': JoiningHarvester,\n",
      "    'path_comment_harvester': PathCommentHarvester,\n",
      "\n",
      "    # context_postprocessing\n",
      "    'partial_memory_postprocessor': PartialMemoryPostprocessor,\n",
      "    'line_length_postprocessor': LineLengthPostprocessor,\n",
      "    'line_strip_postprocessor': LineStripPostprocessor,\n",
      "    'inverse_frequency_memory_postprocessor': InverseFrequencyMemoryPostprocessor,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_filtering.py\n",
      "from pipeline.data.composers.chain import File, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "import random\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class FileFilter(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from pipeline.data.composers.blocks.file_chunking import FileChunker\n",
      "        from pipeline.data.composers.blocks.file_preprocessing import FilePreprocessor\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "\n",
      "\n",
      "class InclusiveFileExtensionFilter(FileFilter):\n",
      "    def __init__(self, whitelist: list[str]) -> None:\n",
      "        self.whitelist = tuple(whitelist)\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if file.metadata['filename'].endswith(self.whitelist)]\n",
      "\n",
      "\n",
      "class ExclusiveFileExtensionFilter(FileFilter):\n",
      "    def __init__(self, blacklist: list[str]) -> None:\n",
      "        self.blacklist = tuple(blacklist)\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if not file.metadata['filename'].endswith(self.blacklist)]\n",
      "\n",
      "\n",
      "class EmptyFileFilter(FileFilter):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if file.content.strip()]\n",
      "\n",
      "\n",
      "class FileLengthFilter(FileFilter):\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if self.min_len <= len(file.content) <= self.max_len]\n",
      "\n",
      "\n",
      "class TokenizedFileLengthFilter(FileFilter):\n",
      "    requires_tokenizer = True\n",
      "\n",
      "    def __init__(self, tokenizer: PreTrainedTokenizerBase, min_len: int, max_len: int) -> None:\n",
      "        self.tokenizer = tokenizer\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        filtered_files = list()\n",
      "\n",
      "        for file in files:\n",
      "            if 'num_tokens' not in file.metadata:\n",
      "                tokenized_file = self.tokenizer(file.content, return_attention_mask=False).input_ids\n",
      "                file.metadata['num_tokens'] = len(tokenized_file)\n",
      "\n",
      "            if self.min_len <= file.metadata['num_tokens'] <= self.max_len:\n",
      "                filtered_files.append(file)\n",
      "\n",
      "        return filtered_files\n",
      "\n",
      "\n",
      "class CharTokenRatioFilter(FileFilter):\n",
      "    requires_tokenizer = True\n",
      "\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 min_ratio: float,\n",
      "                 max_ratio: float,\n",
      "                 subsequence_len: int,\n",
      "                 random_seed: int | None,\n",
      "                 ) -> None:\n",
      "        self.tokenizer = tokenizer\n",
      "        self.min_ratio = min_ratio\n",
      "        self.max_ratio = max_ratio\n",
      "        self.subsequence_len = subsequence_len\n",
      "        self.generator = random.Random(random_seed)\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        filtered_files = list()\n",
      "\n",
      "        for file in files:\n",
      "            if len(file.content) <= self.subsequence_len:\n",
      "                subsequence = file.content\n",
      "            else:\n",
      "                # N.B. this algorithm does NOT preserve the uniformity of token sampling\n",
      "                # only the uniformity of subsequences\n",
      "                start_idx = self.generator.randrange(len(file.content) - self.subsequence_len + 1)\n",
      "                subsequence = file.content[start_idx:start_idx + self.subsequence_len]\n",
      "\n",
      "            tokenized_subsequence = self.tokenizer(subsequence, return_attention_mask=False).input_ids\n",
      "            ratio = len(subsequence) / len(tokenized_subsequence)\n",
      "\n",
      "            if self.min_ratio <= ratio <= self.max_ratio:\n",
      "                filtered_files.append(file)\n",
      "\n",
      "        return filtered_files\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_chunking.py\n",
      "from pipeline.data.composers.chain import File, Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from enum import Enum\n",
      "from string import whitespace\n",
      "from typing import Callable, NamedTuple, Sequence, TypeVar, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "\n",
      "class FileChunker(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "        from pipeline.data.composers.blocks.chunk_ranking import ChunkRanker\n",
      "        return ChunkRanker, ChunkHarvester\n",
      "\n",
      "\n",
      "class FileGrainedChunker(FileChunker):  # identity chunker\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        return [Chunk(content=file.content, metadata=file.metadata, file_ref=file) for file in files\n",
      "                # TODO: remove temporary hardcoded solution for data leakage\n",
      "                if file.metadata['filename'] != 'tinygrad/llops/ops_llvm.py']\n",
      "\n",
      "\n",
      "class CodeSegment(str, Enum):\n",
      "    COMMENT = 'comment_segment'\n",
      "    DOCSTRING = 'docstring_segment'\n",
      "    IMPORT = 'import_segment'\n",
      "    CODE = 'code_segment'\n",
      "    UNDEFINED = 'undefined_segment'\n",
      "\n",
      "    @classmethod\n",
      "    def from_node(cls: Type[T], node: tree_sitter.Node) -> T:\n",
      "        if 'comment' in node.type.lower():\n",
      "            return cls.COMMENT\n",
      "        elif node.type == 'string' and node.text.startswith(CodeSegmentGrainedChunker.DOCSTRING_PREFIX):\n",
      "            return cls.DOCSTRING\n",
      "        elif 'import' in node.type.lower():\n",
      "            return cls.IMPORT\n",
      "        elif node.child_count == 0:\n",
      "            return cls.CODE\n",
      "        else:\n",
      "            return cls.UNDEFINED\n",
      "\n",
      "\n",
      "class Segment(NamedTuple):\n",
      "    start_byte: int\n",
      "    type: CodeSegment\n",
      "\n",
      "\n",
      "class CodeSegmentGrainedChunker(FileChunker):\n",
      "    ENCODING = 'utf8'\n",
      "    DOCSTRING_PREFIX = (bytes(\"'''\", ENCODING), bytes('\"\"\"', ENCODING))\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "    @staticmethod\n",
      "    def dfs_segmentation(root_node: tree_sitter.Node) -> list[Segment]:\n",
      "        segments = list()\n",
      "        queue = [root_node]\n",
      "\n",
      "        while queue:\n",
      "            node = queue.pop()\n",
      "            segment_type = CodeSegment.from_node(node)\n",
      "\n",
      "            if segment_type != CodeSegment.UNDEFINED:\n",
      "                if len(segments) == 0 or segment_type != segments[-1].type:\n",
      "                    segments.append(Segment(node.start_byte, segment_type))\n",
      "            else:\n",
      "                queue.extend(reversed(node.children))\n",
      "\n",
      "        return segments\n",
      "\n",
      "    @staticmethod\n",
      "    def strip_lines(string: str, strip_func: Callable[[str], str]) -> str:\n",
      "        return '\\n'.join(map(strip_func, string.split('\\n')))\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        chunks = list()\n",
      "\n",
      "        for file in files:\n",
      "            if not file.metadata['filename'].endswith('.py'):\n",
      "                chunks.append(Chunk(\n",
      "                    content=file.content,\n",
      "                    metadata=file.metadata | {'segment_type': CodeSegment.UNDEFINED},\n",
      "                    file_ref=file,\n",
      "                ))\n",
      "                continue\n",
      "            # TODO: remove temporary hardcoded solution for data leakage\n",
      "            if file.metadata['filename'] == 'tinygrad/llops/ops_llvm.py':\n",
      "                continue\n",
      "\n",
      "            bytecode = bytes(file.content, self.ENCODING)\n",
      "            tree = self.parser.parse(bytecode)\n",
      "            segments = self.dfs_segmentation(tree.root_node)\n",
      "\n",
      "            dummy_segment = Segment(len(bytecode), CodeSegment.UNDEFINED)\n",
      "            segments.append(dummy_segment)\n",
      "\n",
      "            comments_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.COMMENT}, file_ref=file)\n",
      "            docstrings_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.DOCSTRING}, file_ref=file)\n",
      "            imports_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.IMPORT}, file_ref=file)\n",
      "            code_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.CODE}, file_ref=file)\n",
      "            prev_edited_chunk = None\n",
      "\n",
      "            for i in range(len(segments) - 1):\n",
      "                start = segments[i].start_byte\n",
      "                end = segments[i + 1].start_byte\n",
      "                segment_str = bytecode[start:end].decode(self.ENCODING)\n",
      "                segment_type = segments[i].type\n",
      "\n",
      "                match segment_type:\n",
      "                    case CodeSegment.COMMENT:\n",
      "                        # inline comment newline fix\n",
      "                        if prev_edited_chunk is not None and not prev_edited_chunk.content.rstrip(\n",
      "                                whitespace.replace('\\n', '')).endswith('\\n'):\n",
      "                            prev_edited_chunk.content += '\\n' + segment_str.split('\\n')[-1]\n",
      "\n",
      "                        if segment_str.count('\\n') >= 2:\n",
      "                            comments_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "                            prev_edited_chunk = comments_chunk\n",
      "\n",
      "                    case CodeSegment.DOCSTRING:\n",
      "                        docstrings_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "                        prev_edited_chunk = docstrings_chunk\n",
      "\n",
      "                    case CodeSegment.IMPORT:\n",
      "                        imports_chunk.content += segment_str\n",
      "                        prev_edited_chunk = imports_chunk\n",
      "\n",
      "                    case CodeSegment.CODE:\n",
      "                        code_chunk.content += segment_str\n",
      "                        prev_edited_chunk = code_chunk\n",
      "\n",
      "                    case _:\n",
      "                        raise RuntimeError  # indicates a bug\n",
      "\n",
      "            for chunk in (comments_chunk, docstrings_chunk, imports_chunk, code_chunk):\n",
      "                if chunk.content.strip():\n",
      "                    chunk.content = self.strip_lines(chunk.content.rstrip(), str.rstrip)\n",
      "                    chunks.append(chunk)\n",
      "\n",
      "        return chunks\n",
      "\n",
      "\n",
      "# ../configs/model/dseek1p3.yaml\n",
      "tokenizer_name: deepseek-ai/deepseek-coder-1.3b-base\n",
      "model_name: deepseek-ai/deepseek-coder-1.3b-base\n",
      "trust_remote_code: True\n",
      "compile: False\n",
      "\n",
      "\n",
      "# ../configs/split/256_5.yaml\n",
      "test_size: 256\n",
      "upper_bound_per_repo: 5\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/dataset/small.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: small_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../configs/dataset/huge.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: huge_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../configs/dataset/train_A100_server.yaml\n",
      "path: JetBrains-Research/lca-codegen-train\n",
      "data_dir: train\n",
      "split: train\n",
      "\n",
      "\n",
      "# ../configs/dataset/train.yaml\n",
      "path: JetBrains-Research/lca-codegen-train\n",
      "data_dir: train\n",
      "split: train\n",
      "cache_dir: /mnt/data2/shared-data/lca/hf_cache/\n",
      "\n",
      "\n",
      "# ../configs/dataset/large.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: large_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../configs/dataset/medium.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: medium_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/file_level_preprocessor.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class FileLevelPreprocessor(CompletionLossPreprocessor):\n",
      "    def calc_lens(self,\n",
      "                  prompt: torch.Tensor,\n",
      "                  context: torch.Tensor,\n",
      "                  completion: torch.Tensor,\n",
      "                  ) -> tuple[int, int, int]:\n",
      "        prompt_len, _, completion_len = super().calc_lens(prompt, context, completion)\n",
      "        return prompt_len, -len(context), completion_len\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessorBase\n",
      "from pipeline.data.preprocessors.preprocessors_registry import PREPROCESSORS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_preprocessor(cls_name: str, loaded_config: DictConfig, **kwargs) -> PreprocessorBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    preprocessor = PREPROCESSORS_REGISTRY[cls_name](**config.dict)\n",
      "    return preprocessor\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/preprocessors_registry.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "from pipeline.data.preprocessors.file_level_preprocessor import FileLevelPreprocessor\n",
      "from pipeline.data.preprocessors.lm_preprocessor import LMPreprocessor\n",
      "\n",
      "PREPROCESSORS_REGISTRY = {\n",
      "    'completion_loss_preprocessor': CompletionLossPreprocessor,\n",
      "    'file_level_preprocessor': FileLevelPreprocessor,\n",
      "    'lm_preprocessor': LMPreprocessor,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/completion_loss_preprocessor.py\n",
      "from pipeline.data.categories import CATEGORY2ID, UNDEFINED_CATEGORY_ID\n",
      "from pipeline.data.composed_datapoint import BatchComposedDatapoint\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessedBatch, PreprocessorBase\n",
      "\n",
      "import math\n",
      "import re\n",
      "import warnings\n",
      "\n",
      "import torch\n",
      "from transformers import BatchEncoding, PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class CompletionLossPreprocessor(PreprocessorBase):\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 max_seq_len: int,\n",
      "                 context_tokens: int | float,\n",
      "                 loss_ratio: float,\n",
      "                 num_chars_per_token: int,\n",
      "                 padding: bool,\n",
      "                 verbose: bool,\n",
      "                 ) -> None:\n",
      "        if not 0 < loss_ratio <= 1:\n",
      "            raise ValueError('loss_ratio must be selected from the interval (0, 1]. '\n",
      "                             f'Got {loss_ratio} instead.')\n",
      "\n",
      "        if padding:\n",
      "            tokenizer.deprecation_warnings['Asking-to-pad-a-fast-tokenizer'] = True\n",
      "        tokenizer.deprecation_warnings['sequence-length-is-longer-than-the-specified-maximum'] = True\n",
      "\n",
      "        self.tokenizer = tokenizer\n",
      "        self.max_seq_len = max_seq_len\n",
      "\n",
      "        if isinstance(context_tokens, float):\n",
      "            if not 0 <= context_tokens <= 1:\n",
      "                raise ValueError('The context ratio must be between 0 and 1.')\n",
      "\n",
      "            context_tokens = int(max_seq_len * context_tokens)\n",
      "        self.context_tokens = context_tokens\n",
      "\n",
      "        self.loss_ratio = loss_ratio\n",
      "        self.num_chars_per_token = num_chars_per_token\n",
      "        self.padding = padding\n",
      "        self.verbose = verbose\n",
      "\n",
      "    def _inc_num_chars_per_token(self) -> None:\n",
      "        old_value = self.num_chars_per_token\n",
      "        self.num_chars_per_token = math.ceil(1.5 * self.num_chars_per_token)\n",
      "\n",
      "        if self.verbose:\n",
      "            warnings.warn(\n",
      "                f'num_chars_per_token has been increased from {old_value} to {self.num_chars_per_token} '\n",
      "                'due to an underestimation of the length of the truncated character sequence.')\n",
      "\n",
      "    def tokenize_pre_context_prompt(self, prompts: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "\n",
      "        tokenized_prompts = self.tokenizer(\n",
      "            text=[prompt[-char_trunc_upper_bound:] for prompt in prompts],\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "\n",
      "        for tokenized_prompt, prompt in zip(tokenized_prompts.input_ids, prompts):\n",
      "            overflow_chars = len(prompt) > char_trunc_upper_bound\n",
      "            underflow_tokens = len(tokenized_prompt) < self.max_seq_len\n",
      "\n",
      "            if overflow_chars and underflow_tokens:\n",
      "                self._inc_num_chars_per_token()\n",
      "                return self.tokenize_pre_context_prompt(prompts)\n",
      "\n",
      "        return tokenized_prompts\n",
      "\n",
      "    def tokenize_composed_completion(self, completions: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "        trunc_completions = [completion[:char_trunc_upper_bound] for completion in completions]\n",
      "\n",
      "        tokenized_completions = self.tokenizer(\n",
      "            text=trunc_completions,\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "            return_offsets_mapping=True,\n",
      "            return_length=True,\n",
      "        )\n",
      "\n",
      "        tokenized_completions.length = torch.tensor(tokenized_completions.length)\n",
      "        overflow_chars = torch.tensor([len(completion) > char_trunc_upper_bound for completion in completions])\n",
      "        underflow_tokens = (tokenized_completions.length < self.max_seq_len)\n",
      "\n",
      "        if torch.any(overflow_chars & underflow_tokens):\n",
      "            self._inc_num_chars_per_token()\n",
      "            return self.tokenize_composed_completion(completions)\n",
      "\n",
      "        tokenized_completions['newline_positions'] = [\n",
      "            [match.start() for match in re.finditer('\\n', completion)]\n",
      "            for completion in trunc_completions\n",
      "        ]\n",
      "\n",
      "        return tokenized_completions\n",
      "\n",
      "    def tokenize_composed_context(self, contexts: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "\n",
      "        tokenized_contexts = self.tokenizer(\n",
      "            text=[ctx[-char_trunc_upper_bound:] for ctx in contexts],\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "\n",
      "        for tokenized_ctx, ctx in zip(tokenized_contexts.input_ids, contexts):\n",
      "            overflow_chars = len(ctx) > char_trunc_upper_bound\n",
      "            underflow_tokens = len(tokenized_ctx) < self.max_seq_len\n",
      "\n",
      "            if overflow_chars and underflow_tokens:\n",
      "                self._inc_num_chars_per_token()\n",
      "                return self.tokenize_composed_context(contexts)\n",
      "\n",
      "            if not overflow_chars and len(tokenized_ctx) < self.context_tokens:\n",
      "                if not self.padding:\n",
      "                    raise ValueError('Not enough data to satisfy context_tokens.')\n",
      "                elif self.verbose:\n",
      "                    warnings.warn('Not enough data to satisfy context_tokens.')\n",
      "\n",
      "        return tokenized_contexts\n",
      "\n",
      "    def calc_lens(self,\n",
      "                  prompt: torch.Tensor,\n",
      "                  context: torch.Tensor,\n",
      "                  completion: torch.Tensor,\n",
      "                  ) -> tuple[int, int, int]:\n",
      "        if len(context) >= self.context_tokens:\n",
      "            prompt_len = min(len(prompt), self.max_seq_len - self.context_tokens)\n",
      "            completion_len = min(len(completion), self.max_seq_len - self.context_tokens - prompt_len)\n",
      "            context_len = self.max_seq_len - prompt_len - completion_len\n",
      "        else:\n",
      "            context_len = len(context)\n",
      "            prompt_len = min(len(prompt), self.max_seq_len - context_len)\n",
      "            completion_len = self.max_seq_len - prompt_len - context_len\n",
      "\n",
      "        return prompt_len, context_len, completion_len\n",
      "\n",
      "    @staticmethod\n",
      "    def _get_partial_completion_mask(tokenized_completions: BatchEncoding,\n",
      "                                     target_attn_mask: torch.Tensor,\n",
      "                                     ratio: float,\n",
      "                                     ) -> torch.Tensor:\n",
      "        position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        completions_len = tokenized_completions.length.unsqueeze(-1)\n",
      "        num_masked_tokens = (ratio * completions_len).ceil().long()\n",
      "        mask = (num_informative_tokens - num_masked_tokens <= position_ids)\n",
      "        return mask.logical_and(target_attn_mask)\n",
      "\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        return self._get_partial_completion_mask(*args, **kwargs, ratio=self.loss_ratio)\n",
      "\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        return self._get_partial_completion_mask(*args, **kwargs, ratio=1)\n",
      "\n",
      "    @staticmethod\n",
      "    def get_category_ids(tokenized_completions: BatchEncoding,\n",
      "                         completion_lines: list[CompletionLines],\n",
      "                         target_attn_mask: torch.Tensor,\n",
      "                         ) -> torch.Tensor:\n",
      "        category_ids = torch.full_like(target_attn_mask, UNDEFINED_CATEGORY_ID)\n",
      "        t_completion_start = (target_attn_mask.sum(dim=-1) - tokenized_completions.length).tolist()\n",
      "        batch_size = len(tokenized_completions.length)\n",
      "\n",
      "        for sample_idx in range(batch_size):\n",
      "            newline_positions = tokenized_completions.newline_positions[sample_idx]\n",
      "            offset_mapping = tokenized_completions.offset_mapping[sample_idx]\n",
      "\n",
      "            newline_positions.append(float('inf'))\n",
      "            line2category = {\n",
      "                line_idx: CATEGORY2ID[category]\n",
      "                for category, line_category_ids in completion_lines[sample_idx].items()\n",
      "                for line_idx in line_category_ids\n",
      "            }\n",
      "\n",
      "            line_idx = 0\n",
      "            category_id = line2category.get(line_idx)\n",
      "\n",
      "            for token_idx, (char_start, _) in enumerate(offset_mapping, start=t_completion_start[sample_idx]):\n",
      "                if char_start > newline_positions[line_idx]:\n",
      "                    line_idx += 1\n",
      "                    category_id = line2category.get(line_idx)\n",
      "\n",
      "                if category_id is not None:\n",
      "                    category_ids[sample_idx, token_idx] = category_id\n",
      "\n",
      "        return category_ids\n",
      "\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "        tokenized_prompts = self.tokenize_pre_context_prompt(batch['pre_context_prompt'])\n",
      "        tokenized_completions = self.tokenize_composed_completion(batch['composed_completion'])\n",
      "        tokenized_contexts = self.tokenize_composed_context(batch['composed_context'])\n",
      "\n",
      "        tokenized_batch = list()\n",
      "        batch_size = len(tokenized_completions.length)\n",
      "\n",
      "        for sample_idx in range(batch_size):\n",
      "            prompt = tokenized_prompts.input_ids[sample_idx]\n",
      "            context = tokenized_contexts.input_ids[sample_idx]\n",
      "            completion = tokenized_completions.input_ids[sample_idx]\n",
      "\n",
      "            prompt_len, context_len, completion_len = self.calc_lens(prompt, context, completion)\n",
      "\n",
      "            prompt = [self.tokenizer.bos_token_id] + prompt[-prompt_len:]\n",
      "            context = context[-context_len:]\n",
      "            completion = completion[:completion_len]\n",
      "\n",
      "            tokenized_completions.offset_mapping[sample_idx] = \\\n",
      "                tokenized_completions.offset_mapping[sample_idx][:completion_len]\n",
      "            tokenized_completions.length[sample_idx] = len(completion)\n",
      "\n",
      "            tokenized_batch.append(prompt + context + completion)\n",
      "\n",
      "        self.tokenizer.padding_side = 'right'\n",
      "        padded_batch = self.tokenizer.pad(\n",
      "            encoded_inputs={'input_ids': tokenized_batch},\n",
      "            padding='longest',\n",
      "            return_attention_mask=True,\n",
      "            return_tensors='pt')\n",
      "        input_attn_mask = padded_batch.attention_mask[:, :-1]\n",
      "        target_attn_mask = padded_batch.attention_mask[:, 1:]\n",
      "\n",
      "        return PreprocessedBatch(\n",
      "            input_ids=padded_batch.input_ids[:, :-1],\n",
      "            target_ids=padded_batch.input_ids[:, 1:],\n",
      "            loss_mask=self.get_loss_mask(tokenized_completions, target_attn_mask),\n",
      "            completion_mask=self.get_completion_mask(tokenized_completions, target_attn_mask),\n",
      "            category_ids=self.get_category_ids(tokenized_completions, batch['completion_lines'], target_attn_mask),\n",
      "            input_attn_mask=input_attn_mask,\n",
      "            target_attn_mask=target_attn_mask.bool(),\n",
      "        )\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/lm_preprocessor.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "\n",
      "import torch\n",
      "from transformers import BatchEncoding\n",
      "\n",
      "\n",
      "class LMPreprocessor(CompletionLossPreprocessor):\n",
      "    def get_loss_mask(self,\n",
      "                      _tokenized_completions: BatchEncoding,\n",
      "                      target_attn_mask: torch.Tensor,\n",
      "                      **_kwargs,\n",
      "                      ) -> torch.Tensor:\n",
      "        position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        num_loss_tokens = (self.loss_ratio * num_informative_tokens).ceil().long()\n",
      "        loss_mask = (num_informative_tokens - num_loss_tokens <= position_ids)\n",
      "        return loss_mask.logical_and(target_attn_mask)\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/preprocessor_base.py\n",
      "from pipeline.data.composed_datapoint import BatchComposedDatapoint\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class PreprocessedBatch(TypedDict):\n",
      "    input_ids: torch.Tensor\n",
      "    target_ids: torch.Tensor\n",
      "\n",
      "    loss_mask: torch.Tensor\n",
      "    completion_mask: torch.Tensor\n",
      "    category_ids: torch.Tensor\n",
      "\n",
      "    input_attn_mask: torch.Tensor\n",
      "    target_attn_mask: torch.Tensor\n",
      "\n",
      "\n",
      "class PreprocessorBase(ABC):\n",
      "    @abstractmethod\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Important note: different number of masked tokens in different\n",
      "        micro-batches will break gradient accumulation, in which case\n",
      "        the training loop should include corresponding gradient scaling.\n",
      "        *or we just don't care :)\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def get_category_ids(self, *args, **kwargs) -> torch.Tensor:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.data.composers.blocks.blocks_registry import BLOCKS_REGISTRY\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.composers.composers_registry import COMPOSERS_REGISTRY\n",
      "\n",
      "import os\n",
      "\n",
      "import yaml\n",
      "from omegaconf import DictConfig\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "def init_composer(cls_name: str,\n",
      "                  loaded_config: DictConfig,\n",
      "                  configs_dir: str,\n",
      "                  tokenizer: PreTrainedTokenizerBase,\n",
      "                  **kwargs,\n",
      "                  ) -> ComposerBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "\n",
      "    if cls_name == 'chained_composer':\n",
      "        for path in loaded_config.block_configs:\n",
      "            full_path = os.path.join(configs_dir, 'composer/chained_composer/blocks', path)\n",
      "            block_name = os.path.basename(os.path.dirname(path))\n",
      "\n",
      "            with open(full_path) as stream:\n",
      "                block_config = yaml.safe_load(stream)\n",
      "\n",
      "            if block_config is None:\n",
      "                block_config = dict()\n",
      "\n",
      "            block_cls = BLOCKS_REGISTRY[block_name]\n",
      "            if block_cls.requires_tokenizer:\n",
      "                block_config['tokenizer'] = tokenizer\n",
      "\n",
      "            block = block_cls(**block_config)\n",
      "            config.blocks.append(block)\n",
      "\n",
      "    composer = COMPOSERS_REGISTRY[cls_name](**config.dict)\n",
      "    return composer\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/chain.py\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from pipeline.data.composers.utils import ReprMixin\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from dataclasses import dataclass, field\n",
      "from typing import Any, Sequence\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class File:\n",
      "    content: str\n",
      "    metadata: dict[str, Any]\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Chunk:\n",
      "    content: str\n",
      "    metadata: dict[str, Any]\n",
      "    file_ref: File\n",
      "    rank: list = field(default_factory=list)  # of comparable elements\n",
      "\n",
      "\n",
      "BlockArgs = Sequence[File] | Sequence[Chunk]\n",
      "\n",
      "\n",
      "class ComposerBlock(ABC, ReprMixin):\n",
      "    first_block_permit: bool = False\n",
      "    last_block_permit: bool = False\n",
      "    requires_tokenizer: bool = False\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def next_blocks(self) -> tuple[type, ...]:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def check_next_block(self, block) -> None:\n",
      "        if not isinstance(block, self.next_blocks):\n",
      "            raise ValueError(f'{type(block).__name__} cannot be used after {type(self).__name__}.')\n",
      "\n",
      "    @abstractmethod\n",
      "    def __call__(self, args: BlockArgs, datapoint: Datapoint) -> BlockArgs | str:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "class ComposerChain:\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None:\n",
      "        if not blocks:\n",
      "            raise ValueError('ComposerChain instance must contain at least one element.')\n",
      "        elif not blocks[0].first_block_permit:\n",
      "            raise ValueError(f'{type(blocks[0]).__name__} cannot start a chain of blocks.')\n",
      "        elif not blocks[-1].last_block_permit:\n",
      "            raise ValueError(f'{type(blocks[-1]).__name__} cannot end a chain of blocks.')\n",
      "\n",
      "        for block, next_block in zip(blocks[:-1], blocks[1:]):\n",
      "            block.check_next_block(next_block)\n",
      "\n",
      "        self.blocks = blocks\n",
      "\n",
      "    def __call__(self, datapoint: Datapoint) -> str:\n",
      "        x = [\n",
      "            File(content=cnt, metadata={'filename': fn})\n",
      "            for fn, cnt in zip(*datapoint.repo_snapshot.values())\n",
      "        ]\n",
      "        for block in self.blocks:\n",
      "            x = block(x, datapoint)\n",
      "        return x\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/composer_base.py\n",
      "from pipeline.data.composed_datapoint import ComposedDatapoint, BatchComposedDatapoint\n",
      "from pipeline.data.datapoint import Datapoint, BatchDatapoint\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any\n",
      "\n",
      "from datasets import Dataset\n",
      "\n",
      "\n",
      "class ComposerBase(ABC):\n",
      "    def __init__(self,\n",
      "                 pre_context_prompt: str,\n",
      "                 post_context_prompt: str,\n",
      "                 path_comment_template: str,\n",
      "                 recalculate_random_category: bool,\n",
      "                 ) -> None:\n",
      "        self.pre_context_prompt = pre_context_prompt\n",
      "        self.post_context_prompt = post_context_prompt\n",
      "        self.path_comment_template = path_comment_template\n",
      "        self.recalculate_random_category = recalculate_random_category\n",
      "\n",
      "    def get_pre_context_prompt(self, datapoint: Datapoint) -> str:\n",
      "        return self.pre_context_prompt.format(datapoint.repo)\n",
      "\n",
      "    def get_post_context_prompt(self, _datapoint: Datapoint) -> str:\n",
      "        return self.post_context_prompt\n",
      "\n",
      "    @abstractmethod\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def compose_completion(self, datapoint: Datapoint) -> str:\n",
      "        template_with_inserted_path = self.path_comment_template.format(\n",
      "            filename=datapoint.completion_file['filename'],\n",
      "            content='{content}',\n",
      "        )\n",
      "\n",
      "        for i, line in enumerate(template_with_inserted_path.split('\\n')):\n",
      "            if '{content}' in line:\n",
      "                offset = i\n",
      "                break\n",
      "        else:\n",
      "            raise RuntimeError('The path_comment_template does not contain a content field.')\n",
      "\n",
      "        for line_category_ids in datapoint.completion_lines.values():\n",
      "            for i in range(len(line_category_ids)):\n",
      "                line_category_ids[i] += offset\n",
      "\n",
      "        completion = template_with_inserted_path.format(**datapoint.completion_file)\n",
      "        if not completion.endswith('\\n'):\n",
      "            completion += '\\n'  # instead of EOS token\n",
      "\n",
      "        return completion\n",
      "\n",
      "    def compose(self, datapoint: dict[str, Any]) -> ComposedDatapoint:\n",
      "        datapoint = Datapoint(**datapoint)\n",
      "\n",
      "        if self.recalculate_random_category:\n",
      "            non_categorized_lines = set(range(datapoint.completion_file['content'].count('\\n') + 1))\n",
      "            for category, lines in datapoint.completion_lines.items():\n",
      "                if category != 'random':\n",
      "                    non_categorized_lines.difference_update(lines)\n",
      "            datapoint.completion_lines['random'] = list(non_categorized_lines)\n",
      "\n",
      "        return ComposedDatapoint(\n",
      "            pre_context_prompt=self.get_pre_context_prompt(datapoint),\n",
      "            composed_context=self.compose_context(datapoint) + self.get_post_context_prompt(datapoint),\n",
      "            composed_completion=self.compose_completion(datapoint),\n",
      "            completion_lines=datapoint.completion_lines,\n",
      "        )\n",
      "\n",
      "    def compose_batch(self, batch: BatchDatapoint) -> BatchComposedDatapoint:\n",
      "        batch_keys = batch.keys()\n",
      "        composed_batch_keys = BatchComposedDatapoint.__required_keys__\n",
      "        # transpose and compose\n",
      "        batch = [self.compose(dict(zip(batch_keys, data))) for data in zip(*batch.values())]\n",
      "        # transpose back\n",
      "        batch = {key: list(map(lambda x: x.get(key), batch)) for key in composed_batch_keys}\n",
      "        return batch\n",
      "\n",
      "    def compose_dataset(self,\n",
      "                        dataset: Dataset,\n",
      "                        writer_batch_size: int = 128,\n",
      "                        num_proc: int = 4,\n",
      "                        **map_kwargs,\n",
      "                        ) -> Dataset:\n",
      "        return dataset.map(\n",
      "            function=self.compose,\n",
      "            remove_columns=map_kwargs.pop('remove_columns', dataset.column_names),\n",
      "            # created cache files consume a lot of disk space\n",
      "            load_from_cache_file=map_kwargs.pop('load_from_cache_file', False),\n",
      "            writer_batch_size=writer_batch_size,\n",
      "            num_proc=num_proc,\n",
      "            desc=map_kwargs.pop('desc', f'Applying {type(self).__name__} to a given dataset'),\n",
      "            **map_kwargs,\n",
      "        )\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/chained_composer.py\n",
      "from pipeline.data.composers.chain import ComposerBlock, ComposerChain\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.composers.utils import ReprMixin\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from typing import Sequence\n",
      "\n",
      "\n",
      "class ChainedComposer(ComposerBase, ComposerChain, ReprMixin):\n",
      "    def __init__(self, blocks: Sequence[ComposerBlock], *args, **kwargs) -> None:\n",
      "        ComposerBase.__init__(self, *args, **kwargs)\n",
      "        ComposerChain.__init__(self, *blocks)\n",
      "\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        return self.__call__(datapoint)\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/composers_registry.py\n",
      "from pipeline.data.composers.chained_composer import ChainedComposer\n",
      "\n",
      "COMPOSERS_REGISTRY = {\n",
      "    'chained_composer': ChainedComposer,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/utils.py\n",
      "class ReprMixin:\n",
      "    _init_args = None\n",
      "    _init_kwargs = None\n",
      "\n",
      "    def __init_subclass__(cls, **kwargs) -> None:\n",
      "        super().__init_subclass__(**kwargs)\n",
      "        original_init = cls.__init__\n",
      "\n",
      "        def wrapped_init(self, *init_args, **init_kwargs) -> None:\n",
      "            if cls == type(self):\n",
      "                self._init_args = init_args\n",
      "                self._init_kwargs = init_kwargs\n",
      "            original_init(self, *init_args, **init_kwargs)\n",
      "\n",
      "        cls.__init__ = wrapped_init\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        args_str = ', '.join(\n",
      "            [\n",
      "                f\"'{arg}'\" if isinstance(arg, str) else repr(arg)\n",
      "                for arg in self._init_args\n",
      "            ] + [\n",
      "                f\"{key}='{value}'\" if isinstance(value, str) else f'{key}={value!r}'\n",
      "                for key, value in self._init_kwargs.items()\n",
      "            ])\n",
      "        return f'{type(self).__name__}({args_str})'\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/cross_entropy.py\n",
      "from pipeline.outputs.metrics.metric_base import MetricValue, OptimizationMode, MetricBase\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class CrossEntropy(MetricBase):\n",
      "    mode = OptimizationMode.MIN\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        self.mean_loss = 0\n",
      "        self.num_tokens = 0\n",
      "\n",
      "    @torch.inference_mode\n",
      "    def micro_batch_update(self, loss_per_token: torch.Tensor, mask: torch.Tensor, **_kwargs) -> None:\n",
      "        loss_update = torch.nan_to_num(loss_per_token[mask].mean()).item()\n",
      "        num_tokens_update = mask.sum().item()\n",
      "\n",
      "        # loss correction w.r.t. number of masked tokens (for unbalanced batches)\n",
      "        if not self.num_tokens:\n",
      "            self.mean_loss += loss_update\n",
      "            self.num_tokens = 0\n",
      "        else:\n",
      "            tokens_ratio = num_tokens_update / self.num_tokens\n",
      "            self.mean_loss += tokens_ratio * loss_update\n",
      "            self.mean_loss /= tokens_ratio + 1\n",
      "\n",
      "        self.num_tokens += num_tokens_update\n",
      "\n",
      "    def batch_commit(self) -> MetricValue:\n",
      "        batch_metric = float('nan') if not self.num_tokens else self.mean_loss\n",
      "        self.mean_loss = 0\n",
      "        self.num_tokens = 0\n",
      "        return batch_metric\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/counters.py\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticBase\n",
      "\n",
      "from typing import TypeVar, Type\n",
      "\n",
      "import torch\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "# avoiding cyclical imports\n",
      "FullFineTuningTrainer = TypeVar('FullFineTuningTrainer')\n",
      "\n",
      "\n",
      "class EpochCounter(StatisticBase):\n",
      "    _instance = None  # singleton pattern\n",
      "\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "        if cls._instance is None:\n",
      "            cls._instance = super().__new__(cls)\n",
      "        return cls._instance\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        self.init_epoch = 0  # for resumption\n",
      "        self.samples = 0\n",
      "        self.ds_length = 1\n",
      "\n",
      "    def reinit(self, init_epoch: float | None) -> None:\n",
      "        if init_epoch is not None:\n",
      "            self.init_epoch = init_epoch\n",
      "\n",
      "    def micro_batch_update(self, input_ids: torch.Tensor, trainer: FullFineTuningTrainer, **_kwargs) -> None:\n",
      "        if trainer.model.training:  # ignores validation samples\n",
      "            self.samples += input_ids.shape[0]\n",
      "            self.ds_length = len(trainer.train_dl.dataset)\n",
      "\n",
      "    def batch_commit(self) -> StatisticValue:\n",
      "        return self.init_epoch + self.samples / self.ds_length\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/statistic_base.py\n",
      "# TODO: grad norm, number of (masked) tokens, speed [tok/sec]?\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Type\n",
      "\n",
      "import torch\n",
      "\n",
      "StatisticValue = int | float\n",
      "\n",
      "\n",
      "class StatisticBase(ABC):\n",
      "    def reinit(self, prev_value: StatisticValue | None) -> None:\n",
      "        pass  # default behavior\n",
      "\n",
      "    @abstractmethod\n",
      "    @torch.inference_mode\n",
      "    def micro_batch_update(self, **kwargs) -> None:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def batch_commit(self) -> StatisticValue:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "def ema_factory(statistic_cls: Type[StatisticBase]) -> Type[StatisticBase]:\n",
      "    class EMAStatistic(statistic_cls, ABC):\n",
      "        def __init__(self, ema_alpha: float) -> None:\n",
      "            super().__init__()\n",
      "            self.ema_alpha = ema_alpha\n",
      "            self.ema_state = None\n",
      "\n",
      "        def reinit(self, ema_state: float | None) -> None:\n",
      "            self.ema_state = ema_state\n",
      "\n",
      "        def batch_commit(self) -> StatisticValue:\n",
      "            batch_metric = super().batch_commit()\n",
      "            if self.ema_state is None:\n",
      "                self.ema_state = batch_metric\n",
      "            else:\n",
      "                self.ema_state += self.ema_alpha * (batch_metric - self.ema_state)\n",
      "            return self.ema_state\n",
      "\n",
      "    return EMAStatistic\n",
      "\n",
      "\n",
      "def lazy_statistic_factory(statistic_name: str) -> Type[StatisticBase]:\n",
      "    class LazyStatistic(StatisticBase):\n",
      "        def __init__(self) -> None:\n",
      "            self.value = None\n",
      "\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            self.value = kwargs.get(statistic_name)\n",
      "\n",
      "        def batch_commit(self) -> StatisticValue:\n",
      "            batch_statistic = self.value\n",
      "            self.value = None\n",
      "            return batch_statistic\n",
      "\n",
      "    return LazyStatistic\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/metric_base.py\n",
      "from pipeline.data.categories import CategoryType, CATEGORY2ID\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticBase\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from enum import Enum\n",
      "from typing import Type\n",
      "\n",
      "MetricName = str\n",
      "MetricValue = StatisticValue\n",
      "\n",
      "\n",
      "class OptimizationMode(str, Enum):\n",
      "    MIN = 'minimization'\n",
      "    MAX = 'maximization'\n",
      "\n",
      "\n",
      "class MetricBase(StatisticBase, ABC):\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def mode(self) -> OptimizationMode:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "def loss_based_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class LossBasedMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = kwargs['loss_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "\n",
      "    return LossBasedMetric\n",
      "\n",
      "\n",
      "def detached_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class DetachedMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = ~kwargs['loss_mask'] & kwargs['target_attn_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "\n",
      "    return DetachedMetric\n",
      "\n",
      "\n",
      "def completion_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class FullMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = kwargs['completion_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "\n",
      "    return FullMetric\n",
      "\n",
      "\n",
      "def context_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class FullMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = ~kwargs['completion_mask'] & kwargs['target_attn_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "\n",
      "    return FullMetric\n",
      "\n",
      "\n",
      "def full_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class FullMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = kwargs['target_attn_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "\n",
      "    return FullMetric\n",
      "\n",
      "\n",
      "def categorized_metric_factory(metric_cls: Type[MetricBase], category: CategoryType) -> Type[MetricBase]:\n",
      "    class CategorizedMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = (kwargs['category_ids'] == CATEGORY2ID[category])\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "\n",
      "    return CategorizedMetric\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/metrics_registry.py\n",
      "from pipeline.outputs.metrics.cross_entropy import CrossEntropy\n",
      "from pipeline.outputs.metrics.metric_base import (\n",
      "    loss_based_metric_factory,\n",
      "    detached_metric_factory,\n",
      "    completion_metric_factory,\n",
      "    context_metric_factory,\n",
      "    full_metric_factory,\n",
      "    categorized_metric_factory,\n",
      ")\n",
      "from pipeline.outputs.metrics.statistic_base import ema_factory, lazy_statistic_factory\n",
      "from pipeline.outputs.metrics.counters import EpochCounter\n",
      "\n",
      "METRICS_REGISTRY = {\n",
      "    'cross_entropy': loss_based_metric_factory(CrossEntropy),\n",
      "\n",
      "    'detached_cross_entropy': detached_metric_factory(CrossEntropy),\n",
      "    'completion_cross_entropy': completion_metric_factory(CrossEntropy),\n",
      "    'context_cross_entropy': context_metric_factory(CrossEntropy),\n",
      "    'full_cross_entropy': full_metric_factory(CrossEntropy),\n",
      "    'commited_cross_entropy': categorized_metric_factory(CrossEntropy, 'commited'),\n",
      "    'common_cross_entropy': categorized_metric_factory(CrossEntropy, 'common'),\n",
      "    'infile_cross_entropy': categorized_metric_factory(CrossEntropy, 'infile'),\n",
      "    'inproject_cross_entropy': categorized_metric_factory(CrossEntropy, 'inproject'),\n",
      "    'non_informative_cross_entropy': categorized_metric_factory(CrossEntropy, 'non_informative'),\n",
      "    'random_cross_entropy': categorized_metric_factory(CrossEntropy, 'random'),\n",
      "    'other_cross_entropy': categorized_metric_factory(CrossEntropy, 'other'),\n",
      "\n",
      "    # in training only\n",
      "    'epoch': EpochCounter,\n",
      "    'learning_rate': lazy_statistic_factory('learning_rate'),\n",
      "}\n",
      "METRICS_REGISTRY.update({  # useless due to W&B native support :(\n",
      "    f'ema_{name}': ema_factory(cls) for name, cls in METRICS_REGISTRY.items()\n",
      "})\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/top_k_checkpointer.py\n",
      "from pipeline.outputs.checkpointers.data_structures import Checkpoint\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "\n",
      "import os\n",
      "import shutil\n",
      "\n",
      "\n",
      "class TopKCheckpointManager(CheckpointManager):\n",
      "    def __init__(self, max_checkpoints_num: int, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.max_checkpoints_num = max_checkpoints_num\n",
      "\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "        super().save_checkpoint(checkpoint)\n",
      "\n",
      "        checkpoints = next(os.walk(self.directory))[1]\n",
      "        checkpoints = sorted(checkpoints, key=self.get_checkpoint_score)\n",
      "\n",
      "        while len(checkpoints) > self.max_checkpoints_num:\n",
      "            checkpoint2del = checkpoints.pop()\n",
      "            checkpoint2del = os.path.join(self.directory, checkpoint2del)\n",
      "            shutil.rmtree(checkpoint2del)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/checkpointer.py\n",
      "from pipeline.outputs.checkpointers.data_structures import LoadingMode, Checkpoint\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue, OptimizationMode, MetricBase\n",
      "from pipeline.outputs.metrics.metrics_registry import METRICS_REGISTRY\n",
      "\n",
      "import json\n",
      "import os\n",
      "import warnings\n",
      "\n",
      "from typing import Callable, Literal\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class CheckpointManager:  # aka checkpointer\n",
      "    def __init__(self,\n",
      "                 init_from: LoadingMode | str,\n",
      "                 main_metric: MetricName,\n",
      "                 directory: str,\n",
      "                 checkpoint_directory_template: str,\n",
      "                 extract_iteration_number: Callable[[str], int],\n",
      "                 model_subdirectory: str,\n",
      "                 optim_state_filename: str,\n",
      "                 metrics_filename: str,\n",
      "                 ) -> None:\n",
      "        if main_metric not in METRICS_REGISTRY:\n",
      "            raise ValueError('The specified main_metric is not contained in the registry.')\n",
      "\n",
      "        self.init_from = init_from\n",
      "        self.main_metric_name = main_metric\n",
      "        self.main_metric = METRICS_REGISTRY[main_metric]\n",
      "        self.directory = directory\n",
      "\n",
      "        self._checkpoint_directory_template = checkpoint_directory_template\n",
      "        self._extract_iteration_number = extract_iteration_number\n",
      "        self._model_subdirectory = model_subdirectory\n",
      "        self._optim_state_filename = optim_state_filename\n",
      "        self._metrics_filename = metrics_filename\n",
      "\n",
      "    def get_wandb_resume_mode(self) -> Literal['allow', 'never'] | None:\n",
      "        match self.init_from:\n",
      "            case LoadingMode.SCRATCH:\n",
      "                return None\n",
      "            case LoadingMode.RESUME:\n",
      "                return 'allow'\n",
      "            case _:\n",
      "                return 'never'\n",
      "\n",
      "    def load_metrics(self, checkpoint_dir: str) -> Log:\n",
      "        metrics_file = os.path.join(checkpoint_dir, self._metrics_filename)\n",
      "        with open(metrics_file) as stream:\n",
      "            return Log(**json.load(stream))\n",
      "\n",
      "    def get_checkpoint_score(self, checkpoint_dir: str) -> MetricValue:\n",
      "        checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "        metrics = self.load_metrics(checkpoint_dir)\n",
      "        metric_value = metrics.get('valid_metrics', metrics['train_metrics']).get(self.main_metric_name)\n",
      "\n",
      "        if metric_value is None:\n",
      "            raise RuntimeError(f'The {checkpoint_dir} does not contain information '\n",
      "                               'about the specified main_metric.')\n",
      "        elif self.main_metric.mode == OptimizationMode.MIN:\n",
      "            return metric_value\n",
      "        else:\n",
      "            return -metric_value\n",
      "\n",
      "    def get_checkpoint_directory(self) -> str | None:\n",
      "        match self.init_from:\n",
      "            case LoadingMode.SCRATCH:\n",
      "                return None\n",
      "            case LoadingMode.RESUME:\n",
      "                return max(\n",
      "                    next(os.walk(self.directory))[1],\n",
      "                    key=self._extract_iteration_number,\n",
      "                    default=None,\n",
      "                )\n",
      "            case LoadingMode.BEST:\n",
      "                return min(\n",
      "                    next(os.walk(self.directory))[1],\n",
      "                    key=self.get_checkpoint_score,\n",
      "                    default=None,\n",
      "                )\n",
      "            case _:  # user-defined checkpoint directory\n",
      "                return self.init_from\n",
      "\n",
      "    def get_iteration_number(self) -> int:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        if checkpoint_dir is not None:\n",
      "            return self._extract_iteration_number(checkpoint_dir)\n",
      "        else:\n",
      "            return 0\n",
      "\n",
      "    def get_model_subdirectory(self) -> str | None:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        if checkpoint_dir is not None:\n",
      "            return os.path.join(self.directory, checkpoint_dir, self._model_subdirectory)\n",
      "        else:\n",
      "            return None\n",
      "\n",
      "    def init_optimizer(self, optimizer: torch.optim.AdamW) -> None:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        if checkpoint_dir is not None:\n",
      "            optim_file = os.path.join(self.directory, checkpoint_dir, self._optim_state_filename)\n",
      "            optimizer.load_state_dict(torch.load(optim_file))\n",
      "\n",
      "    def init_metrics(self,\n",
      "                     group: Literal['train_metrics', 'valid_metrics'],\n",
      "                     metrics: list[MetricName],\n",
      "                     ema_alpha: float,\n",
      "                     ) -> dict[MetricName, MetricBase]:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        metrics_dict = dict()\n",
      "\n",
      "        if checkpoint_dir is None:\n",
      "            metrics_states = dict()\n",
      "        else:\n",
      "            checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "            metrics_states = self.load_metrics(checkpoint_dir)[group]\n",
      "\n",
      "        for name in metrics:\n",
      "            init_args = [ema_alpha] if name.startswith('ema_') else list()\n",
      "            metrics_dict[name] = METRICS_REGISTRY[name](*init_args)\n",
      "            metrics_dict[name].reinit(metrics_states.get(name))\n",
      "\n",
      "        return metrics_dict\n",
      "\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "        checkpoint_dir = os.path.join(\n",
      "            self.directory,\n",
      "            self._checkpoint_directory_template.format(\n",
      "                iteration_number=checkpoint.metrics['iteration_number']),\n",
      "        )\n",
      "\n",
      "        if os.path.exists(checkpoint_dir):\n",
      "            warnings.warn(f'The contents of the checkpoint {checkpoint_dir} have been overwritten.')\n",
      "\n",
      "        model_save_dir, optim_file, metrics_file = map(\n",
      "            lambda x: os.path.join(checkpoint_dir, x),\n",
      "            [self._model_subdirectory, self._optim_state_filename, self._metrics_filename],\n",
      "        )\n",
      "\n",
      "        checkpoint.model.save_pretrained(model_save_dir)\n",
      "        torch.save(checkpoint.optimizer_state, optim_file)\n",
      "\n",
      "        with open(metrics_file, 'w') as stream:\n",
      "            json.dump(checkpoint.metrics, stream, indent=4)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/data_structures.py\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from enum import Enum\n",
      "\n",
      "from transformers import PreTrainedModel\n",
      "\n",
      "\n",
      "class LoadingMode(str, Enum):\n",
      "    SCRATCH = 'scratch'\n",
      "    RESUME = 'resume'\n",
      "    BEST = 'best'\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Checkpoint:\n",
      "    metrics: Log\n",
      "    model: PreTrainedModel\n",
      "    optimizer_state: dict\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.checkpointers_registry import CHECKPOINTERS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_checkpointer(cls_name: str, loaded_config: DictConfig, **kwargs) -> CheckpointManager:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    checkpointer = CHECKPOINTERS_REGISTRY[cls_name](**config.dict)\n",
      "    return checkpointer\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/checkpointers_registry.py\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.top_k_checkpointer import TopKCheckpointManager\n",
      "\n",
      "CHECKPOINTERS_REGISTRY = {\n",
      "    'checkpointer': CheckpointManager,\n",
      "    'top_k_checkpointer': TopKCheckpointManager,\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/dummy_logger.py\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "\n",
      "\n",
      "class DummyLogger(LoggerBase):\n",
      "    def __init__(self, *_args, **_kwargs) -> None:\n",
      "        pass\n",
      "\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        return metrics\n",
      "\n",
      "    def message(self, message: Message) -> Message:\n",
      "        return message\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/local_logger.py\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "\n",
      "import csv\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import sys\n",
      "import traceback\n",
      "import warnings\n",
      "from types import TracebackType\n",
      "from typing import NoReturn\n",
      "\n",
      "import datasets.utils.logging\n",
      "import transformers.utils.logging\n",
      "\n",
      "\n",
      "class JsonFormatter(logging.Formatter):\n",
      "    def format(self, record: logging.LogRecord) -> str:\n",
      "        message_dict = {\n",
      "            'timestamp': self.formatTime(record, self.datefmt),\n",
      "            'level': record.levelname,\n",
      "            'content': record.msg,\n",
      "        }\n",
      "\n",
      "        indent = '    '\n",
      "        json_string = json.dumps(message_dict, indent=4)\n",
      "        json_string = indent.join(json_string.splitlines(keepends=True))\n",
      "        json_string = indent + json_string\n",
      "\n",
      "        return json_string\n",
      "\n",
      "\n",
      "class JsonHandler(logging.FileHandler):\n",
      "    def emit(self, record: logging.LogRecord) -> None:\n",
      "        if not os.path.exists(self.baseFilename) or os.stat(self.baseFilename).st_size == 0:\n",
      "            self.stream.write('[\\n')\n",
      "        else:\n",
      "            self.stream.seek(self.stream.tell() - 1)\n",
      "            self.stream.truncate()\n",
      "            self.stream.write(',\\n')\n",
      "\n",
      "        super().emit(record)\n",
      "\n",
      "    def close(self) -> None:\n",
      "        self.stream.seek(self.stream.tell() - 1)\n",
      "        self.stream.write(']')\n",
      "\n",
      "        super().close()\n",
      "\n",
      "\n",
      "class LocalLogger(LoggerBase):\n",
      "    def __init__(self,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 ) -> None:\n",
      "        if train_csv == valid_csv:\n",
      "            raise ValueError('The names of the train_csv and valid_csv files must be different.')\n",
      "\n",
      "        train_csv, valid_csv, stdout_file, stderr_file = map(\n",
      "            lambda x: os.path.join(directory, x),\n",
      "            [train_csv, valid_csv, stdout_file, stderr_file],\n",
      "        )\n",
      "\n",
      "        if os.path.exists(train_csv):\n",
      "            with open(train_csv) as stream:\n",
      "                self.last_logged_iter = max(map(lambda x: int(x.split(',')[0]), stream.readlines()[1:]))\n",
      "        else:\n",
      "            self.last_logged_iter = -1\n",
      "\n",
      "        self.train_csv = train_csv\n",
      "        self.valid_csv = valid_csv\n",
      "\n",
      "        self.logger = logging.getLogger(__name__)\n",
      "        self.logger.propagate = False\n",
      "        self.logger.setLevel(logging.DEBUG)\n",
      "        formatter = JsonFormatter()\n",
      "\n",
      "        stdout_handler = JsonHandler(stdout_file)\n",
      "        stdout_handler.setLevel(logging.INFO)\n",
      "        stdout_handler.setFormatter(formatter)\n",
      "        stdout_handler.addFilter(lambda record: record.levelno < logging.WARNING)\n",
      "\n",
      "        if stderr_file == stdout_file:\n",
      "            stderr_handler = stdout_handler\n",
      "        else:  # TODO: large number of processes + high call frequency breaks the json formatting structure (bug)\n",
      "            stderr_handler = JsonHandler(stderr_file)\n",
      "            stderr_handler.setLevel(logging.WARNING)\n",
      "            stderr_handler.setFormatter(formatter)\n",
      "            stderr_handler.addFilter(lambda record: record.levelno >= logging.WARNING)\n",
      "\n",
      "        # self.logger.handlers.clear()\n",
      "        self.logger.addHandler(stdout_handler)\n",
      "        self.logger.addHandler(stderr_handler)\n",
      "\n",
      "        warnings.showwarning = self.warning_handler\n",
      "        sys.excepthook = self.exception_handler\n",
      "\n",
      "        # redirect all HF logs (at least datasets and transformers)\n",
      "        datasets_logger = datasets.utils.logging.get_logger()\n",
      "        transformers_logger = transformers.utils.logging.get_logger()\n",
      "\n",
      "        datasets_logger.handlers = self.logger.handlers\n",
      "        transformers_logger.handlers = self.logger.handlers\n",
      "\n",
      "    @staticmethod\n",
      "    def write_metrics_to_csv(metrics: dict[MetricName, MetricValue], path: str) -> None:\n",
      "        with open(path, mode='a', newline='') as stream:\n",
      "            writer = csv.DictWriter(stream, fieldnames=metrics.keys())\n",
      "            if stream.tell() == 0:\n",
      "                writer.writeheader()\n",
      "            writer.writerow(metrics)\n",
      "\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "            return metrics  # repeated iterations between checkpoints\n",
      "\n",
      "        iter_num = {'iter_num': metrics['iteration_number']}\n",
      "\n",
      "        if 'train_metrics' in metrics:\n",
      "            self.write_metrics_to_csv(iter_num | metrics['train_metrics'], self.train_csv)\n",
      "        if 'valid_metrics' in metrics:\n",
      "            self.write_metrics_to_csv(iter_num | metrics['valid_metrics'], self.valid_csv)\n",
      "\n",
      "        return metrics\n",
      "\n",
      "    def message(self, message: Message) -> Message:\n",
      "        self.logger.info(message)\n",
      "        return message\n",
      "\n",
      "    def warning_handler(self, message: Warning, category: type, path: str, lineno: int, *_kwargs) -> None:\n",
      "        self.logger.warning({\n",
      "            'category': category.__name__,\n",
      "            'location': f'{path}:{lineno}',\n",
      "            'message': str(message),\n",
      "        })\n",
      "\n",
      "    def exception_handler(self, exc_type: type, exc_value: Exception, exc_traceback: TracebackType) -> NoReturn:\n",
      "        if issubclass(exc_type, KeyboardInterrupt):\n",
      "            self.message('Process was stopped due to a keyboard interrupt.')\n",
      "        else:\n",
      "            self.logger.error({\n",
      "                'category': exc_type.__name__,\n",
      "                'traceback': [{\n",
      "                    'location': f'{filename}:{lineno} in {func_name}',\n",
      "                    'line': line,\n",
      "                } for filename, lineno, func_name, line in traceback.extract_tb(exc_traceback)],\n",
      "                'message': str(exc_value),\n",
      "            })\n",
      "            self.message('Process finished with a non-zero exit code.')\n",
      "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/logger_base.py\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict, TypeVar, Type\n",
      "from typing_extensions import NotRequired\n",
      "\n",
      "T = TypeVar('T')\n",
      "JsonAllowedTypes = dict | list | tuple | str | int | float | bool | None\n",
      "Message = str | int | float | dict[str, JsonAllowedTypes]\n",
      "\n",
      "\n",
      "class Log(TypedDict):  # TODO: replace with dataclass\n",
      "    iteration_number: int\n",
      "    train_metrics: NotRequired[dict[MetricName, MetricValue]]\n",
      "    valid_metrics: NotRequired[dict[MetricName, MetricValue]]\n",
      "\n",
      "\n",
      "class LoggerBase(ABC):\n",
      "    _instance = None  # singleton pattern\n",
      "\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "        if cls._instance is None:\n",
      "            cls._instance = super().__new__(cls)\n",
      "        return cls._instance\n",
      "\n",
      "    @abstractmethod\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def message(self, message: Message) -> Message:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.outputs.loggers.logger_base import LoggerBase\n",
      "from pipeline.outputs.loggers.loggers_registry import LOGGERS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_logger(cls_name: str, loaded_config: DictConfig, **kwargs) -> LoggerBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    logger = LOGGERS_REGISTRY[cls_name](**config.dict)\n",
      "    return logger\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/wandb_logger.py\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "\n",
      "import wandb\n",
      "\n",
      "\n",
      "class WandbLogger(LocalLogger):\n",
      "    def __init__(self,\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 **wandb_init_kwargs,\n",
      "                 ) -> None:\n",
      "        super().__init__(train_csv, valid_csv, stdout_file, stderr_file, directory)\n",
      "        wandb_init_kwargs['resume'] = wandb_init_kwargs.get('resume', checkpointer.get_wandb_resume_mode())\n",
      "        wandb_init_kwargs['id'] = wandb_init_kwargs.get('id', wandb_init_kwargs['name'])\n",
      "        wandb.init(**wandb_init_kwargs)\n",
      "\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "            return super().log(metrics)  # repeated iterations between checkpoints\n",
      "\n",
      "        wandb_log = dict()\n",
      "        if 'train_metrics' in metrics:\n",
      "            wandb_log['train'] = metrics['train_metrics']\n",
      "        if 'valid_metrics' in metrics:\n",
      "            wandb_log['validation'] = metrics['valid_metrics']\n",
      "\n",
      "        wandb.log(wandb_log, step=metrics['iteration_number'])\n",
      "        return super().log(metrics)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/loggers_registry.py\n",
      "from pipeline.outputs.loggers.dummy_logger import DummyLogger\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.wandb_logger import WandbLogger\n",
      "\n",
      "LOGGERS_REGISTRY = {\n",
      "    'dummy': DummyLogger,\n",
      "    'local': LocalLogger,\n",
      "    'wandb': WandbLogger,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/utils/fused_sampler.py\n",
      "import math\n",
      "from typing import Iterator\n",
      "\n",
      "import torch\n",
      "from torch.utils.data import Sampler\n",
      "\n",
      "\n",
      "class FusedSampler(Sampler[int]):\n",
      "    def __init__(self,\n",
      "                 start_sample_idx: int,\n",
      "                 end_sample_idx: int,\n",
      "                 dataset_length: int,\n",
      "                 generator: torch.Generator | None = None,\n",
      "                 ) -> None:\n",
      "        super().__init__()\n",
      "\n",
      "        self.start_sample_idx = start_sample_idx\n",
      "        self.end_sample_idx = end_sample_idx\n",
      "        self.dataset_length = dataset_length\n",
      "        self.max_epochs = math.ceil(end_sample_idx / dataset_length)\n",
      "        self.generator = generator\n",
      "\n",
      "    def __iter__(self) -> Iterator[int]:\n",
      "        fused_weights = torch.rand(self.max_epochs, self.dataset_length, generator=self.generator)\n",
      "        fused_indices = torch.argsort(fused_weights, dim=-1).flatten().tolist()\n",
      "        yield from fused_indices[self.start_sample_idx:self.end_sample_idx]\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        return self.end_sample_idx - self.start_sample_idx\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/utils/schedulers.py\n",
      "import math\n",
      "\n",
      "\n",
      "def get_lr_from_cosine_scheduler_with_linear_warmup(iter_num: int,\n",
      "                                                    min_lr: float,\n",
      "                                                    max_lr: float,\n",
      "                                                    warmup_iters: int,\n",
      "                                                    lr_decay_iters: int,\n",
      "                                                    ) -> float:\n",
      "    if iter_num < warmup_iters:  # warmup\n",
      "        return max_lr * (iter_num + 1) / warmup_iters\n",
      "    elif iter_num > lr_decay_iters:  # constant lr\n",
      "        return min_lr\n",
      "    else:  # cosine wave\n",
      "        decay_ratio = (iter_num - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
      "        return min_lr + (max_lr - min_lr) / 2 * (1 + math.cos(math.pi * decay_ratio))\n",
      "\n",
      "\n",
      "# ../configs/defaults.yaml\n",
      "run_name: ???\n",
      "\n",
      "defaults:\n",
      "  - checkpointer: top_k_checkpointer/top_3\n",
      "  - composer: chained_composer/standard\n",
      "  - dataset: train_A100_server\n",
      "  - logger: wandb/wandb\n",
      "  - model: dseek1p3\n",
      "  - preprocessor: completion_loss_preprocessor/full_completion_loss_16k\n",
      "  - split: '256_5'\n",
      "  - trainer: full_finetuning_trainer/medium_lr\n",
      "\n",
      "  - _self_\n",
      "  - override hydra/hydra_logging: disabled\n",
      "  - override hydra/job_logging: disabled\n",
      "\n",
      "hydra:\n",
      "  output_subdir: null\n",
      "  run:\n",
      "    dir: .\n",
      "\n",
      "\n",
      "# ../pipeline/environment/hardware.py\n",
      "import subprocess\n",
      "import warnings\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "def get_free_device(used_memory_upper_bound: float = 0.001) -> torch.device:\n",
      "    if hasattr(get_free_device, 'allocated'):\n",
      "        return get_free_device.allocated\n",
      "\n",
      "    for gpu_index in range(torch.cuda.device_count()):\n",
      "        gpu_pid_stats = subprocess.check_output([\n",
      "            'nvidia-smi', f'-i={gpu_index}', '--query-compute-apps=pid', '--format=csv,noheader',\n",
      "        ], encoding='utf-8')\n",
      "        gpu_mem_stats = subprocess.check_output([\n",
      "            'nvidia-smi', f'-i={gpu_index}', '--query-gpu=memory.used,memory.total', '--format=csv,noheader',\n",
      "        ], encoding='utf-8')\n",
      "\n",
      "        mem_used, mem_total = map(int, gpu_mem_stats.replace('MiB', '').split(', '))\n",
      "\n",
      "        if not gpu_pid_stats and mem_used / mem_total <= used_memory_upper_bound:\n",
      "            get_free_device.allocated = torch.device(f'cuda:{gpu_index}')\n",
      "            return get_free_device.allocated\n",
      "\n",
      "    warnings.warn('No CUDA devices were found. CPU will be used.')\n",
      "    return torch.device('cpu')\n",
      "\n",
      "\n",
      "def get_optimal_dtype() -> torch.dtype:\n",
      "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
      "        return torch.bfloat16\n",
      "    else:\n",
      "        warnings.warn('torch.bfloat16 is not supported. torch.float16 '\n",
      "                      'with gradient scaling will be used instead.')\n",
      "        return torch.float16\n",
      "\n",
      "\n",
      "# ../pipeline/data/categories.py\n",
      "from typing import Literal\n",
      "\n",
      "CategoryType = Literal['commited', 'common', 'infile', 'inproject', 'non_informative', 'random', 'other']\n",
      "\n",
      "ID2CATEGORY = [\n",
      "    'commited',\n",
      "    'common',\n",
      "    'infile',\n",
      "    'inproject',\n",
      "    'non_informative',\n",
      "    'random',\n",
      "    'other',\n",
      "]\n",
      "CATEGORY2ID = {category: i for i, category in enumerate(ID2CATEGORY)}\n",
      "UNDEFINED_CATEGORY_ID = -1\n",
      "\n",
      "\n",
      "# ../pipeline/data/dataset.py\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessorBase\n",
      "\n",
      "import random\n",
      "from collections import defaultdict\n",
      "\n",
      "from datasets import Dataset\n",
      "\n",
      "\n",
      "def train_test_split(dataset: Dataset,\n",
      "                     test_size: int,\n",
      "                     upper_bound_per_repo: int,\n",
      "                     random_seed: int | None = None,\n",
      "                     ) -> tuple[Dataset, Dataset | None]:\n",
      "    if test_size == 0:\n",
      "        return dataset, None\n",
      "\n",
      "    generator = random.Random(random_seed)\n",
      "    queue = defaultdict(list)\n",
      "    repos_enum = list(enumerate(dataset['repo']))\n",
      "    generator.shuffle(repos_enum)\n",
      "\n",
      "    for idx, repo in repos_enum:\n",
      "        queue[repo].append(idx)\n",
      "\n",
      "    queue = list(queue.items())\n",
      "    generator.shuffle(queue)\n",
      "\n",
      "    train_repos_ids = set(range(len(dataset)))\n",
      "    test_repos_ids = set()\n",
      "    cur_test_size = 0\n",
      "\n",
      "    while cur_test_size != test_size:\n",
      "        if queue:\n",
      "            repo, ids = queue.pop()\n",
      "        else:\n",
      "            raise ValueError(\n",
      "                'There are not enough data points in the original dataset to satisfy both the '\n",
      "                'test_size and upper_bound_per_repo arguments. Try either decreasing the test_size '\n",
      "                'or increasing the upper_bound_per_repo.')\n",
      "\n",
      "        num_new_samples = min(upper_bound_per_repo, test_size - cur_test_size, len(ids))\n",
      "\n",
      "        train_repos_ids.difference_update(ids)\n",
      "        test_repos_ids.update(ids[:num_new_samples])\n",
      "        cur_test_size += num_new_samples\n",
      "\n",
      "    train_ds = dataset.select(train_repos_ids)\n",
      "    test_ds = dataset.select(test_repos_ids)\n",
      "\n",
      "    return train_ds, test_ds\n",
      "\n",
      "\n",
      "def set_transform(train_ds: Dataset,\n",
      "                  test_ds: Dataset | None,\n",
      "                  composer: ComposerBase,\n",
      "                  preprocessor: PreprocessorBase,\n",
      "                  ) -> None:\n",
      "    transform = lambda x: preprocessor(composer.compose_batch(x))\n",
      "    train_ds.set_transform(transform)\n",
      "    if test_ds is not None:\n",
      "        test_ds.set_transform(transform)\n",
      "\n",
      "\n",
      "# ../pipeline/data/datapoint.py\n",
      "from dataclasses import dataclass\n",
      "from typing import TypedDict\n",
      "\n",
      "\n",
      "class CompletionFile(TypedDict):\n",
      "    filename: str\n",
      "    content: str\n",
      "\n",
      "\n",
      "class CompletionLines(TypedDict, total=False):\n",
      "    commited: list[int]\n",
      "    common: list[int]\n",
      "    infile: list[int]\n",
      "    inproject: list[int]\n",
      "    non_informative: list[int]\n",
      "    random: list[int]\n",
      "    other: list[int]\n",
      "\n",
      "\n",
      "class RepoSnapshot(TypedDict):\n",
      "    filename: list[str]\n",
      "    content: list[str]\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Datapoint:\n",
      "    repo: str\n",
      "    commit_hash: str\n",
      "    completion_file: CompletionFile\n",
      "    completion_lines: CompletionLines\n",
      "    repo_snapshot: RepoSnapshot\n",
      "    completion_lines_raw: CompletionLines | None = None\n",
      "\n",
      "\n",
      "class BatchDatapoint(TypedDict):\n",
      "    repo: list[str]\n",
      "    commit_hash: list[str]\n",
      "    completion_file: list[CompletionFile]\n",
      "    completion_lines: list[CompletionLines]\n",
      "    repo_snapshot: list[RepoSnapshot]\n",
      "    completion_lines_raw: list[CompletionLines]\n",
      "\n",
      "\n",
      "# ../pipeline/data/composed_datapoint.py\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "\n",
      "from typing import TypedDict\n",
      "\n",
      "\n",
      "class ComposedDatapoint(TypedDict):\n",
      "    pre_context_prompt: str\n",
      "    composed_context: str\n",
      "    composed_completion: str\n",
      "    completion_lines: CompletionLines\n",
      "\n",
      "\n",
      "class BatchComposedDatapoint(TypedDict):\n",
      "    pre_context_prompt: list[str]\n",
      "    composed_context: list[str]\n",
      "    composed_completion: list[str]\n",
      "    completion_lines: list[CompletionLines]\n",
      "\n",
      "\n",
      "# ../pipeline/configs/configs_registry.py\n",
      "from pipeline.configs.checkpointer_config import (\n",
      "    CheckpointManagerConfig,\n",
      "    TopKCheckpointManagerConfig,\n",
      ")\n",
      "from pipeline.configs.composer_config import ChainedComposerConfig\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.configs.logger_config import (\n",
      "    LocalLoggerConfig,\n",
      "    WandbLoggerConfig,\n",
      ")\n",
      "from pipeline.configs.preprocessor_config import PreprocessorConfig\n",
      "from pipeline.configs.trainer_config import FullFineTuningTrainerConfig\n",
      "\n",
      "CONFIGS_REGISTRY = {\n",
      "    # checkpointers\n",
      "    'checkpointer': CheckpointManagerConfig,\n",
      "    'top_k_checkpointer': TopKCheckpointManagerConfig,\n",
      "\n",
      "    # loggers\n",
      "    'dummy': ConfigBase,\n",
      "    'local': LocalLoggerConfig,\n",
      "    'wandb': WandbLoggerConfig,\n",
      "\n",
      "    # composers\n",
      "    'chained_composer': ChainedComposerConfig,\n",
      "\n",
      "    # preprocessors\n",
      "    'completion_loss_preprocessor': PreprocessorConfig,\n",
      "    'file_level_preprocessor': PreprocessorConfig,\n",
      "    'lm_preprocessor': PreprocessorConfig,\n",
      "\n",
      "    # trainers\n",
      "    'full_finetuning_trainer': FullFineTuningTrainerConfig,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/configs/model_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Literal\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class ModelConfig(ConfigBase):\n",
      "    tokenizer_name: str\n",
      "    model_name: str\n",
      "    trust_remote_code: bool\n",
      "    load_from: str | None\n",
      "\n",
      "    use_cache: bool = False\n",
      "    device: torch.device | None = None\n",
      "    dtype: torch.dtype | None = None\n",
      "    attn_implementation: Literal['flash_attention_2', 'sdpa', 'eager'] | None = None\n",
      "    compile: bool = True\n",
      "\n",
      "    def __post_init__(self) -> None:\n",
      "        if isinstance(self.device, str):\n",
      "            self.device = torch.device(self.device)\n",
      "\n",
      "        if isinstance(self.dtype, str):\n",
      "            self.dtype = getattr(torch, self.dtype)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/logger_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Any\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class LocalLoggerConfig(ConfigBase):\n",
      "    train_csv: str\n",
      "    valid_csv: str\n",
      "    stdout_file: str\n",
      "    stderr_file: str\n",
      "    directory: str\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class WandbLoggerConfig(LocalLoggerConfig):\n",
      "    checkpointer: CheckpointManager\n",
      "    project: str\n",
      "    name: str\n",
      "    config: dict[str, Any] | None = None\n",
      "    group: str | None = None\n",
      "    notes: str | None = None\n",
      "\n",
      "\n",
      "# ../pipeline/configs/composer_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "\n",
      "from dataclasses import dataclass, field\n",
      "from typing import Sequence\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class ChainedComposerConfig(ConfigBase):\n",
      "    pre_context_prompt: str\n",
      "    post_context_prompt: str\n",
      "    path_comment_template: str\n",
      "    recalculate_random_category: bool\n",
      "    blocks: Sequence[ComposerBlock] = field(default_factory=list)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/checkpointer_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.data_structures import LoadingMode\n",
      "from pipeline.outputs.metrics.metric_base import MetricName\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Callable\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class CheckpointManagerConfig(ConfigBase):\n",
      "    init_from: LoadingMode | str\n",
      "    main_metric: MetricName\n",
      "    directory: str\n",
      "\n",
      "    # if you want to change it, override the following function accordingly\n",
      "    checkpoint_directory_template: str = '{iteration_number:04d}'\n",
      "    extract_iteration_number: Callable[[str], int] = staticmethod(int)\n",
      "\n",
      "    model_subdirectory: str = 'model'\n",
      "    optim_state_filename: str = 'optim.pt'\n",
      "    metrics_filename: str = 'metrics.json'  # should be .json\n",
      "\n",
      "    def __post_init__(self) -> None:\n",
      "        if self.init_from in set(LoadingMode):\n",
      "            self.init_from = LoadingMode(self.init_from)\n",
      "\n",
      "\n",
      "@dataclass(kw_only=True)\n",
      "class TopKCheckpointManagerConfig(CheckpointManagerConfig):\n",
      "    max_checkpoints_num: int\n",
      "\n",
      "\n",
      "# ../pipeline/configs/preprocessor_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class PreprocessorConfig(ConfigBase):\n",
      "    tokenizer: PreTrainedTokenizerBase\n",
      "    max_seq_len: int\n",
      "    context_tokens: int | float\n",
      "    loss_ratio: float\n",
      "    num_chars_per_token: int\n",
      "    padding: bool\n",
      "    verbose: bool = True\n",
      "\n",
      "\n",
      "# ../pipeline/configs/dataset_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "\n",
      "from datasets import config\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class DatasetConfig(ConfigBase):\n",
      "    path: str\n",
      "    name: str | None = None\n",
      "    data_dir: str | None = None\n",
      "    split: str | None = None\n",
      "    cache_dir: str = str(config.HF_DATASETS_CACHE)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/config_base.py\n",
      "from dataclasses import asdict, dataclass, fields\n",
      "from pprint import pformat\n",
      "from typing import Any, TypeVar, Type\n",
      "\n",
      "import yaml\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class ConfigBase:\n",
      "    def __str__(self) -> str:\n",
      "        return pformat(self)\n",
      "\n",
      "    @classmethod\n",
      "    def from_dict(cls: Type[T], dictionary: dict[str, Any]) -> T:\n",
      "        config_fields = set(field.name for field in fields(cls))\n",
      "        kwargs = {key: value for key, value in dictionary.items() if key in config_fields}\n",
      "        return cls(**kwargs)  # noqa: PyCharm bug?\n",
      "\n",
      "    @classmethod\n",
      "    def from_yaml(cls: Type[T], path: str | None = None) -> T:\n",
      "        if path is None:\n",
      "            path = cls._default_path\n",
      "\n",
      "        with open(path) as stream:\n",
      "            return cls(**yaml.safe_load(stream))  # noqa: PyCharm bug?\n",
      "\n",
      "    dict = property(vars)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/trainer_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.logger_base import LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Literal\n",
      "\n",
      "from datasets import Dataset\n",
      "from transformers import PreTrainedModel, PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class FullFineTuningTrainerConfig(ConfigBase):\n",
      "    model: PreTrainedModel\n",
      "    tokenizer: PreTrainedTokenizerBase\n",
      "    train_ds: Dataset\n",
      "    valid_ds: Dataset | None\n",
      "\n",
      "    # Auxiliary objects\n",
      "    checkpointer: CheckpointManager\n",
      "    logger: LoggerBase\n",
      "\n",
      "    # Iteration parameters\n",
      "    max_iters: int\n",
      "    valid_freq: int | None  # None means no validation at all\n",
      "    checkpointing_freq: int | None  # None means no checkpointing at all\n",
      "    gradient_accumulation_steps: int\n",
      "    micro_batch_size: int\n",
      "\n",
      "    # AdamW optimizer\n",
      "    learning_rate: float\n",
      "    beta_1: float\n",
      "    beta_2: float\n",
      "    weight_decay: float\n",
      "    max_grad_norm: float\n",
      "\n",
      "    # Cosine lr scheduler with warmup\n",
      "    warmup_iters: int | None\n",
      "    lr_decay_iters: int | None\n",
      "    min_lr: float | None\n",
      "\n",
      "    # Metrics (see METRICS_REGISTRY in pipeline/outputs/metrics/metrics_registry.py)\n",
      "    train_metrics: list[MetricName]\n",
      "    train_ema_alpha: float  # (see ema_factory in pipeline/outputs/metrics/statistic_base.py)\n",
      "    valid_metrics: list[MetricName]  # empty list means no validation at all\n",
      "    valid_ema_alpha: float | None  # if None, will be calculated as 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "\n",
      "    # DataLoader\n",
      "    shuffle: bool\n",
      "    drop_last: bool\n",
      "    num_workers: int\n",
      "    prefetch_factor: int | None\n",
      "    random_seed: int | None\n",
      "\n",
      "    # Floating point\n",
      "    fp32_matmul_precision: Literal['highest', 'high', 'medium']\n",
      "\n",
      "\n",
      "# ../pipeline/configs/split_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class SplitConfig(ConfigBase):\n",
      "    test_size: int  # 0 means no validation at all\n",
      "    upper_bound_per_repo: int\n",
      "    random_seed: int | None\n",
      "\n",
      "\n",
      "# ../pipeline/model/init.py\n",
      "from pipeline.configs.model_config import ModelConfig\n",
      "from pipeline.environment.hardware import get_free_device, get_optimal_dtype\n",
      "\n",
      "from enum import Enum\n",
      "\n",
      "import torch\n",
      "from omegaconf import DictConfig\n",
      "from transformers.models.auto import MODEL_FOR_CAUSAL_LM_MAPPING\n",
      "from transformers.utils import is_flash_attn_2_available, is_torch_sdpa_available\n",
      "from transformers import (\n",
      "    AutoTokenizer,\n",
      "    AutoModelForCausalLM,\n",
      "    AutoConfig,\n",
      "    PreTrainedModel,\n",
      "    PreTrainedTokenizerBase,\n",
      ")\n",
      "\n",
      "\n",
      "class AttentionImplementation(str, Enum):\n",
      "    # nondeterministic\n",
      "    FA2 = 'flash_attention_2'\n",
      "    SDPA = 'sdpa'\n",
      "    # deterministic\n",
      "    EAGER = 'eager'\n",
      "\n",
      "\n",
      "def init_tokenizer(config: ModelConfig) -> PreTrainedTokenizerBase:\n",
      "    return AutoTokenizer.from_pretrained(\n",
      "        pretrained_model_name_or_path=config.tokenizer_name,\n",
      "        trust_remote_code=config.trust_remote_code,\n",
      "    )\n",
      "\n",
      "\n",
      "def get_optimal_attn(model_name: str, device: torch.device, dtype: torch.dtype) -> AttentionImplementation:\n",
      "    hf_model_config = AutoConfig.from_pretrained(model_name)\n",
      "    model_cls = MODEL_FOR_CAUSAL_LM_MAPPING[type(hf_model_config)]\n",
      "\n",
      "    fa2_supported = (\n",
      "            is_flash_attn_2_available() and\n",
      "            model_cls._supports_flash_attn_2 and  # noqa: HF doesn't have an API for this case\n",
      "            device.type == 'cuda' and\n",
      "            dtype in (torch.float16, torch.bfloat16)\n",
      "    )\n",
      "\n",
      "    if fa2_supported:\n",
      "        return AttentionImplementation.FA2\n",
      "    elif is_torch_sdpa_available() and model_cls._supports_sdpa:  # noqa: same\n",
      "        return AttentionImplementation.SDPA\n",
      "    else:\n",
      "        return AttentionImplementation.EAGER\n",
      "\n",
      "\n",
      "def init_model(config: ModelConfig) -> PreTrainedModel:\n",
      "    if config.device is None:\n",
      "        config.device = get_free_device()\n",
      "    if config.dtype is None:\n",
      "        config.dtype = get_optimal_dtype()\n",
      "    if config.attn_implementation is None:\n",
      "        config.attn_implementation = get_optimal_attn(config.model_name, config.device, config.dtype)\n",
      "    if config.load_from is None:\n",
      "        config.load_from = config.model_name\n",
      "\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "        pretrained_model_name_or_path=config.load_from,\n",
      "        trust_remote_code=config.trust_remote_code,\n",
      "        device_map=config.device,\n",
      "        torch_dtype=config.dtype,\n",
      "        attn_implementation=config.attn_implementation,\n",
      "        use_cache=config.use_cache,\n",
      "    )\n",
      "\n",
      "    if config.compile:\n",
      "        model = torch.compile(model)\n",
      "    return model\n",
      "\n",
      "\n",
      "def init_tokenizer_model(loaded_config: DictConfig, **kwargs) -> tuple[PreTrainedTokenizerBase, PreTrainedModel]:\n",
      "    config = ModelConfig.from_dict(dict(loaded_config) | kwargs)\n",
      "    return init_tokenizer(config), init_model(config)\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.trainers_registry import TRAINERS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_trainer(cls_name: str, loaded_config: DictConfig, **kwargs) -> TrainerBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    trainer = TRAINERS_REGISTRY[cls_name](**config.dict)\n",
      "    return trainer\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/full_finetuning_trainer.py\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.data_structures import Checkpoint\n",
      "from pipeline.outputs.loggers.logger_base import Log, LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.utils.fused_sampler import FusedSampler\n",
      "from pipeline.trainers.utils.schedulers import get_lr_from_cosine_scheduler_with_linear_warmup\n",
      "\n",
      "import warnings\n",
      "from functools import partial\n",
      "from typing import Literal\n",
      "\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from datasets import Dataset\n",
      "from torch.utils.data import DataLoader\n",
      "from tqdm.auto import trange, tqdm\n",
      "from transformers import PreTrainedModel, PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class FullFineTuningTrainer(TrainerBase):\n",
      "    def __init__(self,\n",
      "                 model: PreTrainedModel,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 train_ds: Dataset,\n",
      "                 valid_ds: Dataset | None,\n",
      "                 # auxiliary objects\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 logger: LoggerBase,\n",
      "                 # iteration parameters\n",
      "                 max_iters: int,\n",
      "                 valid_freq: int | None,\n",
      "                 checkpointing_freq: int | None,\n",
      "                 gradient_accumulation_steps: int,\n",
      "                 micro_batch_size: int,\n",
      "                 # optimizer\n",
      "                 learning_rate: float,\n",
      "                 beta_1: float,\n",
      "                 beta_2: float,\n",
      "                 weight_decay: float,\n",
      "                 max_grad_norm: float,\n",
      "                 # scheduler\n",
      "                 warmup_iters: int | None,\n",
      "                 lr_decay_iters: int | None,\n",
      "                 min_lr: float | None,\n",
      "                 # metrics\n",
      "                 train_metrics: list[MetricName],\n",
      "                 train_ema_alpha: float,\n",
      "                 valid_metrics: list[MetricName],\n",
      "                 valid_ema_alpha: float | None,\n",
      "                 # DataLoader\n",
      "                 shuffle: bool,\n",
      "                 drop_last: bool,\n",
      "                 num_workers: int,\n",
      "                 prefetch_factor: int,\n",
      "                 random_seed: int | None,\n",
      "                 # Floating point\n",
      "                 fp32_matmul_precision: Literal['highest', 'high', 'medium'],\n",
      "                 ) -> None:\n",
      "        # main objects\n",
      "        self.model = model\n",
      "        self.tokenizer = tokenizer\n",
      "        self.checkpointer = checkpointer\n",
      "        self.logger = logger\n",
      "\n",
      "        # iterations\n",
      "        self.checkpointing_freq = checkpointing_freq\n",
      "\n",
      "        if checkpointing_freq is None:\n",
      "            self.checkpointing_freq = float('inf')\n",
      "            self.logger.message('Checkpointing is disabled.')\n",
      "        elif valid_freq is not None and valid_freq != checkpointing_freq:\n",
      "            warnings.warn('Validation and checkpointing are not synchronized (valid_freq != checkpointing_freq). '\n",
      "                          'Resulting checkpoints will not contain validation metrics.')\n",
      "\n",
      "        self.start_iter = checkpointer.get_iteration_number()\n",
      "        self.max_iters = max_iters\n",
      "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
      "        self.batch_size = gradient_accumulation_steps * micro_batch_size\n",
      "\n",
      "        # environment\n",
      "        self.is_on_cuda = (model.device.type == 'cuda')\n",
      "        if random_seed is not None:\n",
      "            torch.manual_seed(random_seed)\n",
      "        torch.set_float32_matmul_precision(fp32_matmul_precision)\n",
      "        logger.message(f\"Set the FP32 matrix multiplication precision to '{fp32_matmul_precision}'.\")\n",
      "\n",
      "        # validation\n",
      "        if valid_ds is None and valid_freq is None and not valid_metrics:\n",
      "            self.valid_freq = float('inf')\n",
      "            self.valid_dl = None\n",
      "            self.logger.message('Validation is disabled.')\n",
      "        elif valid_ds is not None and valid_freq is not None and valid_metrics:\n",
      "            self.valid_freq = valid_freq\n",
      "            self.valid_dl = DataLoader(\n",
      "                dataset=valid_ds,\n",
      "                batch_size=micro_batch_size,\n",
      "                shuffle=False,\n",
      "                num_workers=num_workers,\n",
      "                pin_memory=self.is_on_cuda,\n",
      "                drop_last=False,\n",
      "                prefetch_factor=prefetch_factor,\n",
      "                persistent_workers=(valid_freq > max_iters),\n",
      "                pin_memory_device=str(model.device),\n",
      "            )\n",
      "\n",
      "            if valid_ema_alpha is None:\n",
      "                valid_ema_alpha = 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "                self.logger.message(f'valid_ema_alpha automatically set to {valid_ema_alpha:.05f}.')\n",
      "\n",
      "        else:\n",
      "            raise ValueError('The valid_ds, valid_freq and valid_metrics arguments do not match each other.')\n",
      "\n",
      "        # training dataset\n",
      "        sampler = FusedSampler(\n",
      "            start_sample_idx=(self.batch_size * self.start_iter),\n",
      "            end_sample_idx=(self.batch_size * max_iters),\n",
      "            dataset_length=len(train_ds),\n",
      "        ) if shuffle else None\n",
      "\n",
      "        self.train_dl = DataLoader(\n",
      "            dataset=train_ds,\n",
      "            batch_size=micro_batch_size,\n",
      "            sampler=sampler,\n",
      "            num_workers=num_workers,\n",
      "            pin_memory=self.is_on_cuda,\n",
      "            drop_last=drop_last,\n",
      "            prefetch_factor=prefetch_factor,\n",
      "            pin_memory_device=str(model.device),\n",
      "        )\n",
      "\n",
      "        # optimizer initialization\n",
      "        self.optimizer = self._init_adamw(learning_rate, beta_1, beta_2, weight_decay)\n",
      "\n",
      "        # gradient utilities\n",
      "        self.grad_scaler = torch.cuda.amp.GradScaler(enabled=(model.dtype == torch.float16))\n",
      "        self.max_grad_norm = max_grad_norm\n",
      "\n",
      "        # scheduler initialization\n",
      "        if warmup_iters is None and lr_decay_iters is None and min_lr is None:\n",
      "            self.get_lr = lambda _: learning_rate\n",
      "        elif warmup_iters is not None and lr_decay_iters is not None and min_lr is not None:\n",
      "            self.get_lr = partial(\n",
      "                get_lr_from_cosine_scheduler_with_linear_warmup,\n",
      "                min_lr=min_lr,\n",
      "                max_lr=learning_rate,\n",
      "                warmup_iters=warmup_iters,\n",
      "                lr_decay_iters=lr_decay_iters,\n",
      "            )\n",
      "        else:\n",
      "            raise ValueError('The warmup_iters, lr_decay_iters and min_lr arguments do not match each other.')\n",
      "\n",
      "        # metrics\n",
      "        self.train_metrics = self.checkpointer.init_metrics('train_metrics', train_metrics, train_ema_alpha)\n",
      "        self.valid_metrics = self.checkpointer.init_metrics('valid_metrics', valid_metrics, valid_ema_alpha)\n",
      "\n",
      "    def _init_adamw(self,\n",
      "                    learning_rate: float,\n",
      "                    beta_1: float,\n",
      "                    beta_2: float,\n",
      "                    weight_decay: float,\n",
      "                    ) -> torch.optim.AdamW:\n",
      "        decay_params = [p for p in self.model.parameters() if p.dim() >= 2]\n",
      "        no_decay_params = [p for p in self.model.parameters() if p.dim() < 2]\n",
      "        params = [\n",
      "            {'params': decay_params, 'weight_decay': weight_decay},\n",
      "            {'params': no_decay_params, 'weight_decay': 0},\n",
      "        ]\n",
      "\n",
      "        optimizer = torch.optim.AdamW(\n",
      "            params=params,\n",
      "            lr=learning_rate,\n",
      "            betas=(beta_1, beta_2),\n",
      "            fused=self.is_on_cuda)\n",
      "        self.checkpointer.init_optimizer(optimizer)\n",
      "\n",
      "        return optimizer\n",
      "\n",
      "    @torch.inference_mode\n",
      "    def validate(self, verbose: bool = True) -> dict[MetricName, MetricValue]:\n",
      "        training = self.model.training\n",
      "        self.model.eval()\n",
      "\n",
      "        valid_iter = tqdm(\n",
      "            iterable=self.valid_dl,\n",
      "            desc='Validation steps',\n",
      "            position=1,\n",
      "            leave=None,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "\n",
      "        for micro_batch in valid_iter:\n",
      "            (input_ids, target_ids,\n",
      "             loss_mask, completion_mask, category_ids,\n",
      "             input_attn_mask, target_attn_mask,\n",
      "             ) = (t.to(self.model.device) for t in micro_batch.values())\n",
      "\n",
      "            model_output = self.model(input_ids, attention_mask=input_attn_mask)\n",
      "            loss_per_token = F.cross_entropy(\n",
      "                input=model_output.logits.flatten(0, 1),\n",
      "                target=target_ids.flatten(0, 1),\n",
      "                reduction='none',\n",
      "            ).view_as(target_ids)\n",
      "\n",
      "            locals_copy = locals().copy()\n",
      "            locals_copy['trainer'] = locals_copy.pop('self')\n",
      "            [metric.micro_batch_update(**locals_copy) for metric in self.valid_metrics.values()]\n",
      "            del locals_copy\n",
      "\n",
      "        valid_log = {name: metric.batch_commit() for name, metric in self.valid_metrics.items()}\n",
      "\n",
      "        self.model.train(training)\n",
      "        return valid_log\n",
      "\n",
      "    def train(self, verbose: bool = True) -> None:\n",
      "        self.model.train()\n",
      "\n",
      "        train_iter = iter(self.train_dl)\n",
      "        pbar_iter = trange(\n",
      "            self.start_iter, self.max_iters,\n",
      "            desc='Optimization steps',\n",
      "            initial=self.start_iter,\n",
      "            total=self.max_iters,\n",
      "            position=0,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "        pbar_accumulation = trange(\n",
      "            self.gradient_accumulation_steps,\n",
      "            desc='Gradient accumulation steps',\n",
      "            position=1,\n",
      "            leave=None,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "\n",
      "        if self.start_iter == 0 and self.valid_dl is not None:\n",
      "            log = Log(iteration_number=0, valid_metrics=self.validate(verbose))\n",
      "            self.logger.log(log)\n",
      "\n",
      "        for iter_num in pbar_iter:\n",
      "            pbar_accumulation.reset()\n",
      "\n",
      "            learning_rate = self.get_lr(iter_num)\n",
      "            for param_group in self.optimizer.param_groups:\n",
      "                param_group['lr'] = learning_rate\n",
      "\n",
      "            for _ in range(self.gradient_accumulation_steps):\n",
      "                (input_ids, target_ids,\n",
      "                 loss_mask, completion_mask, category_ids,\n",
      "                 input_attn_mask, target_attn_mask,\n",
      "                 ) = (t.to(self.model.device) for t in next(train_iter).values())\n",
      "\n",
      "                model_output = self.model(input_ids, attention_mask=input_attn_mask)\n",
      "                loss_per_token = F.cross_entropy(\n",
      "                    input=model_output.logits.flatten(0, 1),\n",
      "                    target=target_ids.flatten(0, 1),\n",
      "                    reduction='none',\n",
      "                ).view_as(target_ids)\n",
      "                # not accurate if drop_last=False and micro_batch_size != 1\n",
      "                # see also PreprocessorBase.get_loss_mask comment in pipeline/data/preprocessors/preprocessor_base.py\n",
      "                loss = loss_per_token[loss_mask].mean() / self.gradient_accumulation_steps\n",
      "\n",
      "                self.grad_scaler.scale(loss).backward()\n",
      "\n",
      "                locals_copy = locals().copy()\n",
      "                locals_copy['trainer'] = locals_copy.pop('self')\n",
      "                [metric.micro_batch_update(**locals_copy) for metric in self.train_metrics.values()]\n",
      "                del locals_copy\n",
      "\n",
      "                pbar_accumulation.update()\n",
      "\n",
      "            if self.max_grad_norm != 0:\n",
      "                self.grad_scaler.unscale_(self.optimizer)\n",
      "                grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
      "\n",
      "            self.grad_scaler.step(self.optimizer)\n",
      "            self.grad_scaler.update()\n",
      "            self.optimizer.zero_grad(set_to_none=True)\n",
      "\n",
      "            log = Log(\n",
      "                iteration_number=iter_num + 1,\n",
      "                train_metrics={name: metric.batch_commit() for name, metric in self.train_metrics.items()},\n",
      "            )\n",
      "            if (iter_num + 1) % self.valid_freq == 0:\n",
      "                log['valid_metrics'] = self.validate(verbose)\n",
      "            self.logger.log(log)\n",
      "\n",
      "            if (iter_num + 1) % self.checkpointing_freq == 0:\n",
      "                self.checkpointer.save_checkpoint(Checkpoint(\n",
      "                    metrics=log,\n",
      "                    model=self.model,\n",
      "                    optimizer_state=self.optimizer.state_dict(),\n",
      "                ))\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/trainer_base.py\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class TrainerBase(ABC):\n",
      "    @abstractmethod\n",
      "    @torch.inference_mode\n",
      "    def validate(self, *args, **kwargs) -> dict[MetricName, MetricValue]:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def train(self, *args, **kwargs) -> None:\n",
      "        raise NotImplementedError\n",
      "\n",
      "# ../pipeline/trainers/trainers_registry.py\n",
      "from pipeline.trainers.full_finetuning_trainer import FullFineTuningTrainer\n",
      "\n",
      "TRAINERS_REGISTRY = {\n",
      "    'full_finetuning_trainer': FullFineTuningTrainer,\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# henceforth, only the composed context is shown for each composer\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e7e39-4175-4098-b891-33753c784f13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Declaration Only Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f5afd6-18b3-4710-95f5-5975e0e56f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ChainedComposer([\n",
    "    InclusiveFileExtensionFilter(whitelist=['.py']),  # include only .py files\n",
    "    DeclarationOnlyPreprocessor(),\n",
    "    FileGrainedChunker(),\n",
    "    RandomRanker(random_seed=42),\n",
    "    LexicographicSorter(),\n",
    "    PathCommentHarvester(chunks_sep='\\n\\n', path_comment_template='# {filename}\\n{content}'),\n",
    "],\n",
    "    **composer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d423e1e3-650f-4ca8-aad1-96b1171722a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ../pipeline/outputs/metrics/counters.py\n",
      "class EpochCounter(StatisticBase): ...\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T: ...\n",
      "    def __init__(self) -> None: ...\n",
      "    def reinit(self, init_epoch: float | None) -> None: ...\n",
      "    def micro_batch_update(self, input_ids: torch.Tensor, trainer: FullFineTuningTrainer, **_kwargs) -> None: ...\n",
      "    def batch_commit(self) -> StatisticValue: ...\n",
      "\n",
      "# ../pipeline/trainers/trainers_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/configs/model_config.py\n",
      "class ModelConfig(ConfigBase): ...\n",
      "    def __post_init__(self) -> None: ...\n",
      "\n",
      "# ../pipeline/data/composers/utils.py\n",
      "class ReprMixin: ...\n",
      "    def __init_subclass__(cls, **kwargs) -> None: ...\n",
      "        def wrapped_init(self, *init_args, **init_kwargs) -> None: ...\n",
      "    def __repr__(self) -> str: ...\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_harvesting.py\n",
      "class ChunkHarvester(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class JoiningHarvester(ChunkHarvester): ...\n",
      "    def __init__(self, chunks_sep: str) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> str: ...\n",
      "class PathCommentHarvester(JoiningHarvester): ...\n",
      "    def __init__(self, chunks_sep: str, path_comment_template: str) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> str: ...\n",
      "\n",
      "# ../pipeline/configs/checkpointer_config.py\n",
      "class CheckpointManagerConfig(ConfigBase): ...\n",
      "    def __post_init__(self) -> None: ...\n",
      "class TopKCheckpointManagerConfig(CheckpointManagerConfig): ...\n",
      "\n",
      "# ../pipeline/configs/config_base.py\n",
      "class ConfigBase: ...\n",
      "    def __str__(self) -> str: ...\n",
      "    def from_dict(cls: Type[T], dictionary: dict[str, Any]) -> T: ...\n",
      "    def from_yaml(cls: Type[T], path: str | None = None) -> T: ...\n",
      "\n",
      "# ../pipeline/trainers/utils/fused_sampler.py\n",
      "class FusedSampler(Sampler[int]): ...\n",
      "    def __init__(self,\n",
      "                 start_sample_idx: int,\n",
      "                 end_sample_idx: int,\n",
      "                 dataset_length: int,\n",
      "                 generator: torch.Generator | None = None,\n",
      "                 ) -> None: ...\n",
      "    def __iter__(self) -> Iterator[int]: ...\n",
      "    def __len__(self) -> int: ...\n",
      "\n",
      "# ../pipeline/configs/split_config.py\n",
      "class SplitConfig(ConfigBase): ...\n",
      "\n",
      "# ../pipeline/data/preprocessors/preprocessor_base.py\n",
      "class PreprocessedBatch(TypedDict): ...\n",
      "class PreprocessorBase(ABC): ...\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def get_category_ids(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch: ...\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_ranking.py\n",
      "class ChunkRanker(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class NegativePathDistanceRanker(ChunkRanker): ...\n",
      "    def _path_distance(path_from: str, path_to: str) -> int: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class FileExtensionRanker(ChunkRanker): ...\n",
      "    def __init__(self, ordered_groups: list[list[str]]) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class FunctionCallRanker(ChunkRanker): ...\n",
      "    def __init__(self, is_relative: bool) -> None: ...\n",
      "    def dfs_count(self, node: tree_sitter.Node) -> int: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class RandomRanker(ChunkRanker): ...\n",
      "    def __init__(self, random_seed: int | None) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "\n",
      "# ../pipeline/data/datapoint.py\n",
      "class CompletionFile(TypedDict): ...\n",
      "class CompletionLines(TypedDict, total=False): ...\n",
      "class RepoSnapshot(TypedDict): ...\n",
      "class Datapoint: ...\n",
      "class BatchDatapoint(TypedDict): ...\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/checkpointers_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/wandb_logger.py\n",
      "class WandbLogger(LocalLogger): ...\n",
      "    def __init__(self,\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 **wandb_init_kwargs,\n",
      "                 ) -> None: ...\n",
      "    def log(self, metrics: Log) -> Log: ...\n",
      "\n",
      "# ../pipeline/model/init.py\n",
      "class AttentionImplementation(str, Enum): ...\n",
      "def init_tokenizer(config: ModelConfig) -> PreTrainedTokenizerBase: ...\n",
      "def get_optimal_attn(model_name: str, device: torch.device, dtype: torch.dtype) -> AttentionImplementation: ...\n",
      "def init_model(config: ModelConfig) -> PreTrainedModel: ...\n",
      "def init_tokenizer_model(loaded_config: DictConfig, **kwargs) -> tuple[PreTrainedTokenizerBase, PreTrainedModel]: ...\n",
      "\n",
      "# ../pipeline/trainers/init.py\n",
      "def init_trainer(cls_name: str, loaded_config: DictConfig, **kwargs) -> TrainerBase: ...\n",
      "\n",
      "# ../pipeline/data/composed_datapoint.py\n",
      "class ComposedDatapoint(TypedDict): ...\n",
      "class BatchComposedDatapoint(TypedDict): ...\n",
      "\n",
      "# ../pipeline/trainers/full_finetuning_trainer.py\n",
      "class FullFineTuningTrainer(TrainerBase): ...\n",
      "    def __init__(self,\n",
      "                 model: PreTrainedModel,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 train_ds: Dataset,\n",
      "                 valid_ds: Dataset | None,\n",
      "                 # auxiliary objects\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 logger: LoggerBase,\n",
      "                 # iteration parameters\n",
      "                 max_iters: int,\n",
      "                 valid_freq: int | None,\n",
      "                 checkpointing_freq: int | None,\n",
      "                 gradient_accumulation_steps: int,\n",
      "                 micro_batch_size: int,\n",
      "                 # optimizer\n",
      "                 learning_rate: float,\n",
      "                 beta_1: float,\n",
      "                 beta_2: float,\n",
      "                 weight_decay: float,\n",
      "                 max_grad_norm: float,\n",
      "                 # scheduler\n",
      "                 warmup_iters: int | None,\n",
      "                 lr_decay_iters: int | None,\n",
      "                 min_lr: float | None,\n",
      "                 # metrics\n",
      "                 train_metrics: list[MetricName],\n",
      "                 train_ema_alpha: float,\n",
      "                 valid_metrics: list[MetricName],\n",
      "                 valid_ema_alpha: float | None,\n",
      "                 # DataLoader\n",
      "                 shuffle: bool,\n",
      "                 drop_last: bool,\n",
      "                 num_workers: int,\n",
      "                 prefetch_factor: int,\n",
      "                 random_seed: int | None,\n",
      "                 # Floating point\n",
      "                 fp32_matmul_precision: Literal['highest', 'high', 'medium'],\n",
      "                 ) -> None: ...\n",
      "    def _init_adamw(self,\n",
      "                    learning_rate: float,\n",
      "                    beta_1: float,\n",
      "                    beta_2: float,\n",
      "                    weight_decay: float,\n",
      "                    ) -> torch.optim.AdamW: ...\n",
      "    def validate(self, verbose: bool = True) -> dict[MetricName, MetricValue]: ...\n",
      "    def train(self, verbose: bool = True) -> None: ...\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/top_k_checkpointer.py\n",
      "class TopKCheckpointManager(CheckpointManager): ...\n",
      "    def __init__(self, max_checkpoints_num: int, *args, **kwargs) -> None: ...\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None: ...\n",
      "\n",
      "# ../pipeline/data/preprocessors/lm_preprocessor.py\n",
      "class LMPreprocessor(CompletionLossPreprocessor): ...\n",
      "    def get_loss_mask(self,\n",
      "                      _tokenized_completions: BatchEncoding,\n",
      "                      target_attn_mask: torch.Tensor,\n",
      "                      **_kwargs,\n",
      "                      ) -> torch.Tensor: ...\n",
      "\n",
      "# ../pipeline/data/preprocessors/file_level_preprocessor.py\n",
      "class FileLevelPreprocessor(CompletionLossPreprocessor): ...\n",
      "    def calc_lens(self,\n",
      "                  prompt: torch.Tensor,\n",
      "                  context: torch.Tensor,\n",
      "                  completion: torch.Tensor,\n",
      "                  ) -> tuple[int, int, int]: ...\n",
      "\n",
      "# ../pipeline/data/composers/blocks/context_postprocessing.py\n",
      "class ContextPostprocessor(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class PartialMemoryPostprocessor(ContextPostprocessor): ...\n",
      "    def __init__(self, dropout: float, random_seed: int | None) -> None: ...\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str: ...\n",
      "class LineLengthPostprocessor(ContextPostprocessor): ...\n",
      "    def __init__(self, min_len: int, max_len: int) -> None: ...\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str: ...\n",
      "class LineStripPostprocessor(ContextPostprocessor): ...\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str: ...\n",
      "class InverseFrequencyMemoryPostprocessor(ContextPostprocessor): ...\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str: ...\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_filtering.py\n",
      "class FileFilter(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class InclusiveFileExtensionFilter(FileFilter): ...\n",
      "    def __init__(self, whitelist: list[str]) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class ExclusiveFileExtensionFilter(FileFilter): ...\n",
      "    def __init__(self, blacklist: list[str]) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class EmptyFileFilter(FileFilter): ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class FileLengthFilter(FileFilter): ...\n",
      "    def __init__(self, min_len: int, max_len: int) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class TokenizedFileLengthFilter(FileFilter): ...\n",
      "    def __init__(self, tokenizer: PreTrainedTokenizerBase, min_len: int, max_len: int) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class CharTokenRatioFilter(FileFilter): ...\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 min_ratio: float,\n",
      "                 max_ratio: float,\n",
      "                 subsequence_len: int,\n",
      "                 random_seed: int | None,\n",
      "                 ) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "\n",
      "# ../pipeline/data/categories.py\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/cross_entropy.py\n",
      "class CrossEntropy(MetricBase): ...\n",
      "    def __init__(self) -> None: ...\n",
      "    def micro_batch_update(self, loss_per_token: torch.Tensor, mask: torch.Tensor, **_kwargs) -> None: ...\n",
      "    def batch_commit(self) -> MetricValue: ...\n",
      "\n",
      "# ../pipeline/outputs/metrics/metric_base.py\n",
      "class OptimizationMode(str, Enum): ...\n",
      "class MetricBase(StatisticBase, ABC): ...\n",
      "    def mode(self) -> OptimizationMode: ...\n",
      "def loss_based_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]: ...\n",
      "    class LossBasedMetric(metric_cls, ABC): ...\n",
      "        def micro_batch_update(self, **kwargs) -> None: ...\n",
      "def detached_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]: ...\n",
      "    class DetachedMetric(metric_cls, ABC): ...\n",
      "        def micro_batch_update(self, **kwargs) -> None: ...\n",
      "def completion_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]: ...\n",
      "    class FullMetric(metric_cls, ABC): ...\n",
      "        def micro_batch_update(self, **kwargs) -> None: ...\n",
      "def context_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]: ...\n",
      "    class FullMetric(metric_cls, ABC): ...\n",
      "        def micro_batch_update(self, **kwargs) -> None: ...\n",
      "def full_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]: ...\n",
      "    class FullMetric(metric_cls, ABC): ...\n",
      "        def micro_batch_update(self, **kwargs) -> None: ...\n",
      "def categorized_metric_factory(metric_cls: Type[MetricBase], category: CategoryType) -> Type[MetricBase]: ...\n",
      "    class CategorizedMetric(metric_cls, ABC): ...\n",
      "        def micro_batch_update(self, **kwargs) -> None: ...\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/init.py\n",
      "def init_checkpointer(cls_name: str, loaded_config: DictConfig, **kwargs) -> CheckpointManager: ...\n",
      "\n",
      "# ../pipeline/configs/logger_config.py\n",
      "class LocalLoggerConfig(ConfigBase): ...\n",
      "class WandbLoggerConfig(LocalLoggerConfig): ...\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/checkpointer.py\n",
      "class CheckpointManager: ...\n",
      "    def __init__(self,\n",
      "                 init_from: LoadingMode | str,\n",
      "                 main_metric: MetricName,\n",
      "                 directory: str,\n",
      "                 checkpoint_directory_template: str,\n",
      "                 extract_iteration_number: Callable[[str], int],\n",
      "                 model_subdirectory: str,\n",
      "                 optim_state_filename: str,\n",
      "                 metrics_filename: str,\n",
      "                 ) -> None: ...\n",
      "    def get_wandb_resume_mode(self) -> Literal['allow', 'never'] | None: ...\n",
      "    def load_metrics(self, checkpoint_dir: str) -> Log: ...\n",
      "    def get_checkpoint_score(self, checkpoint_dir: str) -> MetricValue: ...\n",
      "    def get_checkpoint_directory(self) -> str | None: ...\n",
      "    def get_iteration_number(self) -> int: ...\n",
      "    def get_model_subdirectory(self) -> str | None: ...\n",
      "    def init_optimizer(self, optimizer: torch.optim.AdamW) -> None: ...\n",
      "    def init_metrics(self,\n",
      "                     group: Literal['train_metrics', 'valid_metrics'],\n",
      "                     metrics: list[MetricName],\n",
      "                     ema_alpha: float,\n",
      "                     ) -> dict[MetricName, MetricBase]: ...\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None: ...\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_preprocessing.py\n",
      "class FilePreprocessor(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class EmptyLinesRemovalPreprocessor(FilePreprocessor): ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class DeclarationOnlyPreprocessor(FilePreprocessor): ...\n",
      "    def __init__(self) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[File]: ...\n",
      "\n",
      "# ../pipeline/data/composers/chained_composer.py\n",
      "class ChainedComposer(ComposerBase, ComposerChain, ReprMixin): ...\n",
      "    def __init__(self, blocks: Sequence[ComposerBlock], *args, **kwargs) -> None: ...\n",
      "    def compose_context(self, datapoint: Datapoint) -> str: ...\n",
      "\n",
      "# ../pipeline/data/composers/chain.py\n",
      "class File: ...\n",
      "class Chunk: ...\n",
      "class ComposerBlock(ABC, ReprMixin): ...\n",
      "    def next_blocks(self) -> tuple[type, ...]: ...\n",
      "    def check_next_block(self, block) -> None: ...\n",
      "    def __call__(self, args: BlockArgs, datapoint: Datapoint) -> BlockArgs | str: ...\n",
      "class ComposerChain: ...\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None: ...\n",
      "    def __call__(self, datapoint: Datapoint) -> str: ...\n",
      "\n",
      "# ../pipeline/outputs/loggers/logger_base.py\n",
      "class Log(TypedDict): ...\n",
      "class LoggerBase(ABC): ...\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T: ...\n",
      "    def log(self, metrics: Log) -> Log: ...\n",
      "    def message(self, message: Message) -> Message: ...\n",
      "\n",
      "# ../pipeline/data/preprocessors/completion_loss_preprocessor.py\n",
      "class CompletionLossPreprocessor(PreprocessorBase): ...\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 max_seq_len: int,\n",
      "                 context_tokens: int | float,\n",
      "                 loss_ratio: float,\n",
      "                 num_chars_per_token: int,\n",
      "                 padding: bool,\n",
      "                 verbose: bool,\n",
      "                 ) -> None: ...\n",
      "    def _inc_num_chars_per_token(self) -> None: ...\n",
      "    def tokenize_pre_context_prompt(self, prompts: list[str]) -> BatchEncoding: ...\n",
      "    def tokenize_composed_completion(self, completions: list[str]) -> BatchEncoding: ...\n",
      "    def tokenize_composed_context(self, contexts: list[str]) -> BatchEncoding: ...\n",
      "    def calc_lens(self,\n",
      "                  prompt: torch.Tensor,\n",
      "                  context: torch.Tensor,\n",
      "                  completion: torch.Tensor,\n",
      "                  ) -> tuple[int, int, int]: ...\n",
      "    def _get_partial_completion_mask(tokenized_completions: BatchEncoding,\n",
      "                                     target_attn_mask: torch.Tensor,\n",
      "                                     ratio: float,\n",
      "                                     ) -> torch.Tensor: ...\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def get_category_ids(tokenized_completions: BatchEncoding,\n",
      "                         completion_lines: list[CompletionLines],\n",
      "                         target_attn_mask: torch.Tensor,\n",
      "                         ) -> torch.Tensor: ...\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch: ...\n",
      "\n",
      "# ../pipeline/configs/preprocessor_config.py\n",
      "class PreprocessorConfig(ConfigBase): ...\n",
      "\n",
      "# ../pipeline/outputs/loggers/dummy_logger.py\n",
      "class DummyLogger(LoggerBase): ...\n",
      "    def __init__(self, *_args, **_kwargs) -> None: ...\n",
      "    def log(self, metrics: Log) -> Log: ...\n",
      "    def message(self, message: Message) -> Message: ...\n",
      "\n",
      "# ../pipeline/data/composers/composer_base.py\n",
      "class ComposerBase(ABC): ...\n",
      "    def __init__(self,\n",
      "                 pre_context_prompt: str,\n",
      "                 post_context_prompt: str,\n",
      "                 path_comment_template: str,\n",
      "                 recalculate_random_category: bool,\n",
      "                 ) -> None: ...\n",
      "    def get_pre_context_prompt(self, datapoint: Datapoint) -> str: ...\n",
      "    def get_post_context_prompt(self, _datapoint: Datapoint) -> str: ...\n",
      "    def compose_context(self, datapoint: Datapoint) -> str: ...\n",
      "    def compose_completion(self, datapoint: Datapoint) -> str: ...\n",
      "    def compose(self, datapoint: dict[str, Any]) -> ComposedDatapoint: ...\n",
      "    def compose_batch(self, batch: BatchDatapoint) -> BatchComposedDatapoint: ...\n",
      "    def compose_dataset(self,\n",
      "                        dataset: Dataset,\n",
      "                        writer_batch_size: int = 128,\n",
      "                        num_proc: int = 4,\n",
      "                        **map_kwargs,\n",
      "                        ) -> Dataset: ...\n",
      "\n",
      "# ../pipeline/configs/composer_config.py\n",
      "class ChainedComposerConfig(ConfigBase): ...\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/data_structures.py\n",
      "class LoadingMode(str, Enum): ...\n",
      "class Checkpoint: ...\n",
      "\n",
      "# ../pipeline/data/composers/blocks/blocks_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/utils/schedulers.py\n",
      "def get_lr_from_cosine_scheduler_with_linear_warmup(iter_num: int,\n",
      "                                                    min_lr: float,\n",
      "                                                    max_lr: float,\n",
      "                                                    warmup_iters: int,\n",
      "                                                    lr_decay_iters: int,\n",
      "                                                    ) -> float: ...\n",
      "\n",
      "# ../pipeline/outputs/loggers/local_logger.py\n",
      "class JsonFormatter(logging.Formatter): ...\n",
      "    def format(self, record: logging.LogRecord) -> str: ...\n",
      "class JsonHandler(logging.FileHandler): ...\n",
      "    def emit(self, record: logging.LogRecord) -> None: ...\n",
      "    def close(self) -> None: ...\n",
      "class LocalLogger(LoggerBase): ...\n",
      "    def __init__(self,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 ) -> None: ...\n",
      "    def write_metrics_to_csv(metrics: dict[MetricName, MetricValue], path: str) -> None: ...\n",
      "    def log(self, metrics: Log) -> Log: ...\n",
      "    def message(self, message: Message) -> Message: ...\n",
      "    def warning_handler(self, message: Warning, category: type, path: str, lineno: int, *_kwargs) -> None: ...\n",
      "    def exception_handler(self, exc_type: type, exc_value: Exception, exc_traceback: TracebackType) -> NoReturn: ...\n",
      "\n",
      "# ../pipeline/data/composers/composers_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/configs/dataset_config.py\n",
      "class DatasetConfig(ConfigBase): ...\n",
      "\n",
      "# ../pipeline/environment/hardware.py\n",
      "def get_free_device(used_memory_upper_bound: float = 0.001) -> torch.device: ...\n",
      "def get_optimal_dtype() -> torch.dtype: ...\n",
      "\n",
      "# ../pipeline/outputs/loggers/loggers_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/init.py\n",
      "def init_composer(cls_name: str,\n",
      "                  loaded_config: DictConfig,\n",
      "                  configs_dir: str,\n",
      "                  tokenizer: PreTrainedTokenizerBase,\n",
      "                  **kwargs,\n",
      "                  ) -> ComposerBase: ...\n",
      "\n",
      "# ../pipeline/trainers/trainer_base.py\n",
      "class TrainerBase(ABC): ...\n",
      "    def validate(self, *args, **kwargs) -> dict[MetricName, MetricValue]: ...\n",
      "    def train(self, *args, **kwargs) -> None: ...\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_sorting.py\n",
      "class ChunkSorter(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class LexicographicSorter(ChunkSorter): ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "\n",
      "# ../pipeline/outputs/metrics/statistic_base.py\n",
      "class StatisticBase(ABC): ...\n",
      "    def reinit(self, prev_value: StatisticValue | None) -> None: ...\n",
      "    def micro_batch_update(self, **kwargs) -> None: ...\n",
      "    def batch_commit(self) -> StatisticValue: ...\n",
      "def ema_factory(statistic_cls: Type[StatisticBase]) -> Type[StatisticBase]: ...\n",
      "    class EMAStatistic(statistic_cls, ABC): ...\n",
      "        def __init__(self, ema_alpha: float) -> None: ...\n",
      "        def reinit(self, ema_state: float | None) -> None: ...\n",
      "        def batch_commit(self) -> StatisticValue: ...\n",
      "def lazy_statistic_factory(statistic_name: str) -> Type[StatisticBase]: ...\n",
      "    class LazyStatistic(StatisticBase): ...\n",
      "        def __init__(self) -> None: ...\n",
      "        def micro_batch_update(self, **kwargs) -> None: ...\n",
      "        def batch_commit(self) -> StatisticValue: ...\n",
      "\n",
      "# ../pipeline/outputs/metrics/metrics_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/init.py\n",
      "def init_logger(cls_name: str, loaded_config: DictConfig, **kwargs) -> LoggerBase: ...\n",
      "\n",
      "# ../pipeline/data/dataset.py\n",
      "def train_test_split(dataset: Dataset,\n",
      "                     test_size: int,\n",
      "                     upper_bound_per_repo: int,\n",
      "                     random_seed: int | None = None,\n",
      "                     ) -> tuple[Dataset, Dataset | None]: ...\n",
      "def set_transform(train_ds: Dataset,\n",
      "                  test_ds: Dataset | None,\n",
      "                  composer: ComposerBase,\n",
      "                  preprocessor: PreprocessorBase,\n",
      "                  ) -> None: ...\n",
      "\n",
      "# ../pipeline/data/preprocessors/init.py\n",
      "def init_preprocessor(cls_name: str, loaded_config: DictConfig, **kwargs) -> PreprocessorBase: ...\n",
      "\n",
      "# ../pipeline/configs/trainer_config.py\n",
      "class FullFineTuningTrainerConfig(ConfigBase): ...\n",
      "\n",
      "# ../pipeline/configs/configs_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/preprocessors_registry.py\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_chunking.py\n",
      "class FileChunker(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class FileGrainedChunker(FileChunker): ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class CodeSegment(str, Enum): ...\n",
      "    def from_node(cls: Type[T], node: tree_sitter.Node) -> T: ...\n",
      "class Segment(NamedTuple): ...\n",
      "class CodeSegmentGrainedChunker(FileChunker): ...\n",
      "    def __init__(self) -> None: ...\n",
      "    def dfs_segmentation(root_node: tree_sitter.Node) -> list[Segment]: ...\n",
      "    def strip_lines(string: str, strip_func: Callable[[str], str]) -> str: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca8b5c4-b67d-4e9d-a8da-7fc44d34b616",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Double Ranking Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcf95b6e-5b14-4946-aa69-95ad3448d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ChainedComposer([\n",
    "    FileLengthFilter(min_len=100, max_len=float('inf')),\n",
    "    EmptyLinesRemovalPreprocessor(),\n",
    "    CodeSegmentGrainedChunker(),\n",
    "    FunctionCallRanker(is_relative=True),  # first sort criterion\n",
    "    NegativePathDistanceRanker(),  # second sort criterion\n",
    "    LexicographicSorter(),\n",
    "    JoiningHarvester(chunks_sep='\\n--------------- NEW FILE ---------------\\n'),\n",
    "],\n",
    "    **composer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ca759e2-bf26-4577-96dc-53512b8a6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "# AdamW optimizer\n",
      "learning_rate: 7.0e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 25\n",
      "lr_decay_iters: 600\n",
      "min_lr: 1.0e-7\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "--------------- NEW FILE ---------------\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 32\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "--------------- NEW FILE ---------------\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "--------------- NEW FILE ---------------\n",
      "# Iteration parameters\n",
      "max_iters: 20\n",
      "valid_freq: 5\n",
      "checkpointing_freq: null\n",
      "gradient_accumulation_steps: 16\n",
      "micro_batch_size: 1\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: ''\n",
      "post_context_prompt: ''\n",
      "path_comment_template: '{content}'\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/empty.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/file_length_filter/0_20k.yaml,\n",
      "  file_preprocessing/empty_lines_removal_preprocessor/no_args.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  context_postprocessing/line_strip_postprocessor/no_args.yaml,\n",
      "  context_postprocessing/line_length_postprocessor/10_200.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "  file_preprocessing/declaration_only_preprocessor/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/random_ranker/1337.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/char_token_ratio_filter/1p5_inf.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/relative.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  context_postprocessing/line_strip_postprocessor/no_args.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "  file_preprocessing/declaration_only_preprocessor/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  context_postprocessing/partial_memory_postprocessor/half_memory.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/file_extension_ranker/text_files.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "--------------- NEW FILE ---------------\n",
      "train_csv: train.csv\n",
      "valid_csv: valid.csv\n",
      "stdout_file: stdout.json\n",
      "stderr_file: stderr.json\n",
      "project: LCA Context Composers\n",
      "--------------- NEW FILE ---------------\n",
      "# TODO concerns:\n",
      "# 1. L1 or softmax normalization?\n",
      "# 2. Equivalence groups by line.strip() transformation?\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "import random\n",
      "from abc import ABC\n",
      "from typing import Type\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "from pipeline.data.composers.blocks.context_postprocessing import ContextPostprocessor\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import File, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "import warnings\n",
      "from pipeline.data.composers.blocks.file_chunking import FileChunker\n",
      "        from pipeline.data.composers.blocks.file_filtering import FileFilter\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "import os\n",
      "import random\n",
      "import warnings\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "from pipeline.data.composers.blocks.chunk_sorting import ChunkSorter\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import (\n",
      "    JoiningHarvester,\n",
      "    PathCommentHarvester,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_ranking import (\n",
      "    NegativePathDistanceRanker,\n",
      "    FunctionCallRanker,\n",
      "    FileExtensionRanker,\n",
      "    RandomRanker,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_sorting import (\n",
      "    LexicographicSorter,\n",
      ")\n",
      "from pipeline.data.composers.blocks.context_postprocessing import (\n",
      "    PartialMemoryPostprocessor,\n",
      "    LineLengthPostprocessor,\n",
      "    LineStripPostprocessor,\n",
      "    InverseFrequencyMemoryPostprocessor,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_chunking import (\n",
      "    FileGrainedChunker,\n",
      "    CodeSegmentGrainedChunker,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_filtering import (\n",
      "    InclusiveFileExtensionFilter,\n",
      "    ExclusiveFileExtensionFilter,\n",
      "    EmptyFileFilter,\n",
      "    FileLengthFilter,\n",
      "    TokenizedFileLengthFilter,\n",
      "    CharTokenRatioFilter,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_preprocessing import (\n",
      "    EmptyLinesRemovalPreprocessor,\n",
      "    DeclarationOnlyPreprocessor,\n",
      ")\n",
      "--------------- NEW FILE ---------------\n",
      "BLOCKS_REGISTRY = {\n",
      "    'inclusive_file_extension_filter': InclusiveFileExtensionFilter,\n",
      "    'exclusive_file_extension_filter': ExclusiveFileExtensionFilter,\n",
      "    'empty_file_filter': EmptyFileFilter,\n",
      "    'file_length_filter': FileLengthFilter,\n",
      "    'tokenized_file_length_filter': TokenizedFileLengthFilter,\n",
      "    'char_token_ratio_filter': CharTokenRatioFilter,\n",
      "    'empty_lines_removal_preprocessor': EmptyLinesRemovalPreprocessor,\n",
      "    'declaration_only_preprocessor': DeclarationOnlyPreprocessor,\n",
      "    'file_grained_chunker': FileGrainedChunker,\n",
      "    'code_segment_grained_chunker': CodeSegmentGrainedChunker,\n",
      "    'negative_path_distance_ranker': NegativePathDistanceRanker,\n",
      "    'function_call_ranker': FunctionCallRanker,\n",
      "    'file_extension_ranker': FileExtensionRanker,\n",
      "    'random_ranker': RandomRanker,\n",
      "    'lexicographic_sorter': LexicographicSorter,\n",
      "    'joining_harvester': JoiningHarvester,\n",
      "    'path_comment_harvester': PathCommentHarvester,\n",
      "    'partial_memory_postprocessor': PartialMemoryPostprocessor,\n",
      "    'line_length_postprocessor': LineLengthPostprocessor,\n",
      "    'line_strip_postprocessor': LineStripPostprocessor,\n",
      "    'inverse_frequency_memory_postprocessor': InverseFrequencyMemoryPostprocessor,\n",
      "}\n",
      "--------------- NEW FILE ---------------\n",
      "# N.B. this algorithm does NOT preserve the uniformity of token sampling\n",
      "# only the uniformity of subsequences\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import File, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "import random\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "from pipeline.data.composers.blocks.file_chunking import FileChunker\n",
      "        from pipeline.data.composers.blocks.file_preprocessing import FilePreprocessor\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import File, Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from abc import ABC\n",
      "from enum import Enum\n",
      "from string import whitespace\n",
      "from typing import Callable, NamedTuple, Sequence, TypeVar, Type\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "        from pipeline.data.composers.blocks.chunk_ranking import ChunkRanker\n",
      "--------------- NEW FILE ---------------\n",
      "tokenizer_name: deepseek-ai/deepseek-coder-1.3b-base\n",
      "model_name: deepseek-ai/deepseek-coder-1.3b-base\n",
      "trust_remote_code: True\n",
      "compile: False\n",
      "--------------- NEW FILE ---------------\n",
      "path: JetBrains-Research/lca-codegen-train\n",
      "data_dir: train\n",
      "split: train\n",
      "cache_dir: /mnt/data2/shared-data/lca/hf_cache/\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessorBase\n",
      "from pipeline.data.preprocessors.preprocessors_registry import PREPROCESSORS_REGISTRY\n",
      "from omegaconf import DictConfig\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "from pipeline.data.preprocessors.file_level_preprocessor import FileLevelPreprocessor\n",
      "from pipeline.data.preprocessors.lm_preprocessor import LMPreprocessor\n",
      "--------------- NEW FILE ---------------\n",
      "PREPROCESSORS_REGISTRY = {\n",
      "    'completion_loss_preprocessor': CompletionLossPreprocessor,\n",
      "    'file_level_preprocessor': FileLevelPreprocessor,\n",
      "    'lm_preprocessor': LMPreprocessor,\n",
      "}\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.categories import CATEGORY2ID, UNDEFINED_CATEGORY_ID\n",
      "from pipeline.data.composed_datapoint import BatchComposedDatapoint\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessedBatch, PreprocessorBase\n",
      "import math\n",
      "import re\n",
      "import warnings\n",
      "import torch\n",
      "from transformers import BatchEncoding, PreTrainedTokenizerBase\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "import torch\n",
      "from transformers import BatchEncoding\n",
      "--------------- NEW FILE ---------------\n",
      "\"\"\"\n",
      "Important note: different number of masked tokens in different\n",
      "micro-batches will break gradient accumulation, in which case\n",
      "the training loop should include corresponding gradient scaling.\n",
      "*or we just don't care :)\n",
      "\"\"\"\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composed_datapoint import BatchComposedDatapoint\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "class PreprocessedBatch(TypedDict):\n",
      "    input_ids: torch.Tensor\n",
      "    target_ids: torch.Tensor\n",
      "    loss_mask: torch.Tensor\n",
      "    completion_mask: torch.Tensor\n",
      "    category_ids: torch.Tensor\n",
      "    input_attn_mask: torch.Tensor\n",
      "    target_attn_mask: torch.Tensor\n",
      "class PreprocessorBase(ABC):\n",
      "    @abstractmethod\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        raise NotImplementedError\n",
      "    @abstractmethod\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        raise NotImplementedError\n",
      "    @abstractmethod\n",
      "    def get_category_ids(self, *args, **kwargs) -> torch.Tensor:\n",
      "        raise NotImplementedError\n",
      "    @abstractmethod\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "        raise NotImplementedError\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.data.composers.blocks.blocks_registry import BLOCKS_REGISTRY\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.composers.composers_registry import COMPOSERS_REGISTRY\n",
      "import os\n",
      "import yaml\n",
      "from omegaconf import DictConfig\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from pipeline.data.composers.utils import ReprMixin\n",
      "from abc import ABC, abstractmethod\n",
      "from dataclasses import dataclass, field\n",
      "from typing import Any, Sequence\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composed_datapoint import ComposedDatapoint, BatchComposedDatapoint\n",
      "from pipeline.data.datapoint import Datapoint, BatchDatapoint\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any\n",
      "from datasets import Dataset\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chain import ComposerBlock, ComposerChain\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.composers.utils import ReprMixin\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from typing import Sequence\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.chained_composer import ChainedComposer\n",
      "--------------- NEW FILE ---------------\n",
      "COMPOSERS_REGISTRY = {\n",
      "    'chained_composer': ChainedComposer,\n",
      "}\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.metrics.metric_base import MetricValue, OptimizationMode, MetricBase\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticBase\n",
      "from typing import TypeVar, Type\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Type\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.categories import CategoryType, CATEGORY2ID\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticBase\n",
      "from abc import ABC, abstractmethod\n",
      "from enum import Enum\n",
      "from typing import Type\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.metrics.cross_entropy import CrossEntropy\n",
      "from pipeline.outputs.metrics.metric_base import (\n",
      "    loss_based_metric_factory,\n",
      "    detached_metric_factory,\n",
      "    completion_metric_factory,\n",
      "    context_metric_factory,\n",
      "    full_metric_factory,\n",
      "    categorized_metric_factory,\n",
      ")\n",
      "from pipeline.outputs.metrics.statistic_base import ema_factory, lazy_statistic_factory\n",
      "from pipeline.outputs.metrics.counters import EpochCounter\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.checkpointers.data_structures import Checkpoint\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "import os\n",
      "import shutil\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.checkpointers.data_structures import LoadingMode, Checkpoint\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue, OptimizationMode, MetricBase\n",
      "from pipeline.outputs.metrics.metrics_registry import METRICS_REGISTRY\n",
      "import json\n",
      "import os\n",
      "import warnings\n",
      "from typing import Callable, Literal\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "from dataclasses import dataclass\n",
      "from enum import Enum\n",
      "from transformers import PreTrainedModel\n",
      "--------------- NEW FILE ---------------\n",
      "class LoadingMode(str, Enum):\n",
      "    SCRATCH = 'scratch'\n",
      "    RESUME = 'resume'\n",
      "    BEST = 'best'\n",
      "@dataclass\n",
      "class Checkpoint:\n",
      "    metrics: Log\n",
      "    model: PreTrainedModel\n",
      "    optimizer_state: dict\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.checkpointers_registry import CHECKPOINTERS_REGISTRY\n",
      "from omegaconf import DictConfig\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.top_k_checkpointer import TopKCheckpointManager\n",
      "--------------- NEW FILE ---------------\n",
      "CHECKPOINTERS_REGISTRY = {\n",
      "    'checkpointer': CheckpointManager,\n",
      "    'top_k_checkpointer': TopKCheckpointManager,\n",
      "}\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "--------------- NEW FILE ---------------\n",
      "class DummyLogger(LoggerBase):\n",
      "    def __init__(self, *_args, **_kwargs) -> None:\n",
      "        pass\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        return metrics\n",
      "    def message(self, message: Message) -> Message:\n",
      "        return message\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "import csv\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import sys\n",
      "import traceback\n",
      "import warnings\n",
      "from types import TracebackType\n",
      "from typing import NoReturn\n",
      "import datasets.utils.logging\n",
      "import transformers.utils.logging\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict, TypeVar, Type\n",
      "from typing_extensions import NotRequired\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.outputs.loggers.logger_base import LoggerBase\n",
      "from pipeline.outputs.loggers.loggers_registry import LOGGERS_REGISTRY\n",
      "from omegaconf import DictConfig\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "import wandb\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.loggers.dummy_logger import DummyLogger\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.wandb_logger import WandbLogger\n",
      "--------------- NEW FILE ---------------\n",
      "LOGGERS_REGISTRY = {\n",
      "    'dummy': DummyLogger,\n",
      "    'local': LocalLogger,\n",
      "    'wandb': WandbLogger,\n",
      "}\n",
      "--------------- NEW FILE ---------------\n",
      "import math\n",
      "from typing import Iterator\n",
      "import torch\n",
      "from torch.utils.data import Sampler\n",
      "--------------- NEW FILE ---------------\n",
      "import math\n",
      "--------------- NEW FILE ---------------\n",
      "run_name: ???\n",
      "defaults:\n",
      "  - checkpointer: top_k_checkpointer/top_3\n",
      "  - composer: chained_composer/standard\n",
      "  - dataset: train_A100_server\n",
      "  - logger: wandb/wandb\n",
      "  - model: dseek1p3\n",
      "  - preprocessor: completion_loss_preprocessor/full_completion_loss_16k\n",
      "  - split: '256_5'\n",
      "  - trainer: full_finetuning_trainer/medium_lr\n",
      "  - _self_\n",
      "  - override hydra/hydra_logging: disabled\n",
      "  - override hydra/job_logging: disabled\n",
      "hydra:\n",
      "  output_subdir: null\n",
      "  run:\n",
      "    dir: .\n",
      "--------------- NEW FILE ---------------\n",
      "import subprocess\n",
      "import warnings\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "from typing import Literal\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessorBase\n",
      "import random\n",
      "from collections import defaultdict\n",
      "from datasets import Dataset\n",
      "--------------- NEW FILE ---------------\n",
      "from dataclasses import dataclass\n",
      "from typing import TypedDict\n",
      "--------------- NEW FILE ---------------\n",
      "class CompletionFile(TypedDict):\n",
      "    filename: str\n",
      "    content: str\n",
      "class CompletionLines(TypedDict, total=False):\n",
      "    commited: list[int]\n",
      "    common: list[int]\n",
      "    infile: list[int]\n",
      "    inproject: list[int]\n",
      "    non_informative: list[int]\n",
      "    random: list[int]\n",
      "    other: list[int]\n",
      "class RepoSnapshot(TypedDict):\n",
      "    filename: list[str]\n",
      "    content: list[str]\n",
      "@dataclass\n",
      "class Datapoint:\n",
      "    repo: str\n",
      "    commit_hash: str\n",
      "    completion_file: CompletionFile\n",
      "    completion_lines: CompletionLines\n",
      "    repo_snapshot: RepoSnapshot\n",
      "    completion_lines_raw: CompletionLines | None = None\n",
      "class BatchDatapoint(TypedDict):\n",
      "    repo: list[str]\n",
      "    commit_hash: list[str]\n",
      "    completion_file: list[CompletionFile]\n",
      "    completion_lines: list[CompletionLines]\n",
      "    repo_snapshot: list[RepoSnapshot]\n",
      "    completion_lines_raw: list[CompletionLines]\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "from typing import TypedDict\n",
      "--------------- NEW FILE ---------------\n",
      "class ComposedDatapoint(TypedDict):\n",
      "    pre_context_prompt: str\n",
      "    composed_context: str\n",
      "    composed_completion: str\n",
      "    completion_lines: CompletionLines\n",
      "class BatchComposedDatapoint(TypedDict):\n",
      "    pre_context_prompt: list[str]\n",
      "    composed_context: list[str]\n",
      "    composed_completion: list[str]\n",
      "    completion_lines: list[CompletionLines]\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.checkpointer_config import (\n",
      "    CheckpointManagerConfig,\n",
      "    TopKCheckpointManagerConfig,\n",
      ")\n",
      "from pipeline.configs.composer_config import ChainedComposerConfig\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.configs.logger_config import (\n",
      "    LocalLoggerConfig,\n",
      "    WandbLoggerConfig,\n",
      ")\n",
      "from pipeline.configs.preprocessor_config import PreprocessorConfig\n",
      "from pipeline.configs.trainer_config import FullFineTuningTrainerConfig\n",
      "--------------- NEW FILE ---------------\n",
      "CONFIGS_REGISTRY = {\n",
      "    'checkpointer': CheckpointManagerConfig,\n",
      "    'top_k_checkpointer': TopKCheckpointManagerConfig,\n",
      "    'dummy': ConfigBase,\n",
      "    'local': LocalLoggerConfig,\n",
      "    'wandb': WandbLoggerConfig,\n",
      "    'chained_composer': ChainedComposerConfig,\n",
      "    'completion_loss_preprocessor': PreprocessorConfig,\n",
      "    'file_level_preprocessor': PreprocessorConfig,\n",
      "    'lm_preprocessor': PreprocessorConfig,\n",
      "    'full_finetuning_trainer': FullFineTuningTrainerConfig,\n",
      "}\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from dataclasses import dataclass\n",
      "from typing import Literal\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from dataclasses import dataclass\n",
      "from typing import Any\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class LocalLoggerConfig(ConfigBase):\n",
      "    train_csv: str\n",
      "    valid_csv: str\n",
      "    stdout_file: str\n",
      "    stderr_file: str\n",
      "    directory: str\n",
      "@dataclass\n",
      "class WandbLoggerConfig(LocalLoggerConfig):\n",
      "    checkpointer: CheckpointManager\n",
      "    project: str\n",
      "    name: str\n",
      "    config: dict[str, Any] | None = None\n",
      "    group: str | None = None\n",
      "    notes: str | None = None\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "from dataclasses import dataclass, field\n",
      "from typing import Sequence\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.data_structures import LoadingMode\n",
      "from pipeline.outputs.metrics.metric_base import MetricName\n",
      "from dataclasses import dataclass\n",
      "from typing import Callable\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from dataclasses import dataclass\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class PreprocessorConfig(ConfigBase):\n",
      "    tokenizer: PreTrainedTokenizerBase\n",
      "    max_seq_len: int\n",
      "    context_tokens: int | float\n",
      "    loss_ratio: float\n",
      "    num_chars_per_token: int\n",
      "    padding: bool\n",
      "    verbose: bool = True\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from dataclasses import dataclass\n",
      "from datasets import config\n",
      "--------------- NEW FILE ---------------\n",
      "from dataclasses import asdict, dataclass, fields\n",
      "from pprint import pformat\n",
      "from typing import Any, TypeVar, Type\n",
      "import yaml\n",
      "--------------- NEW FILE ---------------\n",
      "# if None, will be calculated as 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "# DataLoader\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.logger_base import LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName\n",
      "from dataclasses import dataclass\n",
      "from typing import Literal\n",
      "from datasets import Dataset\n",
      "from transformers import PreTrainedModel, PreTrainedTokenizerBase\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class FullFineTuningTrainerConfig(ConfigBase):\n",
      "    model: PreTrainedModel\n",
      "    tokenizer: PreTrainedTokenizerBase\n",
      "    train_ds: Dataset\n",
      "    valid_ds: Dataset | None\n",
      "    checkpointer: CheckpointManager\n",
      "    logger: LoggerBase\n",
      "    max_iters: int\n",
      "    valid_freq: int | None\n",
      "    checkpointing_freq: int | None\n",
      "    gradient_accumulation_steps: int\n",
      "    micro_batch_size: int\n",
      "    learning_rate: float\n",
      "    beta_1: float\n",
      "    beta_2: float\n",
      "    weight_decay: float\n",
      "    max_grad_norm: float\n",
      "    warmup_iters: int | None\n",
      "    lr_decay_iters: int | None\n",
      "    min_lr: float | None\n",
      "    train_metrics: list[MetricName]\n",
      "    train_ema_alpha: float\n",
      "    valid_metrics: list[MetricName]\n",
      "    valid_ema_alpha: float | None\n",
      "    shuffle: bool\n",
      "    drop_last: bool\n",
      "    num_workers: int\n",
      "    prefetch_factor: int | None\n",
      "    random_seed: int | None\n",
      "    fp32_matmul_precision: Literal['highest', 'high', 'medium']\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from dataclasses import dataclass\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class SplitConfig(ConfigBase):\n",
      "    test_size: int\n",
      "    upper_bound_per_repo: int\n",
      "    random_seed: int | None\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.model_config import ModelConfig\n",
      "from pipeline.environment.hardware import get_free_device, get_optimal_dtype\n",
      "from enum import Enum\n",
      "import torch\n",
      "from omegaconf import DictConfig\n",
      "from transformers.models.auto import MODEL_FOR_CAUSAL_LM_MAPPING\n",
      "from transformers.utils import is_flash_attn_2_available, is_torch_sdpa_available\n",
      "from transformers import (\n",
      "    AutoTokenizer,\n",
      "    AutoModelForCausalLM,\n",
      "    AutoConfig,\n",
      "    PreTrainedModel,\n",
      "    PreTrainedTokenizerBase,\n",
      ")\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.trainers_registry import TRAINERS_REGISTRY\n",
      "from omegaconf import DictConfig\n",
      "--------------- NEW FILE ---------------\n",
      "# not accurate if drop_last=False and micro_batch_size != 1\n",
      "# see also PreprocessorBase.get_loss_mask comment in pipeline/data/preprocessors/preprocessor_base.py\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.data_structures import Checkpoint\n",
      "from pipeline.outputs.loggers.logger_base import Log, LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.utils.fused_sampler import FusedSampler\n",
      "from pipeline.trainers.utils.schedulers import get_lr_from_cosine_scheduler_with_linear_warmup\n",
      "import warnings\n",
      "from functools import partial\n",
      "from typing import Literal\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from datasets import Dataset\n",
      "from torch.utils.data import DataLoader\n",
      "from tqdm.auto import trange, tqdm\n",
      "from transformers import PreTrainedModel, PreTrainedTokenizerBase\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "from abc import ABC, abstractmethod\n",
      "import torch\n",
      "--------------- NEW FILE ---------------\n",
      "class TrainerBase(ABC):\n",
      "    @abstractmethod\n",
      "    @torch.inference_mode\n",
      "    def validate(self, *args, **kwargs) -> dict[MetricName, MetricValue]:\n",
      "        raise NotImplementedError\n",
      "    @abstractmethod\n",
      "    def train(self, *args, **kwargs) -> None:\n",
      "        raise NotImplementedError\n",
      "--------------- NEW FILE ---------------\n",
      "from pipeline.trainers.full_finetuning_trainer import FullFineTuningTrainer\n",
      "--------------- NEW FILE ---------------\n",
      "TRAINERS_REGISTRY = {\n",
      "    'full_finetuning_trainer': FullFineTuningTrainer,\n",
      "}\n",
      "--------------- NEW FILE ---------------\n",
      "def get_lr_from_cosine_scheduler_with_linear_warmup(iter_num: int,\n",
      "                                                    min_lr: float,\n",
      "                                                    max_lr: float,\n",
      "                                                    warmup_iters: int,\n",
      "                                                    lr_decay_iters: int,\n",
      "                                                    ) -> float:\n",
      "    if iter_num < warmup_iters:\n",
      "        return max_lr * (iter_num + 1) / warmup_iters\n",
      "    elif iter_num > lr_decay_iters:\n",
      "        return min_lr\n",
      "    else:\n",
      "        decay_ratio = (iter_num - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
      "        return min_lr + (max_lr - min_lr) / 2 * (1 + math.cos(math.pi * decay_ratio))\n",
      "--------------- NEW FILE ---------------\n",
      "class ChunkSorter(ComposerBlock, ABC):\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return ChunkSorter, ChunkHarvester\n",
      "class LexicographicSorter(ChunkSorter):\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        return sorted(chunks, key=lambda c: c.rank)\n",
      "--------------- NEW FILE ---------------\n",
      "CategoryType = Literal['commited', 'common', 'infile', 'inproject', 'non_informative', 'random', 'other']\n",
      "ID2CATEGORY = [\n",
      "    'commited',\n",
      "    'common',\n",
      "    'infile',\n",
      "    'inproject',\n",
      "    'non_informative',\n",
      "    'random',\n",
      "    'other',\n",
      "]\n",
      "CATEGORY2ID = {category: i for i, category in enumerate(ID2CATEGORY)}\n",
      "UNDEFINED_CATEGORY_ID = -1\n",
      "--------------- NEW FILE ---------------\n",
      "StatisticValue = int | float\n",
      "class StatisticBase(ABC):\n",
      "    def reinit(self, prev_value: StatisticValue | None) -> None:\n",
      "        pass\n",
      "    @abstractmethod\n",
      "    @torch.inference_mode\n",
      "    def micro_batch_update(self, **kwargs) -> None:\n",
      "        raise NotImplementedError\n",
      "    @abstractmethod\n",
      "    def batch_commit(self) -> StatisticValue:\n",
      "        raise NotImplementedError\n",
      "def ema_factory(statistic_cls: Type[StatisticBase]) -> Type[StatisticBase]:\n",
      "    class EMAStatistic(statistic_cls, ABC):\n",
      "        def __init__(self, ema_alpha: float) -> None:\n",
      "            super().__init__()\n",
      "            self.ema_alpha = ema_alpha\n",
      "            self.ema_state = None\n",
      "        def reinit(self, ema_state: float | None) -> None:\n",
      "            self.ema_state = ema_state\n",
      "        def batch_commit(self) -> StatisticValue:\n",
      "            batch_metric = super().batch_commit()\n",
      "            if self.ema_state is None:\n",
      "                self.ema_state = batch_metric\n",
      "            else:\n",
      "                self.ema_state += self.ema_alpha * (batch_metric - self.ema_state)\n",
      "            return self.ema_state\n",
      "    return EMAStatistic\n",
      "def lazy_statistic_factory(statistic_name: str) -> Type[StatisticBase]:\n",
      "    class LazyStatistic(StatisticBase):\n",
      "        def __init__(self) -> None:\n",
      "            self.value = None\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            self.value = kwargs.get(statistic_name)\n",
      "        def batch_commit(self) -> StatisticValue:\n",
      "            batch_statistic = self.value\n",
      "            self.value = None\n",
      "            return batch_statistic\n",
      "    return LazyStatistic\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class ChainedComposerConfig(ConfigBase):\n",
      "    pre_context_prompt: str\n",
      "    post_context_prompt: str\n",
      "    path_comment_template: str\n",
      "    recalculate_random_category: bool\n",
      "    blocks: Sequence[ComposerBlock] = field(default_factory=list)\n",
      "--------------- NEW FILE ---------------\n",
      "T = TypeVar('T')\n",
      "JsonAllowedTypes = dict | list | tuple | str | int | float | bool | None\n",
      "Message = str | int | float | dict[str, JsonAllowedTypes]\n",
      "class Log(TypedDict):\n",
      "    iteration_number: int\n",
      "    train_metrics: NotRequired[dict[MetricName, MetricValue]]\n",
      "    valid_metrics: NotRequired[dict[MetricName, MetricValue]]\n",
      "class LoggerBase(ABC):\n",
      "    _instance = None\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "        if cls._instance is None:\n",
      "            cls._instance = super().__new__(cls)\n",
      "        return cls._instance\n",
      "    @abstractmethod\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        raise NotImplementedError\n",
      "    @abstractmethod\n",
      "    def message(self, message: Message) -> Message:\n",
      "        raise NotImplementedError\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class DatasetConfig(ConfigBase):\n",
      "    path: str\n",
      "    name: str | None = None\n",
      "    data_dir: str | None = None\n",
      "    split: str | None = None\n",
      "    cache_dir: str = str(config.HF_DATASETS_CACHE)\n",
      "--------------- NEW FILE ---------------\n",
      "MetricName = str\n",
      "MetricValue = StatisticValue\n",
      "class OptimizationMode(str, Enum):\n",
      "    MIN = 'minimization'\n",
      "    MAX = 'maximization'\n",
      "class MetricBase(StatisticBase, ABC):\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def mode(self) -> OptimizationMode:\n",
      "        raise NotImplementedError\n",
      "def loss_based_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class LossBasedMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = kwargs['loss_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "    return LossBasedMetric\n",
      "def detached_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class DetachedMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = ~kwargs['loss_mask'] & kwargs['target_attn_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "    return DetachedMetric\n",
      "def completion_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class FullMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = kwargs['completion_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "    return FullMetric\n",
      "def context_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class FullMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = ~kwargs['completion_mask'] & kwargs['target_attn_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "    return FullMetric\n",
      "def full_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class FullMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = kwargs['target_attn_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "    return FullMetric\n",
      "def categorized_metric_factory(metric_cls: Type[MetricBase], category: CategoryType) -> Type[MetricBase]:\n",
      "    class CategorizedMetric(metric_cls, ABC):\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "            kwargs['mask'] = (kwargs['category_ids'] == CATEGORY2ID[category])\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "    return CategorizedMetric\n",
      "--------------- NEW FILE ---------------\n",
      "class FileFilter(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "class InclusiveFileExtensionFilter(FileFilter):\n",
      "    def __init__(self, whitelist: list[str]) -> None:\n",
      "        self.whitelist = tuple(whitelist)\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if file.metadata['filename'].endswith(self.whitelist)]\n",
      "class ExclusiveFileExtensionFilter(FileFilter):\n",
      "    def __init__(self, blacklist: list[str]) -> None:\n",
      "        self.blacklist = tuple(blacklist)\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if not file.metadata['filename'].endswith(self.blacklist)]\n",
      "class EmptyFileFilter(FileFilter):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if file.content.strip()]\n",
      "class FileLengthFilter(FileFilter):\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if self.min_len <= len(file.content) <= self.max_len]\n",
      "class TokenizedFileLengthFilter(FileFilter):\n",
      "    requires_tokenizer = True\n",
      "    def __init__(self, tokenizer: PreTrainedTokenizerBase, min_len: int, max_len: int) -> None:\n",
      "        self.tokenizer = tokenizer\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        filtered_files = list()\n",
      "        for file in files:\n",
      "            if 'num_tokens' not in file.metadata:\n",
      "                tokenized_file = self.tokenizer(file.content, return_attention_mask=False).input_ids\n",
      "                file.metadata['num_tokens'] = len(tokenized_file)\n",
      "            if self.min_len <= file.metadata['num_tokens'] <= self.max_len:\n",
      "                filtered_files.append(file)\n",
      "        return filtered_files\n",
      "class CharTokenRatioFilter(FileFilter):\n",
      "    requires_tokenizer = True\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 min_ratio: float,\n",
      "                 max_ratio: float,\n",
      "                 subsequence_len: int,\n",
      "                 random_seed: int | None,\n",
      "                 ) -> None:\n",
      "        self.tokenizer = tokenizer\n",
      "        self.min_ratio = min_ratio\n",
      "        self.max_ratio = max_ratio\n",
      "        self.subsequence_len = subsequence_len\n",
      "        self.generator = random.Random(random_seed)\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        filtered_files = list()\n",
      "        for file in files:\n",
      "            if len(file.content) <= self.subsequence_len:\n",
      "                subsequence = file.content\n",
      "            else:\n",
      "                start_idx = self.generator.randrange(len(file.content) - self.subsequence_len + 1)\n",
      "                subsequence = file.content[start_idx:start_idx + self.subsequence_len]\n",
      "            tokenized_subsequence = self.tokenizer(subsequence, return_attention_mask=False).input_ids\n",
      "            ratio = len(subsequence) / len(tokenized_subsequence)\n",
      "            if self.min_ratio <= ratio <= self.max_ratio:\n",
      "                filtered_files.append(file)\n",
      "        return filtered_files\n",
      "--------------- NEW FILE ---------------\n",
      "T = TypeVar('T')\n",
      "FullFineTuningTrainer = TypeVar('FullFineTuningTrainer')\n",
      "class EpochCounter(StatisticBase):\n",
      "    _instance = None\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "        if cls._instance is None:\n",
      "            cls._instance = super().__new__(cls)\n",
      "        return cls._instance\n",
      "    def __init__(self) -> None:\n",
      "        self.init_epoch = 0\n",
      "        self.samples = 0\n",
      "        self.ds_length = 1\n",
      "    def reinit(self, init_epoch: float | None) -> None:\n",
      "        if init_epoch is not None:\n",
      "            self.init_epoch = init_epoch\n",
      "    def micro_batch_update(self, input_ids: torch.Tensor, trainer: FullFineTuningTrainer, **_kwargs) -> None:\n",
      "        if trainer.model.training:\n",
      "            self.samples += input_ids.shape[0]\n",
      "            self.ds_length = len(trainer.train_dl.dataset)\n",
      "    def batch_commit(self) -> StatisticValue:\n",
      "        return self.init_epoch + self.samples / self.ds_length\n",
      "--------------- NEW FILE ---------------\n",
      "class ChunkHarvester(ComposerBlock, ABC):\n",
      "    last_block_permit = True\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return ContextPostprocessor,\n",
      "class JoiningHarvester(ChunkHarvester):\n",
      "    def __init__(self, chunks_sep: str) -> None:\n",
      "        self.chunks_sep = chunks_sep\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> str:\n",
      "        return self.chunks_sep.join(chunk.content for chunk in chunks)\n",
      "class PathCommentHarvester(JoiningHarvester):\n",
      "    def __init__(self, chunks_sep: str, path_comment_template: str) -> None:\n",
      "        super().__init__(chunks_sep)\n",
      "        self.path_comment_template = path_comment_template\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> str:\n",
      "        for chunk in chunks:\n",
      "            chunk.content = self.path_comment_template.format(\n",
      "                filename=chunk.file_ref.metadata['filename'], content=chunk.content)\n",
      "        return super().__call__(chunks, datapoint)\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class CheckpointManagerConfig(ConfigBase):\n",
      "    init_from: LoadingMode | str\n",
      "    main_metric: MetricName\n",
      "    directory: str\n",
      "    checkpoint_directory_template: str = '{iteration_number:04d}'\n",
      "    extract_iteration_number: Callable[[str], int] = staticmethod(int)\n",
      "    model_subdirectory: str = 'model'\n",
      "    optim_state_filename: str = 'optim.pt'\n",
      "    metrics_filename: str = 'metrics.json'\n",
      "    def __post_init__(self) -> None:\n",
      "        if self.init_from in set(LoadingMode):\n",
      "            self.init_from = LoadingMode(self.init_from)\n",
      "@dataclass(kw_only=True)\n",
      "class TopKCheckpointManagerConfig(CheckpointManagerConfig):\n",
      "    max_checkpoints_num: int\n",
      "--------------- NEW FILE ---------------\n",
      "class CrossEntropy(MetricBase):\n",
      "    mode = OptimizationMode.MIN\n",
      "    def __init__(self) -> None:\n",
      "        self.mean_loss = 0\n",
      "        self.num_tokens = 0\n",
      "    @torch.inference_mode\n",
      "    def micro_batch_update(self, loss_per_token: torch.Tensor, mask: torch.Tensor, **_kwargs) -> None:\n",
      "        loss_update = torch.nan_to_num(loss_per_token[mask].mean()).item()\n",
      "        num_tokens_update = mask.sum().item()\n",
      "        if not self.num_tokens:\n",
      "            self.mean_loss += loss_update\n",
      "            self.num_tokens = 0\n",
      "        else:\n",
      "            tokens_ratio = num_tokens_update / self.num_tokens\n",
      "            self.mean_loss += tokens_ratio * loss_update\n",
      "            self.mean_loss /= tokens_ratio + 1\n",
      "        self.num_tokens += num_tokens_update\n",
      "    def batch_commit(self) -> MetricValue:\n",
      "        batch_metric = float('nan') if not self.num_tokens else self.mean_loss\n",
      "        self.mean_loss = 0\n",
      "        self.num_tokens = 0\n",
      "        return batch_metric\n",
      "--------------- NEW FILE ---------------\n",
      "class AttentionImplementation(str, Enum):\n",
      "    FA2 = 'flash_attention_2'\n",
      "    SDPA = 'sdpa'\n",
      "    EAGER = 'eager'\n",
      "def init_tokenizer(config: ModelConfig) -> PreTrainedTokenizerBase:\n",
      "    return AutoTokenizer.from_pretrained(\n",
      "        pretrained_model_name_or_path=config.tokenizer_name,\n",
      "        trust_remote_code=config.trust_remote_code,\n",
      "    )\n",
      "def get_optimal_attn(model_name: str, device: torch.device, dtype: torch.dtype) -> AttentionImplementation:\n",
      "    hf_model_config = AutoConfig.from_pretrained(model_name)\n",
      "    model_cls = MODEL_FOR_CAUSAL_LM_MAPPING[type(hf_model_config)]\n",
      "    fa2_supported = (\n",
      "            is_flash_attn_2_available() and\n",
      "            model_cls._supports_flash_attn_2 and\n",
      "            device.type == 'cuda' and\n",
      "            dtype in (torch.float16, torch.bfloat16)\n",
      "    )\n",
      "    if fa2_supported:\n",
      "        return AttentionImplementation.FA2\n",
      "    elif is_torch_sdpa_available() and model_cls._supports_sdpa:\n",
      "        return AttentionImplementation.SDPA\n",
      "    else:\n",
      "        return AttentionImplementation.EAGER\n",
      "def init_model(config: ModelConfig) -> PreTrainedModel:\n",
      "    if config.device is None:\n",
      "        config.device = get_free_device()\n",
      "    if config.dtype is None:\n",
      "        config.dtype = get_optimal_dtype()\n",
      "    if config.attn_implementation is None:\n",
      "        config.attn_implementation = get_optimal_attn(config.model_name, config.device, config.dtype)\n",
      "    if config.load_from is None:\n",
      "        config.load_from = config.model_name\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "        pretrained_model_name_or_path=config.load_from,\n",
      "        trust_remote_code=config.trust_remote_code,\n",
      "        device_map=config.device,\n",
      "        torch_dtype=config.dtype,\n",
      "        attn_implementation=config.attn_implementation,\n",
      "        use_cache=config.use_cache,\n",
      "    )\n",
      "    if config.compile:\n",
      "        model = torch.compile(model)\n",
      "    return model\n",
      "def init_tokenizer_model(loaded_config: DictConfig, **kwargs) -> tuple[PreTrainedTokenizerBase, PreTrainedModel]:\n",
      "    config = ModelConfig.from_dict(dict(loaded_config) | kwargs)\n",
      "    return init_tokenizer(config), init_model(config)\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class ModelConfig(ConfigBase):\n",
      "    tokenizer_name: str\n",
      "    model_name: str\n",
      "    trust_remote_code: bool\n",
      "    load_from: str | None\n",
      "    use_cache: bool = False\n",
      "    device: torch.device | None = None\n",
      "    dtype: torch.dtype | None = None\n",
      "    attn_implementation: Literal['flash_attention_2', 'sdpa', 'eager'] | None = None\n",
      "    compile: bool = True\n",
      "    def __post_init__(self) -> None:\n",
      "        if isinstance(self.device, str):\n",
      "            self.device = torch.device(self.device)\n",
      "        if isinstance(self.dtype, str):\n",
      "            self.dtype = getattr(torch, self.dtype)\n",
      "--------------- NEW FILE ---------------\n",
      "class CompletionLossPreprocessor(PreprocessorBase):\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 max_seq_len: int,\n",
      "                 context_tokens: int | float,\n",
      "                 loss_ratio: float,\n",
      "                 num_chars_per_token: int,\n",
      "                 padding: bool,\n",
      "                 verbose: bool,\n",
      "                 ) -> None:\n",
      "        if not 0 < loss_ratio <= 1:\n",
      "            raise ValueError('loss_ratio must be selected from the interval (0, 1]. '\n",
      "                             f'Got {loss_ratio} instead.')\n",
      "        if padding:\n",
      "            tokenizer.deprecation_warnings['Asking-to-pad-a-fast-tokenizer'] = True\n",
      "        tokenizer.deprecation_warnings['sequence-length-is-longer-than-the-specified-maximum'] = True\n",
      "        self.tokenizer = tokenizer\n",
      "        self.max_seq_len = max_seq_len\n",
      "        if isinstance(context_tokens, float):\n",
      "            if not 0 <= context_tokens <= 1:\n",
      "                raise ValueError('The context ratio must be between 0 and 1.')\n",
      "            context_tokens = int(max_seq_len * context_tokens)\n",
      "        self.context_tokens = context_tokens\n",
      "        self.loss_ratio = loss_ratio\n",
      "        self.num_chars_per_token = num_chars_per_token\n",
      "        self.padding = padding\n",
      "        self.verbose = verbose\n",
      "    def _inc_num_chars_per_token(self) -> None:\n",
      "        old_value = self.num_chars_per_token\n",
      "        self.num_chars_per_token = math.ceil(1.5 * self.num_chars_per_token)\n",
      "        if self.verbose:\n",
      "            warnings.warn(\n",
      "                f'num_chars_per_token has been increased from {old_value} to {self.num_chars_per_token} '\n",
      "                'due to an underestimation of the length of the truncated character sequence.')\n",
      "    def tokenize_pre_context_prompt(self, prompts: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "        tokenized_prompts = self.tokenizer(\n",
      "            text=[prompt[-char_trunc_upper_bound:] for prompt in prompts],\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "        for tokenized_prompt, prompt in zip(tokenized_prompts.input_ids, prompts):\n",
      "            overflow_chars = len(prompt) > char_trunc_upper_bound\n",
      "            underflow_tokens = len(tokenized_prompt) < self.max_seq_len\n",
      "            if overflow_chars and underflow_tokens:\n",
      "                self._inc_num_chars_per_token()\n",
      "                return self.tokenize_pre_context_prompt(prompts)\n",
      "        return tokenized_prompts\n",
      "    def tokenize_composed_completion(self, completions: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "        trunc_completions = [completion[:char_trunc_upper_bound] for completion in completions]\n",
      "        tokenized_completions = self.tokenizer(\n",
      "            text=trunc_completions,\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "            return_offsets_mapping=True,\n",
      "            return_length=True,\n",
      "        )\n",
      "        tokenized_completions.length = torch.tensor(tokenized_completions.length)\n",
      "        overflow_chars = torch.tensor([len(completion) > char_trunc_upper_bound for completion in completions])\n",
      "        underflow_tokens = (tokenized_completions.length < self.max_seq_len)\n",
      "        if torch.any(overflow_chars & underflow_tokens):\n",
      "            self._inc_num_chars_per_token()\n",
      "            return self.tokenize_composed_completion(completions)\n",
      "        tokenized_completions['newline_positions'] = [\n",
      "            [match.start() for match in re.finditer('\\n', completion)]\n",
      "            for completion in trunc_completions\n",
      "        ]\n",
      "        return tokenized_completions\n",
      "    def tokenize_composed_context(self, contexts: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "        tokenized_contexts = self.tokenizer(\n",
      "            text=[ctx[-char_trunc_upper_bound:] for ctx in contexts],\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "        for tokenized_ctx, ctx in zip(tokenized_contexts.input_ids, contexts):\n",
      "            overflow_chars = len(ctx) > char_trunc_upper_bound\n",
      "            underflow_tokens = len(tokenized_ctx) < self.max_seq_len\n",
      "            if overflow_chars and underflow_tokens:\n",
      "                self._inc_num_chars_per_token()\n",
      "                return self.tokenize_composed_context(contexts)\n",
      "            if not overflow_chars and len(tokenized_ctx) < self.context_tokens:\n",
      "                if not self.padding:\n",
      "                    raise ValueError('Not enough data to satisfy context_tokens.')\n",
      "                elif self.verbose:\n",
      "                    warnings.warn('Not enough data to satisfy context_tokens.')\n",
      "        return tokenized_contexts\n",
      "    def calc_lens(self,\n",
      "                  prompt: torch.Tensor,\n",
      "                  context: torch.Tensor,\n",
      "                  completion: torch.Tensor,\n",
      "                  ) -> tuple[int, int, int]:\n",
      "        if len(context) >= self.context_tokens:\n",
      "            prompt_len = min(len(prompt), self.max_seq_len - self.context_tokens)\n",
      "            completion_len = min(len(completion), self.max_seq_len - self.context_tokens - prompt_len)\n",
      "            context_len = self.max_seq_len - prompt_len - completion_len\n",
      "        else:\n",
      "            context_len = len(context)\n",
      "            prompt_len = min(len(prompt), self.max_seq_len - context_len)\n",
      "            completion_len = self.max_seq_len - prompt_len - context_len\n",
      "        return prompt_len, context_len, completion_len\n",
      "    @staticmethod\n",
      "    def _get_partial_completion_mask(tokenized_completions: BatchEncoding,\n",
      "                                     target_attn_mask: torch.Tensor,\n",
      "                                     ratio: float,\n",
      "                                     ) -> torch.Tensor:\n",
      "        position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        completions_len = tokenized_completions.length.unsqueeze(-1)\n",
      "        num_masked_tokens = (ratio * completions_len).ceil().long()\n",
      "        mask = (num_informative_tokens - num_masked_tokens <= position_ids)\n",
      "        return mask.logical_and(target_attn_mask)\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        return self._get_partial_completion_mask(*args, **kwargs, ratio=self.loss_ratio)\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        return self._get_partial_completion_mask(*args, **kwargs, ratio=1)\n",
      "    @staticmethod\n",
      "    def get_category_ids(tokenized_completions: BatchEncoding,\n",
      "                         completion_lines: list[CompletionLines],\n",
      "                         target_attn_mask: torch.Tensor,\n",
      "                         ) -> torch.Tensor:\n",
      "        category_ids = torch.full_like(target_attn_mask, UNDEFINED_CATEGORY_ID)\n",
      "        t_completion_start = (target_attn_mask.sum(dim=-1) - tokenized_completions.length).tolist()\n",
      "        batch_size = len(tokenized_completions.length)\n",
      "        for sample_idx in range(batch_size):\n",
      "            newline_positions = tokenized_completions.newline_positions[sample_idx]\n",
      "            offset_mapping = tokenized_completions.offset_mapping[sample_idx]\n",
      "            newline_positions.append(float('inf'))\n",
      "            line2category = {\n",
      "                line_idx: CATEGORY2ID[category]\n",
      "                for category, line_category_ids in completion_lines[sample_idx].items()\n",
      "                for line_idx in line_category_ids\n",
      "            }\n",
      "            line_idx = 0\n",
      "            category_id = line2category.get(line_idx)\n",
      "            for token_idx, (char_start, _) in enumerate(offset_mapping, start=t_completion_start[sample_idx]):\n",
      "                if char_start > newline_positions[line_idx]:\n",
      "                    line_idx += 1\n",
      "                    category_id = line2category.get(line_idx)\n",
      "                if category_id is not None:\n",
      "                    category_ids[sample_idx, token_idx] = category_id\n",
      "        return category_ids\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "        tokenized_prompts = self.tokenize_pre_context_prompt(batch['pre_context_prompt'])\n",
      "        tokenized_completions = self.tokenize_composed_completion(batch['composed_completion'])\n",
      "        tokenized_contexts = self.tokenize_composed_context(batch['composed_context'])\n",
      "        tokenized_batch = list()\n",
      "        batch_size = len(tokenized_completions.length)\n",
      "        for sample_idx in range(batch_size):\n",
      "            prompt = tokenized_prompts.input_ids[sample_idx]\n",
      "            context = tokenized_contexts.input_ids[sample_idx]\n",
      "            completion = tokenized_completions.input_ids[sample_idx]\n",
      "            prompt_len, context_len, completion_len = self.calc_lens(prompt, context, completion)\n",
      "            prompt = [self.tokenizer.bos_token_id] + prompt[-prompt_len:]\n",
      "            context = context[-context_len:]\n",
      "            completion = completion[:completion_len]\n",
      "            tokenized_completions.offset_mapping[sample_idx] = \\\n",
      "                tokenized_completions.offset_mapping[sample_idx][:completion_len]\n",
      "            tokenized_completions.length[sample_idx] = len(completion)\n",
      "            tokenized_batch.append(prompt + context + completion)\n",
      "        self.tokenizer.padding_side = 'right'\n",
      "        padded_batch = self.tokenizer.pad(\n",
      "            encoded_inputs={'input_ids': tokenized_batch},\n",
      "            padding='longest',\n",
      "            return_attention_mask=True,\n",
      "            return_tensors='pt')\n",
      "        input_attn_mask = padded_batch.attention_mask[:, :-1]\n",
      "        target_attn_mask = padded_batch.attention_mask[:, 1:]\n",
      "        return PreprocessedBatch(\n",
      "            input_ids=padded_batch.input_ids[:, :-1],\n",
      "            target_ids=padded_batch.input_ids[:, 1:],\n",
      "            loss_mask=self.get_loss_mask(tokenized_completions, target_attn_mask),\n",
      "            completion_mask=self.get_completion_mask(tokenized_completions, target_attn_mask),\n",
      "            category_ids=self.get_category_ids(tokenized_completions, batch['completion_lines'], target_attn_mask),\n",
      "            input_attn_mask=input_attn_mask,\n",
      "            target_attn_mask=target_attn_mask.bool(),\n",
      "        )\n",
      "--------------- NEW FILE ---------------\n",
      "class ContextPostprocessor(ComposerBlock, ABC):\n",
      "    last_block_permit = True\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return ContextPostprocessor,\n",
      "class PartialMemoryPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self, dropout: float, random_seed: int | None) -> None:\n",
      "        if not 0 <= dropout <= 1:\n",
      "            raise ValueError('dropout must be selected from the interval [0, 1]. '\n",
      "                             f'Got {dropout} instead.')\n",
      "        self.dropout = dropout\n",
      "        self.generator = random.Random(random_seed)\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.generator.random() >= self.dropout)\n",
      "class LineLengthPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.min_len <= len(line) <= self.max_len)\n",
      "class LineStripPostprocessor(ContextPostprocessor):\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line.strip() for line in context.split('\\n'))\n",
      "class InverseFrequencyMemoryPostprocessor(ContextPostprocessor):\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return context\n",
      "--------------- NEW FILE ---------------\n",
      "class FileLevelPreprocessor(CompletionLossPreprocessor):\n",
      "    def calc_lens(self,\n",
      "                  prompt: torch.Tensor,\n",
      "                  context: torch.Tensor,\n",
      "                  completion: torch.Tensor,\n",
      "                  ) -> tuple[int, int, int]:\n",
      "        prompt_len, _, completion_len = super().calc_lens(prompt, context, completion)\n",
      "        return prompt_len, -len(context), completion_len\n",
      "--------------- NEW FILE ---------------\n",
      "class FusedSampler(Sampler[int]):\n",
      "    def __init__(self,\n",
      "                 start_sample_idx: int,\n",
      "                 end_sample_idx: int,\n",
      "                 dataset_length: int,\n",
      "                 generator: torch.Generator | None = None,\n",
      "                 ) -> None:\n",
      "        super().__init__()\n",
      "        self.start_sample_idx = start_sample_idx\n",
      "        self.end_sample_idx = end_sample_idx\n",
      "        self.dataset_length = dataset_length\n",
      "        self.max_epochs = math.ceil(end_sample_idx / dataset_length)\n",
      "        self.generator = generator\n",
      "    def __iter__(self) -> Iterator[int]:\n",
      "        fused_weights = torch.rand(self.max_epochs, self.dataset_length, generator=self.generator)\n",
      "        fused_indices = torch.argsort(fused_weights, dim=-1).flatten().tolist()\n",
      "        yield from fused_indices[self.start_sample_idx:self.end_sample_idx]\n",
      "    def __len__(self) -> int:\n",
      "        return self.end_sample_idx - self.start_sample_idx\n",
      "--------------- NEW FILE ---------------\n",
      "class LMPreprocessor(CompletionLossPreprocessor):\n",
      "    def get_loss_mask(self,\n",
      "                      _tokenized_completions: BatchEncoding,\n",
      "                      target_attn_mask: torch.Tensor,\n",
      "                      **_kwargs,\n",
      "                      ) -> torch.Tensor:\n",
      "        position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        num_loss_tokens = (self.loss_ratio * num_informative_tokens).ceil().long()\n",
      "        loss_mask = (num_informative_tokens - num_loss_tokens <= position_ids)\n",
      "        return loss_mask.logical_and(target_attn_mask)\n",
      "--------------- NEW FILE ---------------\n",
      "class CheckpointManager:\n",
      "    def __init__(self,\n",
      "                 init_from: LoadingMode | str,\n",
      "                 main_metric: MetricName,\n",
      "                 directory: str,\n",
      "                 checkpoint_directory_template: str,\n",
      "                 extract_iteration_number: Callable[[str], int],\n",
      "                 model_subdirectory: str,\n",
      "                 optim_state_filename: str,\n",
      "                 metrics_filename: str,\n",
      "                 ) -> None:\n",
      "        if main_metric not in METRICS_REGISTRY:\n",
      "            raise ValueError('The specified main_metric is not contained in the registry.')\n",
      "        self.init_from = init_from\n",
      "        self.main_metric_name = main_metric\n",
      "        self.main_metric = METRICS_REGISTRY[main_metric]\n",
      "        self.directory = directory\n",
      "        self._checkpoint_directory_template = checkpoint_directory_template\n",
      "        self._extract_iteration_number = extract_iteration_number\n",
      "        self._model_subdirectory = model_subdirectory\n",
      "        self._optim_state_filename = optim_state_filename\n",
      "        self._metrics_filename = metrics_filename\n",
      "    def get_wandb_resume_mode(self) -> Literal['allow', 'never'] | None:\n",
      "        match self.init_from:\n",
      "            case LoadingMode.SCRATCH:\n",
      "                return None\n",
      "            case LoadingMode.RESUME:\n",
      "                return 'allow'\n",
      "            case _:\n",
      "                return 'never'\n",
      "    def load_metrics(self, checkpoint_dir: str) -> Log:\n",
      "        metrics_file = os.path.join(checkpoint_dir, self._metrics_filename)\n",
      "        with open(metrics_file) as stream:\n",
      "            return Log(**json.load(stream))\n",
      "    def get_checkpoint_score(self, checkpoint_dir: str) -> MetricValue:\n",
      "        checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "        metrics = self.load_metrics(checkpoint_dir)\n",
      "        metric_value = metrics.get('valid_metrics', metrics['train_metrics']).get(self.main_metric_name)\n",
      "        if metric_value is None:\n",
      "            raise RuntimeError(f'The {checkpoint_dir} does not contain information '\n",
      "                               'about the specified main_metric.')\n",
      "        elif self.main_metric.mode == OptimizationMode.MIN:\n",
      "            return metric_value\n",
      "        else:\n",
      "            return -metric_value\n",
      "    def get_checkpoint_directory(self) -> str | None:\n",
      "        match self.init_from:\n",
      "            case LoadingMode.SCRATCH:\n",
      "                return None\n",
      "            case LoadingMode.RESUME:\n",
      "                return max(\n",
      "                    next(os.walk(self.directory))[1],\n",
      "                    key=self._extract_iteration_number,\n",
      "                    default=None,\n",
      "                )\n",
      "            case LoadingMode.BEST:\n",
      "                return min(\n",
      "                    next(os.walk(self.directory))[1],\n",
      "                    key=self.get_checkpoint_score,\n",
      "                    default=None,\n",
      "                )\n",
      "            case _:\n",
      "                return self.init_from\n",
      "    def get_iteration_number(self) -> int:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        if checkpoint_dir is not None:\n",
      "            return self._extract_iteration_number(checkpoint_dir)\n",
      "        else:\n",
      "            return 0\n",
      "    def get_model_subdirectory(self) -> str | None:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        if checkpoint_dir is not None:\n",
      "            return os.path.join(self.directory, checkpoint_dir, self._model_subdirectory)\n",
      "        else:\n",
      "            return None\n",
      "    def init_optimizer(self, optimizer: torch.optim.AdamW) -> None:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        if checkpoint_dir is not None:\n",
      "            optim_file = os.path.join(self.directory, checkpoint_dir, self._optim_state_filename)\n",
      "            optimizer.load_state_dict(torch.load(optim_file))\n",
      "    def init_metrics(self,\n",
      "                     group: Literal['train_metrics', 'valid_metrics'],\n",
      "                     metrics: list[MetricName],\n",
      "                     ema_alpha: float,\n",
      "                     ) -> dict[MetricName, MetricBase]:\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        metrics_dict = dict()\n",
      "        if checkpoint_dir is None:\n",
      "            metrics_states = dict()\n",
      "        else:\n",
      "            checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "            metrics_states = self.load_metrics(checkpoint_dir)[group]\n",
      "        for name in metrics:\n",
      "            init_args = [ema_alpha] if name.startswith('ema_') else list()\n",
      "            metrics_dict[name] = METRICS_REGISTRY[name](*init_args)\n",
      "            metrics_dict[name].reinit(metrics_states.get(name))\n",
      "        return metrics_dict\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "        checkpoint_dir = os.path.join(\n",
      "            self.directory,\n",
      "            self._checkpoint_directory_template.format(\n",
      "                iteration_number=checkpoint.metrics['iteration_number']),\n",
      "        )\n",
      "        if os.path.exists(checkpoint_dir):\n",
      "            warnings.warn(f'The contents of the checkpoint {checkpoint_dir} have been overwritten.')\n",
      "        model_save_dir, optim_file, metrics_file = map(\n",
      "            lambda x: os.path.join(checkpoint_dir, x),\n",
      "            [self._model_subdirectory, self._optim_state_filename, self._metrics_filename],\n",
      "        )\n",
      "        checkpoint.model.save_pretrained(model_save_dir)\n",
      "        torch.save(checkpoint.optimizer_state, optim_file)\n",
      "        with open(metrics_file, 'w') as stream:\n",
      "            json.dump(checkpoint.metrics, stream, indent=4)\n",
      "--------------- NEW FILE ---------------\n",
      "class FullFineTuningTrainer(TrainerBase):\n",
      "    def __init__(self,\n",
      "                 model: PreTrainedModel,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 train_ds: Dataset,\n",
      "                 valid_ds: Dataset | None,\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 logger: LoggerBase,\n",
      "                 max_iters: int,\n",
      "                 valid_freq: int | None,\n",
      "                 checkpointing_freq: int | None,\n",
      "                 gradient_accumulation_steps: int,\n",
      "                 micro_batch_size: int,\n",
      "                 learning_rate: float,\n",
      "                 beta_1: float,\n",
      "                 beta_2: float,\n",
      "                 weight_decay: float,\n",
      "                 max_grad_norm: float,\n",
      "                 warmup_iters: int | None,\n",
      "                 lr_decay_iters: int | None,\n",
      "                 min_lr: float | None,\n",
      "                 train_metrics: list[MetricName],\n",
      "                 train_ema_alpha: float,\n",
      "                 valid_metrics: list[MetricName],\n",
      "                 valid_ema_alpha: float | None,\n",
      "                 shuffle: bool,\n",
      "                 drop_last: bool,\n",
      "                 num_workers: int,\n",
      "                 prefetch_factor: int,\n",
      "                 random_seed: int | None,\n",
      "                 fp32_matmul_precision: Literal['highest', 'high', 'medium'],\n",
      "                 ) -> None:\n",
      "        self.model = model\n",
      "        self.tokenizer = tokenizer\n",
      "        self.checkpointer = checkpointer\n",
      "        self.logger = logger\n",
      "        self.checkpointing_freq = checkpointing_freq\n",
      "        if checkpointing_freq is None:\n",
      "            self.checkpointing_freq = float('inf')\n",
      "            self.logger.message('Checkpointing is disabled.')\n",
      "        elif valid_freq is not None and valid_freq != checkpointing_freq:\n",
      "            warnings.warn('Validation and checkpointing are not synchronized (valid_freq != checkpointing_freq). '\n",
      "                          'Resulting checkpoints will not contain validation metrics.')\n",
      "        self.start_iter = checkpointer.get_iteration_number()\n",
      "        self.max_iters = max_iters\n",
      "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
      "        self.batch_size = gradient_accumulation_steps * micro_batch_size\n",
      "        self.is_on_cuda = (model.device.type == 'cuda')\n",
      "        if random_seed is not None:\n",
      "            torch.manual_seed(random_seed)\n",
      "        torch.set_float32_matmul_precision(fp32_matmul_precision)\n",
      "        logger.message(f\"Set the FP32 matrix multiplication precision to '{fp32_matmul_precision}'.\")\n",
      "        if valid_ds is None and valid_freq is None and not valid_metrics:\n",
      "            self.valid_freq = float('inf')\n",
      "            self.valid_dl = None\n",
      "            self.logger.message('Validation is disabled.')\n",
      "        elif valid_ds is not None and valid_freq is not None and valid_metrics:\n",
      "            self.valid_freq = valid_freq\n",
      "            self.valid_dl = DataLoader(\n",
      "                dataset=valid_ds,\n",
      "                batch_size=micro_batch_size,\n",
      "                shuffle=False,\n",
      "                num_workers=num_workers,\n",
      "                pin_memory=self.is_on_cuda,\n",
      "                drop_last=False,\n",
      "                prefetch_factor=prefetch_factor,\n",
      "                persistent_workers=(valid_freq > max_iters),\n",
      "                pin_memory_device=str(model.device),\n",
      "            )\n",
      "            if valid_ema_alpha is None:\n",
      "                valid_ema_alpha = 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "                self.logger.message(f'valid_ema_alpha automatically set to {valid_ema_alpha:.05f}.')\n",
      "        else:\n",
      "            raise ValueError('The valid_ds, valid_freq and valid_metrics arguments do not match each other.')\n",
      "        sampler = FusedSampler(\n",
      "            start_sample_idx=(self.batch_size * self.start_iter),\n",
      "            end_sample_idx=(self.batch_size * max_iters),\n",
      "            dataset_length=len(train_ds),\n",
      "        ) if shuffle else None\n",
      "        self.train_dl = DataLoader(\n",
      "            dataset=train_ds,\n",
      "            batch_size=micro_batch_size,\n",
      "            sampler=sampler,\n",
      "            num_workers=num_workers,\n",
      "            pin_memory=self.is_on_cuda,\n",
      "            drop_last=drop_last,\n",
      "            prefetch_factor=prefetch_factor,\n",
      "            pin_memory_device=str(model.device),\n",
      "        )\n",
      "        self.optimizer = self._init_adamw(learning_rate, beta_1, beta_2, weight_decay)\n",
      "        self.grad_scaler = torch.cuda.amp.GradScaler(enabled=(model.dtype == torch.float16))\n",
      "        self.max_grad_norm = max_grad_norm\n",
      "        if warmup_iters is None and lr_decay_iters is None and min_lr is None:\n",
      "            self.get_lr = lambda _: learning_rate\n",
      "        elif warmup_iters is not None and lr_decay_iters is not None and min_lr is not None:\n",
      "            self.get_lr = partial(\n",
      "                get_lr_from_cosine_scheduler_with_linear_warmup,\n",
      "                min_lr=min_lr,\n",
      "                max_lr=learning_rate,\n",
      "                warmup_iters=warmup_iters,\n",
      "                lr_decay_iters=lr_decay_iters,\n",
      "            )\n",
      "        else:\n",
      "            raise ValueError('The warmup_iters, lr_decay_iters and min_lr arguments do not match each other.')\n",
      "        self.train_metrics = self.checkpointer.init_metrics('train_metrics', train_metrics, train_ema_alpha)\n",
      "        self.valid_metrics = self.checkpointer.init_metrics('valid_metrics', valid_metrics, valid_ema_alpha)\n",
      "    def _init_adamw(self,\n",
      "                    learning_rate: float,\n",
      "                    beta_1: float,\n",
      "                    beta_2: float,\n",
      "                    weight_decay: float,\n",
      "                    ) -> torch.optim.AdamW:\n",
      "        decay_params = [p for p in self.model.parameters() if p.dim() >= 2]\n",
      "        no_decay_params = [p for p in self.model.parameters() if p.dim() < 2]\n",
      "        params = [\n",
      "            {'params': decay_params, 'weight_decay': weight_decay},\n",
      "            {'params': no_decay_params, 'weight_decay': 0},\n",
      "        ]\n",
      "        optimizer = torch.optim.AdamW(\n",
      "            params=params,\n",
      "            lr=learning_rate,\n",
      "            betas=(beta_1, beta_2),\n",
      "            fused=self.is_on_cuda)\n",
      "        self.checkpointer.init_optimizer(optimizer)\n",
      "        return optimizer\n",
      "    @torch.inference_mode\n",
      "    def validate(self, verbose: bool = True) -> dict[MetricName, MetricValue]:\n",
      "        training = self.model.training\n",
      "        self.model.eval()\n",
      "        valid_iter = tqdm(\n",
      "            iterable=self.valid_dl,\n",
      "            desc='Validation steps',\n",
      "            position=1,\n",
      "            leave=None,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "        for micro_batch in valid_iter:\n",
      "            (input_ids, target_ids,\n",
      "             loss_mask, completion_mask, category_ids,\n",
      "             input_attn_mask, target_attn_mask,\n",
      "             ) = (t.to(self.model.device) for t in micro_batch.values())\n",
      "            model_output = self.model(input_ids, attention_mask=input_attn_mask)\n",
      "            loss_per_token = F.cross_entropy(\n",
      "                input=model_output.logits.flatten(0, 1),\n",
      "                target=target_ids.flatten(0, 1),\n",
      "                reduction='none',\n",
      "            ).view_as(target_ids)\n",
      "            locals_copy = locals().copy()\n",
      "            locals_copy['trainer'] = locals_copy.pop('self')\n",
      "            [metric.micro_batch_update(**locals_copy) for metric in self.valid_metrics.values()]\n",
      "            del locals_copy\n",
      "        valid_log = {name: metric.batch_commit() for name, metric in self.valid_metrics.items()}\n",
      "        self.model.train(training)\n",
      "        return valid_log\n",
      "    def train(self, verbose: bool = True) -> None:\n",
      "        self.model.train()\n",
      "        train_iter = iter(self.train_dl)\n",
      "        pbar_iter = trange(\n",
      "            self.start_iter, self.max_iters,\n",
      "            desc='Optimization steps',\n",
      "            initial=self.start_iter,\n",
      "            total=self.max_iters,\n",
      "            position=0,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "        pbar_accumulation = trange(\n",
      "            self.gradient_accumulation_steps,\n",
      "            desc='Gradient accumulation steps',\n",
      "            position=1,\n",
      "            leave=None,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "        if self.start_iter == 0 and self.valid_dl is not None:\n",
      "            log = Log(iteration_number=0, valid_metrics=self.validate(verbose))\n",
      "            self.logger.log(log)\n",
      "        for iter_num in pbar_iter:\n",
      "            pbar_accumulation.reset()\n",
      "            learning_rate = self.get_lr(iter_num)\n",
      "            for param_group in self.optimizer.param_groups:\n",
      "                param_group['lr'] = learning_rate\n",
      "            for _ in range(self.gradient_accumulation_steps):\n",
      "                (input_ids, target_ids,\n",
      "                 loss_mask, completion_mask, category_ids,\n",
      "                 input_attn_mask, target_attn_mask,\n",
      "                 ) = (t.to(self.model.device) for t in next(train_iter).values())\n",
      "                model_output = self.model(input_ids, attention_mask=input_attn_mask)\n",
      "                loss_per_token = F.cross_entropy(\n",
      "                    input=model_output.logits.flatten(0, 1),\n",
      "                    target=target_ids.flatten(0, 1),\n",
      "                    reduction='none',\n",
      "                ).view_as(target_ids)\n",
      "                loss = loss_per_token[loss_mask].mean() / self.gradient_accumulation_steps\n",
      "                self.grad_scaler.scale(loss).backward()\n",
      "                locals_copy = locals().copy()\n",
      "                locals_copy['trainer'] = locals_copy.pop('self')\n",
      "                [metric.micro_batch_update(**locals_copy) for metric in self.train_metrics.values()]\n",
      "                del locals_copy\n",
      "                pbar_accumulation.update()\n",
      "            if self.max_grad_norm != 0:\n",
      "                self.grad_scaler.unscale_(self.optimizer)\n",
      "                grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
      "            self.grad_scaler.step(self.optimizer)\n",
      "            self.grad_scaler.update()\n",
      "            self.optimizer.zero_grad(set_to_none=True)\n",
      "            log = Log(\n",
      "                iteration_number=iter_num + 1,\n",
      "                train_metrics={name: metric.batch_commit() for name, metric in self.train_metrics.items()},\n",
      "            )\n",
      "            if (iter_num + 1) % self.valid_freq == 0:\n",
      "                log['valid_metrics'] = self.validate(verbose)\n",
      "            self.logger.log(log)\n",
      "            if (iter_num + 1) % self.checkpointing_freq == 0:\n",
      "                self.checkpointer.save_checkpoint(Checkpoint(\n",
      "                    metrics=log,\n",
      "                    model=self.model,\n",
      "                    optimizer_state=self.optimizer.state_dict(),\n",
      "                ))\n",
      "--------------- NEW FILE ---------------\n",
      "class ChainedComposer(ComposerBase, ComposerChain, ReprMixin):\n",
      "    def __init__(self, blocks: Sequence[ComposerBlock], *args, **kwargs) -> None:\n",
      "        ComposerBase.__init__(self, *args, **kwargs)\n",
      "        ComposerChain.__init__(self, *blocks)\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        return self.__call__(datapoint)\n",
      "--------------- NEW FILE ---------------\n",
      "class FilePreprocessor(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "class EmptyLinesRemovalPreprocessor(FilePreprocessor):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        for file in files:\n",
      "            file.content = '\\n'.join(line for line in file.content.split('\\n') if line.strip())\n",
      "        return files\n",
      "class DeclarationOnlyPreprocessor(FilePreprocessor):\n",
      "    ENCODING = 'utf8'\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[File]:\n",
      "        for file in files:\n",
      "            if not file.metadata['filename'].endswith('.py'):\n",
      "                continue\n",
      "            bytecode = bytes(file.content, self.ENCODING)\n",
      "            queue = [self.parser.parse(bytecode).root_node]\n",
      "            declarations = list()\n",
      "            while queue:\n",
      "                node = queue.pop()\n",
      "                queue.extend(reversed(node.children))\n",
      "                if node.type not in ('function_definition', 'class_definition'):\n",
      "                    continue\n",
      "                start = bytecode[:node.start_byte].rfind(b'\\n') + 1\n",
      "                for child in node.children:\n",
      "                    if child.type == ':':\n",
      "                        end = child.end_byte\n",
      "                        break\n",
      "                else:\n",
      "                    warnings.warn(f'A corrupted {file.metadata[\"filename\"]} file structure '\n",
      "                                  f'has been detected in the {datapoint.repo} repository.')\n",
      "                    end = node.end_byte\n",
      "                declaration = bytecode[start:end]\n",
      "                declaration = declaration.decode('utf8') + ' ...'\n",
      "                declarations.append(declaration)\n",
      "            file.content = '\\n'.join(declarations)\n",
      "        return files\n",
      "--------------- NEW FILE ---------------\n",
      "T = TypeVar('T')\n",
      "class FileChunker(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return ChunkRanker, ChunkHarvester\n",
      "class FileGrainedChunker(FileChunker):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        return [Chunk(content=file.content, metadata=file.metadata, file_ref=file) for file in files\n",
      "                if file.metadata['filename'] != 'tinygrad/llops/ops_llvm.py']\n",
      "class CodeSegment(str, Enum):\n",
      "    COMMENT = 'comment_segment'\n",
      "    DOCSTRING = 'docstring_segment'\n",
      "    IMPORT = 'import_segment'\n",
      "    CODE = 'code_segment'\n",
      "    UNDEFINED = 'undefined_segment'\n",
      "    @classmethod\n",
      "    def from_node(cls: Type[T], node: tree_sitter.Node) -> T:\n",
      "        if 'comment' in node.type.lower():\n",
      "            return cls.COMMENT\n",
      "        elif node.type == 'string' and node.text.startswith(CodeSegmentGrainedChunker.DOCSTRING_PREFIX):\n",
      "            return cls.DOCSTRING\n",
      "        elif 'import' in node.type.lower():\n",
      "            return cls.IMPORT\n",
      "        elif node.child_count == 0:\n",
      "            return cls.CODE\n",
      "        else:\n",
      "            return cls.UNDEFINED\n",
      "class Segment(NamedTuple):\n",
      "    start_byte: int\n",
      "    type: CodeSegment\n",
      "class CodeSegmentGrainedChunker(FileChunker):\n",
      "    ENCODING = 'utf8'\n",
      "    DOCSTRING_PREFIX = (bytes(\"'''\", ENCODING), bytes('\"\"\"', ENCODING))\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "    @staticmethod\n",
      "    def dfs_segmentation(root_node: tree_sitter.Node) -> list[Segment]:\n",
      "        segments = list()\n",
      "        queue = [root_node]\n",
      "        while queue:\n",
      "            node = queue.pop()\n",
      "            segment_type = CodeSegment.from_node(node)\n",
      "            if segment_type != CodeSegment.UNDEFINED:\n",
      "                if len(segments) == 0 or segment_type != segments[-1].type:\n",
      "                    segments.append(Segment(node.start_byte, segment_type))\n",
      "            else:\n",
      "                queue.extend(reversed(node.children))\n",
      "        return segments\n",
      "    @staticmethod\n",
      "    def strip_lines(string: str, strip_func: Callable[[str], str]) -> str:\n",
      "        return '\\n'.join(map(strip_func, string.split('\\n')))\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        chunks = list()\n",
      "        for file in files:\n",
      "            if not file.metadata['filename'].endswith('.py'):\n",
      "                chunks.append(Chunk(\n",
      "                    content=file.content,\n",
      "                    metadata=file.metadata | {'segment_type': CodeSegment.UNDEFINED},\n",
      "                    file_ref=file,\n",
      "                ))\n",
      "                continue\n",
      "            if file.metadata['filename'] == 'tinygrad/llops/ops_llvm.py':\n",
      "                continue\n",
      "            bytecode = bytes(file.content, self.ENCODING)\n",
      "            tree = self.parser.parse(bytecode)\n",
      "            segments = self.dfs_segmentation(tree.root_node)\n",
      "            dummy_segment = Segment(len(bytecode), CodeSegment.UNDEFINED)\n",
      "            segments.append(dummy_segment)\n",
      "            comments_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.COMMENT}, file_ref=file)\n",
      "            docstrings_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.DOCSTRING}, file_ref=file)\n",
      "            imports_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.IMPORT}, file_ref=file)\n",
      "            code_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.CODE}, file_ref=file)\n",
      "            prev_edited_chunk = None\n",
      "            for i in range(len(segments) - 1):\n",
      "                start = segments[i].start_byte\n",
      "                end = segments[i + 1].start_byte\n",
      "                segment_str = bytecode[start:end].decode(self.ENCODING)\n",
      "                segment_type = segments[i].type\n",
      "                match segment_type:\n",
      "                    case CodeSegment.COMMENT:\n",
      "                        if prev_edited_chunk is not None and not prev_edited_chunk.content.rstrip(\n",
      "                                whitespace.replace('\\n', '')).endswith('\\n'):\n",
      "                            prev_edited_chunk.content += '\\n' + segment_str.split('\\n')[-1]\n",
      "                        if segment_str.count('\\n') >= 2:\n",
      "                            comments_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "                            prev_edited_chunk = comments_chunk\n",
      "                    case CodeSegment.DOCSTRING:\n",
      "                        docstrings_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "                        prev_edited_chunk = docstrings_chunk\n",
      "                    case CodeSegment.IMPORT:\n",
      "                        imports_chunk.content += segment_str\n",
      "                        prev_edited_chunk = imports_chunk\n",
      "                    case CodeSegment.CODE:\n",
      "                        code_chunk.content += segment_str\n",
      "                        prev_edited_chunk = code_chunk\n",
      "                    case _:\n",
      "                        raise RuntimeError\n",
      "            for chunk in (comments_chunk, docstrings_chunk, imports_chunk, code_chunk):\n",
      "                if chunk.content.strip():\n",
      "                    chunk.content = self.strip_lines(chunk.content.rstrip(), str.rstrip)\n",
      "                    chunks.append(chunk)\n",
      "        return chunks\n",
      "--------------- NEW FILE ---------------\n",
      "@dataclass\n",
      "class File:\n",
      "    content: str\n",
      "    metadata: dict[str, Any]\n",
      "@dataclass\n",
      "class Chunk:\n",
      "    content: str\n",
      "    metadata: dict[str, Any]\n",
      "    file_ref: File\n",
      "    rank: list = field(default_factory=list)\n",
      "BlockArgs = Sequence[File] | Sequence[Chunk]\n",
      "class ComposerBlock(ABC, ReprMixin):\n",
      "    first_block_permit: bool = False\n",
      "    last_block_permit: bool = False\n",
      "    requires_tokenizer: bool = False\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def next_blocks(self) -> tuple[type, ...]:\n",
      "        raise NotImplementedError\n",
      "    def check_next_block(self, block) -> None:\n",
      "        if not isinstance(block, self.next_blocks):\n",
      "            raise ValueError(f'{type(block).__name__} cannot be used after {type(self).__name__}.')\n",
      "    @abstractmethod\n",
      "    def __call__(self, args: BlockArgs, datapoint: Datapoint) -> BlockArgs | str:\n",
      "        raise NotImplementedError\n",
      "class ComposerChain:\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None:\n",
      "        if not blocks:\n",
      "            raise ValueError('ComposerChain instance must contain at least one element.')\n",
      "        elif not blocks[0].first_block_permit:\n",
      "            raise ValueError(f'{type(blocks[0]).__name__} cannot start a chain of blocks.')\n",
      "        elif not blocks[-1].last_block_permit:\n",
      "            raise ValueError(f'{type(blocks[-1]).__name__} cannot end a chain of blocks.')\n",
      "        for block, next_block in zip(blocks[:-1], blocks[1:]):\n",
      "            block.check_next_block(next_block)\n",
      "        self.blocks = blocks\n",
      "    def __call__(self, datapoint: Datapoint) -> str:\n",
      "        x = [\n",
      "            File(content=cnt, metadata={'filename': fn})\n",
      "            for fn, cnt in zip(*datapoint.repo_snapshot.values())\n",
      "        ]\n",
      "        for block in self.blocks:\n",
      "            x = block(x, datapoint)\n",
      "        return x\n",
      "--------------- NEW FILE ---------------\n",
      "class ChunkRanker(ComposerBlock, ABC):\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return ChunkRanker, ChunkSorter\n",
      "class NegativePathDistanceRanker(ChunkRanker):\n",
      "    @staticmethod\n",
      "    def _path_distance(path_from: str, path_to: str) -> int:\n",
      "        path_from = os.path.normpath(path_from)\n",
      "        path_to = os.path.normpath(path_to)\n",
      "        if path_from == path_to:\n",
      "            warnings.warn(f'Data leakage: the {path_from} completion file is contained in the repo snapshot.')\n",
      "        divided_path_from = path_from.split(os.path.sep)\n",
      "        divided_path_to = path_to.split(os.path.sep)\n",
      "        common_len = 0\n",
      "        for segment_from, segment_to in zip(divided_path_from, divided_path_to):\n",
      "            if segment_from == segment_to:\n",
      "                common_len += 1\n",
      "            else:\n",
      "                break\n",
      "        num_residuals_from = len(divided_path_from) - common_len - 1\n",
      "        num_residuals_to = len(divided_path_to) - common_len - 1\n",
      "        return num_residuals_from + num_residuals_to\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        path_to = datapoint.completion_file['filename']\n",
      "        for chunk in chunks:\n",
      "            dist = self._path_distance(chunk.file_ref.metadata['filename'], path_to)\n",
      "            chunk.rank.append(-dist)\n",
      "        return chunks\n",
      "class FileExtensionRanker(ChunkRanker):\n",
      "    def __init__(self, ordered_groups: list[list[str]]) -> None:\n",
      "        self.group_weights = {\n",
      "            extension: weight\n",
      "            for weight, group in enumerate(ordered_groups)\n",
      "            for extension in group\n",
      "        }\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        for chunk in chunks:\n",
      "            extension = '.' + chunk.file_ref.metadata['filename'].split('.')[-1]\n",
      "            chunk.rank.append(self.group_weights.get(extension, -1))\n",
      "        return chunks\n",
      "class FunctionCallRanker(ChunkRanker):\n",
      "    ENCODING = 'utf8'\n",
      "    def __init__(self, is_relative: bool) -> None:\n",
      "        self.is_relative = is_relative\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "    def dfs_count(self, node: tree_sitter.Node) -> int:\n",
      "        return (node.type == 'call') + sum(self.dfs_count(child) for child in node.children)\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        for chunk in chunks:\n",
      "            if chunk.file_ref.metadata['filename'].endswith('.py'):\n",
      "                bytecode = bytes(chunk.content, self.ENCODING)\n",
      "                tree = self.parser.parse(bytecode)\n",
      "                num_calls = self.dfs_count(tree.root_node)\n",
      "            else:\n",
      "                num_calls = 0\n",
      "            if self.is_relative:\n",
      "                num_calls /= len(chunk.content)\n",
      "            chunk.rank.append(num_calls)\n",
      "        return chunks\n",
      "class RandomRanker(ChunkRanker):\n",
      "    def __init__(self, random_seed: int | None) -> None:\n",
      "        self.generator = random.Random(random_seed)\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        ranks = list(range(len(chunks)))\n",
      "        self.generator.shuffle(ranks)\n",
      "        for rank, chunk in zip(ranks, chunks):\n",
      "            chunk.rank.append(rank)\n",
      "        return chunks\n",
      "--------------- NEW FILE ---------------\n",
      "class ComposerBase(ABC):\n",
      "    def __init__(self,\n",
      "                 pre_context_prompt: str,\n",
      "                 post_context_prompt: str,\n",
      "                 path_comment_template: str,\n",
      "                 recalculate_random_category: bool,\n",
      "                 ) -> None:\n",
      "        self.pre_context_prompt = pre_context_prompt\n",
      "        self.post_context_prompt = post_context_prompt\n",
      "        self.path_comment_template = path_comment_template\n",
      "        self.recalculate_random_category = recalculate_random_category\n",
      "    def get_pre_context_prompt(self, datapoint: Datapoint) -> str:\n",
      "        return self.pre_context_prompt.format(datapoint.repo)\n",
      "    def get_post_context_prompt(self, _datapoint: Datapoint) -> str:\n",
      "        return self.post_context_prompt\n",
      "    @abstractmethod\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        raise NotImplementedError\n",
      "    def compose_completion(self, datapoint: Datapoint) -> str:\n",
      "        template_with_inserted_path = self.path_comment_template.format(\n",
      "            filename=datapoint.completion_file['filename'],\n",
      "            content='{content}',\n",
      "        )\n",
      "        for i, line in enumerate(template_with_inserted_path.split('\\n')):\n",
      "            if '{content}' in line:\n",
      "                offset = i\n",
      "                break\n",
      "        else:\n",
      "            raise RuntimeError('The path_comment_template does not contain a content field.')\n",
      "        for line_category_ids in datapoint.completion_lines.values():\n",
      "            for i in range(len(line_category_ids)):\n",
      "                line_category_ids[i] += offset\n",
      "        completion = template_with_inserted_path.format(**datapoint.completion_file)\n",
      "        if not completion.endswith('\\n'):\n",
      "            completion += '\\n'\n",
      "        return completion\n",
      "    def compose(self, datapoint: dict[str, Any]) -> ComposedDatapoint:\n",
      "        datapoint = Datapoint(**datapoint)\n",
      "        if self.recalculate_random_category:\n",
      "            non_categorized_lines = set(range(datapoint.completion_file['content'].count('\\n') + 1))\n",
      "            for category, lines in datapoint.completion_lines.items():\n",
      "                if category != 'random':\n",
      "                    non_categorized_lines.difference_update(lines)\n",
      "            datapoint.completion_lines['random'] = list(non_categorized_lines)\n",
      "        return ComposedDatapoint(\n",
      "            pre_context_prompt=self.get_pre_context_prompt(datapoint),\n",
      "            composed_context=self.compose_context(datapoint) + self.get_post_context_prompt(datapoint),\n",
      "            composed_completion=self.compose_completion(datapoint),\n",
      "            completion_lines=datapoint.completion_lines,\n",
      "        )\n",
      "    def compose_batch(self, batch: BatchDatapoint) -> BatchComposedDatapoint:\n",
      "        batch_keys = batch.keys()\n",
      "        composed_batch_keys = BatchComposedDatapoint.__required_keys__\n",
      "        batch = [self.compose(dict(zip(batch_keys, data))) for data in zip(*batch.values())]\n",
      "        batch = {key: list(map(lambda x: x.get(key), batch)) for key in composed_batch_keys}\n",
      "        return batch\n",
      "    def compose_dataset(self,\n",
      "                        dataset: Dataset,\n",
      "                        writer_batch_size: int = 128,\n",
      "                        num_proc: int = 4,\n",
      "                        **map_kwargs,\n",
      "                        ) -> Dataset:\n",
      "        return dataset.map(\n",
      "            function=self.compose,\n",
      "            remove_columns=map_kwargs.pop('remove_columns', dataset.column_names),\n",
      "            load_from_cache_file=map_kwargs.pop('load_from_cache_file', False),\n",
      "            writer_batch_size=writer_batch_size,\n",
      "            num_proc=num_proc,\n",
      "            desc=map_kwargs.pop('desc', f'Applying {type(self).__name__} to a given dataset'),\n",
      "            **map_kwargs,\n",
      "        )\n",
      "--------------- NEW FILE ---------------\n",
      "def init_composer(cls_name: str,\n",
      "                  loaded_config: DictConfig,\n",
      "                  configs_dir: str,\n",
      "                  tokenizer: PreTrainedTokenizerBase,\n",
      "                  **kwargs,\n",
      "                  ) -> ComposerBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    if cls_name == 'chained_composer':\n",
      "        for path in loaded_config.block_configs:\n",
      "            full_path = os.path.join(configs_dir, 'composer/chained_composer/blocks', path)\n",
      "            block_name = os.path.basename(os.path.dirname(path))\n",
      "            with open(full_path) as stream:\n",
      "                block_config = yaml.safe_load(stream)\n",
      "            if block_config is None:\n",
      "                block_config = dict()\n",
      "            block_cls = BLOCKS_REGISTRY[block_name]\n",
      "            if block_cls.requires_tokenizer:\n",
      "                block_config['tokenizer'] = tokenizer\n",
      "            block = block_cls(**block_config)\n",
      "            config.blocks.append(block)\n",
      "    composer = COMPOSERS_REGISTRY[cls_name](**config.dict)\n",
      "    return composer\n",
      "--------------- NEW FILE ---------------\n",
      "class WandbLogger(LocalLogger):\n",
      "    def __init__(self,\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 **wandb_init_kwargs,\n",
      "                 ) -> None:\n",
      "        super().__init__(train_csv, valid_csv, stdout_file, stderr_file, directory)\n",
      "        wandb_init_kwargs['resume'] = wandb_init_kwargs.get('resume', checkpointer.get_wandb_resume_mode())\n",
      "        wandb_init_kwargs['id'] = wandb_init_kwargs.get('id', wandb_init_kwargs['name'])\n",
      "        wandb.init(**wandb_init_kwargs)\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "            return super().log(metrics)\n",
      "        wandb_log = dict()\n",
      "        if 'train_metrics' in metrics:\n",
      "            wandb_log['train'] = metrics['train_metrics']\n",
      "        if 'valid_metrics' in metrics:\n",
      "            wandb_log['validation'] = metrics['valid_metrics']\n",
      "        wandb.log(wandb_log, step=metrics['iteration_number'])\n",
      "        return super().log(metrics)\n",
      "--------------- NEW FILE ---------------\n",
      "def get_free_device(used_memory_upper_bound: float = 0.001) -> torch.device:\n",
      "    if hasattr(get_free_device, 'allocated'):\n",
      "        return get_free_device.allocated\n",
      "    for gpu_index in range(torch.cuda.device_count()):\n",
      "        gpu_pid_stats = subprocess.check_output([\n",
      "            'nvidia-smi', f'-i={gpu_index}', '--query-compute-apps=pid', '--format=csv,noheader',\n",
      "        ], encoding='utf-8')\n",
      "        gpu_mem_stats = subprocess.check_output([\n",
      "            'nvidia-smi', f'-i={gpu_index}', '--query-gpu=memory.used,memory.total', '--format=csv,noheader',\n",
      "        ], encoding='utf-8')\n",
      "        mem_used, mem_total = map(int, gpu_mem_stats.replace('MiB', '').split(', '))\n",
      "        if not gpu_pid_stats and mem_used / mem_total <= used_memory_upper_bound:\n",
      "            get_free_device.allocated = torch.device(f'cuda:{gpu_index}')\n",
      "            return get_free_device.allocated\n",
      "    warnings.warn('No CUDA devices were found. CPU will be used.')\n",
      "    return torch.device('cpu')\n",
      "def get_optimal_dtype() -> torch.dtype:\n",
      "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
      "        return torch.bfloat16\n",
      "    else:\n",
      "        warnings.warn('torch.bfloat16 is not supported. torch.float16 '\n",
      "                      'with gradient scaling will be used instead.')\n",
      "        return torch.float16\n",
      "--------------- NEW FILE ---------------\n",
      "class ReprMixin:\n",
      "    _init_args = None\n",
      "    _init_kwargs = None\n",
      "    def __init_subclass__(cls, **kwargs) -> None:\n",
      "        super().__init_subclass__(**kwargs)\n",
      "        original_init = cls.__init__\n",
      "        def wrapped_init(self, *init_args, **init_kwargs) -> None:\n",
      "            if cls == type(self):\n",
      "                self._init_args = init_args\n",
      "                self._init_kwargs = init_kwargs\n",
      "            original_init(self, *init_args, **init_kwargs)\n",
      "        cls.__init__ = wrapped_init\n",
      "    def __repr__(self) -> str:\n",
      "        args_str = ', '.join(\n",
      "            [\n",
      "                f\"'{arg}'\" if isinstance(arg, str) else repr(arg)\n",
      "                for arg in self._init_args\n",
      "            ] + [\n",
      "                f\"{key}='{value}'\" if isinstance(value, str) else f'{key}={value!r}'\n",
      "                for key, value in self._init_kwargs.items()\n",
      "            ])\n",
      "        return f'{type(self).__name__}({args_str})'\n",
      "--------------- NEW FILE ---------------\n",
      "def init_checkpointer(cls_name: str, loaded_config: DictConfig, **kwargs) -> CheckpointManager:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    checkpointer = CHECKPOINTERS_REGISTRY[cls_name](**config.dict)\n",
      "    return checkpointer\n",
      "--------------- NEW FILE ---------------\n",
      "def init_preprocessor(cls_name: str, loaded_config: DictConfig, **kwargs) -> PreprocessorBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    preprocessor = PREPROCESSORS_REGISTRY[cls_name](**config.dict)\n",
      "    return preprocessor\n",
      "--------------- NEW FILE ---------------\n",
      "class JsonFormatter(logging.Formatter):\n",
      "    def format(self, record: logging.LogRecord) -> str:\n",
      "        message_dict = {\n",
      "            'timestamp': self.formatTime(record, self.datefmt),\n",
      "            'level': record.levelname,\n",
      "            'content': record.msg,\n",
      "        }\n",
      "        indent = '    '\n",
      "        json_string = json.dumps(message_dict, indent=4)\n",
      "        json_string = indent.join(json_string.splitlines(keepends=True))\n",
      "        json_string = indent + json_string\n",
      "        return json_string\n",
      "class JsonHandler(logging.FileHandler):\n",
      "    def emit(self, record: logging.LogRecord) -> None:\n",
      "        if not os.path.exists(self.baseFilename) or os.stat(self.baseFilename).st_size == 0:\n",
      "            self.stream.write('[\\n')\n",
      "        else:\n",
      "            self.stream.seek(self.stream.tell() - 1)\n",
      "            self.stream.truncate()\n",
      "            self.stream.write(',\\n')\n",
      "        super().emit(record)\n",
      "    def close(self) -> None:\n",
      "        self.stream.seek(self.stream.tell() - 1)\n",
      "        self.stream.write(']')\n",
      "        super().close()\n",
      "class LocalLogger(LoggerBase):\n",
      "    def __init__(self,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 ) -> None:\n",
      "        if train_csv == valid_csv:\n",
      "            raise ValueError('The names of the train_csv and valid_csv files must be different.')\n",
      "        train_csv, valid_csv, stdout_file, stderr_file = map(\n",
      "            lambda x: os.path.join(directory, x),\n",
      "            [train_csv, valid_csv, stdout_file, stderr_file],\n",
      "        )\n",
      "        if os.path.exists(train_csv):\n",
      "            with open(train_csv) as stream:\n",
      "                self.last_logged_iter = max(map(lambda x: int(x.split(',')[0]), stream.readlines()[1:]))\n",
      "        else:\n",
      "            self.last_logged_iter = -1\n",
      "        self.train_csv = train_csv\n",
      "        self.valid_csv = valid_csv\n",
      "        self.logger = logging.getLogger(__name__)\n",
      "        self.logger.propagate = False\n",
      "        self.logger.setLevel(logging.DEBUG)\n",
      "        formatter = JsonFormatter()\n",
      "        stdout_handler = JsonHandler(stdout_file)\n",
      "        stdout_handler.setLevel(logging.INFO)\n",
      "        stdout_handler.setFormatter(formatter)\n",
      "        stdout_handler.addFilter(lambda record: record.levelno < logging.WARNING)\n",
      "        if stderr_file == stdout_file:\n",
      "            stderr_handler = stdout_handler\n",
      "        else:\n",
      "            stderr_handler = JsonHandler(stderr_file)\n",
      "            stderr_handler.setLevel(logging.WARNING)\n",
      "            stderr_handler.setFormatter(formatter)\n",
      "            stderr_handler.addFilter(lambda record: record.levelno >= logging.WARNING)\n",
      "        self.logger.addHandler(stdout_handler)\n",
      "        self.logger.addHandler(stderr_handler)\n",
      "        warnings.showwarning = self.warning_handler\n",
      "        sys.excepthook = self.exception_handler\n",
      "        datasets_logger = datasets.utils.logging.get_logger()\n",
      "        transformers_logger = transformers.utils.logging.get_logger()\n",
      "        datasets_logger.handlers = self.logger.handlers\n",
      "        transformers_logger.handlers = self.logger.handlers\n",
      "    @staticmethod\n",
      "    def write_metrics_to_csv(metrics: dict[MetricName, MetricValue], path: str) -> None:\n",
      "        with open(path, mode='a', newline='') as stream:\n",
      "            writer = csv.DictWriter(stream, fieldnames=metrics.keys())\n",
      "            if stream.tell() == 0:\n",
      "                writer.writeheader()\n",
      "            writer.writerow(metrics)\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "            return metrics\n",
      "        iter_num = {'iter_num': metrics['iteration_number']}\n",
      "        if 'train_metrics' in metrics:\n",
      "            self.write_metrics_to_csv(iter_num | metrics['train_metrics'], self.train_csv)\n",
      "        if 'valid_metrics' in metrics:\n",
      "            self.write_metrics_to_csv(iter_num | metrics['valid_metrics'], self.valid_csv)\n",
      "        return metrics\n",
      "    def message(self, message: Message) -> Message:\n",
      "        self.logger.info(message)\n",
      "        return message\n",
      "    def warning_handler(self, message: Warning, category: type, path: str, lineno: int, *_kwargs) -> None:\n",
      "        self.logger.warning({\n",
      "            'category': category.__name__,\n",
      "            'location': f'{path}:{lineno}',\n",
      "            'message': str(message),\n",
      "        })\n",
      "    def exception_handler(self, exc_type: type, exc_value: Exception, exc_traceback: TracebackType) -> NoReturn:\n",
      "        if issubclass(exc_type, KeyboardInterrupt):\n",
      "            self.message('Process was stopped due to a keyboard interrupt.')\n",
      "        else:\n",
      "            self.logger.error({\n",
      "                'category': exc_type.__name__,\n",
      "                'traceback': [{\n",
      "                    'location': f'{filename}:{lineno} in {func_name}',\n",
      "                    'line': line,\n",
      "                } for filename, lineno, func_name, line in traceback.extract_tb(exc_traceback)],\n",
      "                'message': str(exc_value),\n",
      "            })\n",
      "            self.message('Process finished with a non-zero exit code.')\n",
      "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
      "--------------- NEW FILE ---------------\n",
      "def init_trainer(cls_name: str, loaded_config: DictConfig, **kwargs) -> TrainerBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    trainer = TRAINERS_REGISTRY[cls_name](**config.dict)\n",
      "    return trainer\n",
      "--------------- NEW FILE ---------------\n",
      "def init_logger(cls_name: str, loaded_config: DictConfig, **kwargs) -> LoggerBase:\n",
      "    config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "    logger = LOGGERS_REGISTRY[cls_name](**config.dict)\n",
      "    return logger\n",
      "--------------- NEW FILE ---------------\n",
      "def train_test_split(dataset: Dataset,\n",
      "                     test_size: int,\n",
      "                     upper_bound_per_repo: int,\n",
      "                     random_seed: int | None = None,\n",
      "                     ) -> tuple[Dataset, Dataset | None]:\n",
      "    if test_size == 0:\n",
      "        return dataset, None\n",
      "    generator = random.Random(random_seed)\n",
      "    queue = defaultdict(list)\n",
      "    repos_enum = list(enumerate(dataset['repo']))\n",
      "    generator.shuffle(repos_enum)\n",
      "    for idx, repo in repos_enum:\n",
      "        queue[repo].append(idx)\n",
      "    queue = list(queue.items())\n",
      "    generator.shuffle(queue)\n",
      "    train_repos_ids = set(range(len(dataset)))\n",
      "    test_repos_ids = set()\n",
      "    cur_test_size = 0\n",
      "    while cur_test_size != test_size:\n",
      "        if queue:\n",
      "            repo, ids = queue.pop()\n",
      "        else:\n",
      "            raise ValueError(\n",
      "                'There are not enough data points in the original dataset to satisfy both the '\n",
      "                'test_size and upper_bound_per_repo arguments. Try either decreasing the test_size '\n",
      "                'or increasing the upper_bound_per_repo.')\n",
      "        num_new_samples = min(upper_bound_per_repo, test_size - cur_test_size, len(ids))\n",
      "        train_repos_ids.difference_update(ids)\n",
      "        test_repos_ids.update(ids[:num_new_samples])\n",
      "        cur_test_size += num_new_samples\n",
      "    train_ds = dataset.select(train_repos_ids)\n",
      "    test_ds = dataset.select(test_repos_ids)\n",
      "    return train_ds, test_ds\n",
      "def set_transform(train_ds: Dataset,\n",
      "                  test_ds: Dataset | None,\n",
      "                  composer: ComposerBase,\n",
      "                  preprocessor: PreprocessorBase,\n",
      "                  ) -> None:\n",
      "    transform = lambda x: preprocessor(composer.compose_batch(x))\n",
      "    train_ds.set_transform(transform)\n",
      "    if test_ds is not None:\n",
      "        test_ds.set_transform(transform)\n",
      "--------------- NEW FILE ---------------\n",
      "METRICS_REGISTRY = {\n",
      "    'cross_entropy': loss_based_metric_factory(CrossEntropy),\n",
      "    'detached_cross_entropy': detached_metric_factory(CrossEntropy),\n",
      "    'completion_cross_entropy': completion_metric_factory(CrossEntropy),\n",
      "    'context_cross_entropy': context_metric_factory(CrossEntropy),\n",
      "    'full_cross_entropy': full_metric_factory(CrossEntropy),\n",
      "    'commited_cross_entropy': categorized_metric_factory(CrossEntropy, 'commited'),\n",
      "    'common_cross_entropy': categorized_metric_factory(CrossEntropy, 'common'),\n",
      "    'infile_cross_entropy': categorized_metric_factory(CrossEntropy, 'infile'),\n",
      "    'inproject_cross_entropy': categorized_metric_factory(CrossEntropy, 'inproject'),\n",
      "    'non_informative_cross_entropy': categorized_metric_factory(CrossEntropy, 'non_informative'),\n",
      "    'random_cross_entropy': categorized_metric_factory(CrossEntropy, 'random'),\n",
      "    'other_cross_entropy': categorized_metric_factory(CrossEntropy, 'other'),\n",
      "    'epoch': EpochCounter,\n",
      "    'learning_rate': lazy_statistic_factory('learning_rate'),\n",
      "}\n",
      "METRICS_REGISTRY.update({\n",
      "    f'ema_{name}': ema_factory(cls) for name, cls in METRICS_REGISTRY.items()\n",
      "})\n",
      "--------------- NEW FILE ---------------\n",
      "T = TypeVar('T')\n",
      "@dataclass\n",
      "class ConfigBase:\n",
      "    def __str__(self) -> str:\n",
      "        return pformat(self)\n",
      "    @classmethod\n",
      "    def from_dict(cls: Type[T], dictionary: dict[str, Any]) -> T:\n",
      "        config_fields = set(field.name for field in fields(cls))\n",
      "        kwargs = {key: value for key, value in dictionary.items() if key in config_fields}\n",
      "        return cls(**kwargs)\n",
      "    @classmethod\n",
      "    def from_yaml(cls: Type[T], path: str | None = None) -> T:\n",
      "        if path is None:\n",
      "            path = cls._default_path\n",
      "        with open(path) as stream:\n",
      "            return cls(**yaml.safe_load(stream))\n",
      "    dict = property(vars)\n",
      "--------------- NEW FILE ---------------\n",
      "class TopKCheckpointManager(CheckpointManager):\n",
      "    def __init__(self, max_checkpoints_num: int, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.max_checkpoints_num = max_checkpoints_num\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "        super().save_checkpoint(checkpoint)\n",
      "        checkpoints = next(os.walk(self.directory))[1]\n",
      "        checkpoints = sorted(checkpoints, key=self.get_checkpoint_score)\n",
      "        while len(checkpoints) > self.max_checkpoints_num:\n",
      "            checkpoint2del = checkpoints.pop()\n",
      "            checkpoint2del = os.path.join(self.directory, checkpoint2del)\n",
      "            shutil.rmtree(checkpoint2del)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648a872-43f9-46f5-bfd5-1df52b6a1c3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Extension Ranking Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4278649b-61e2-4978-b23a-91e3356f5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ChainedComposer([\n",
    "    FileGrainedChunker(),\n",
    "    FileExtensionRanker([['.py'], ['.yaml']]),  # YAML files are placed at the end\n",
    "    LexicographicSorter(),\n",
    "    PathCommentHarvester(chunks_sep='\\n\\n', path_comment_template='# {filename}\\n{content}'),\n",
    "    LineStripPostprocessor(),\n",
    "],\n",
    "    **composer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbf4a150-55ea-4e14-8d23-dcc7f7fd9244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ../pipeline/environment/hardware.py\n",
      "import subprocess\n",
      "import warnings\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "def get_free_device(used_memory_upper_bound: float = 0.001) -> torch.device:\n",
      "if hasattr(get_free_device, 'allocated'):\n",
      "return get_free_device.allocated\n",
      "\n",
      "for gpu_index in range(torch.cuda.device_count()):\n",
      "gpu_pid_stats = subprocess.check_output([\n",
      "'nvidia-smi', f'-i={gpu_index}', '--query-compute-apps=pid', '--format=csv,noheader',\n",
      "], encoding='utf-8')\n",
      "gpu_mem_stats = subprocess.check_output([\n",
      "'nvidia-smi', f'-i={gpu_index}', '--query-gpu=memory.used,memory.total', '--format=csv,noheader',\n",
      "], encoding='utf-8')\n",
      "\n",
      "mem_used, mem_total = map(int, gpu_mem_stats.replace('MiB', '').split(', '))\n",
      "\n",
      "if not gpu_pid_stats and mem_used / mem_total <= used_memory_upper_bound:\n",
      "get_free_device.allocated = torch.device(f'cuda:{gpu_index}')\n",
      "return get_free_device.allocated\n",
      "\n",
      "warnings.warn('No CUDA devices were found. CPU will be used.')\n",
      "return torch.device('cpu')\n",
      "\n",
      "\n",
      "def get_optimal_dtype() -> torch.dtype:\n",
      "if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
      "return torch.bfloat16\n",
      "else:\n",
      "warnings.warn('torch.bfloat16 is not supported. torch.float16 '\n",
      "'with gradient scaling will be used instead.')\n",
      "return torch.float16\n",
      "\n",
      "\n",
      "# ../pipeline/data/categories.py\n",
      "from typing import Literal\n",
      "\n",
      "CategoryType = Literal['commited', 'common', 'infile', 'inproject', 'non_informative', 'random', 'other']\n",
      "\n",
      "ID2CATEGORY = [\n",
      "'commited',\n",
      "'common',\n",
      "'infile',\n",
      "'inproject',\n",
      "'non_informative',\n",
      "'random',\n",
      "'other',\n",
      "]\n",
      "CATEGORY2ID = {category: i for i, category in enumerate(ID2CATEGORY)}\n",
      "UNDEFINED_CATEGORY_ID = -1\n",
      "\n",
      "\n",
      "# ../pipeline/data/dataset.py\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessorBase\n",
      "\n",
      "import random\n",
      "from collections import defaultdict\n",
      "\n",
      "from datasets import Dataset\n",
      "\n",
      "\n",
      "def train_test_split(dataset: Dataset,\n",
      "test_size: int,\n",
      "upper_bound_per_repo: int,\n",
      "random_seed: int | None = None,\n",
      ") -> tuple[Dataset, Dataset | None]:\n",
      "if test_size == 0:\n",
      "return dataset, None\n",
      "\n",
      "generator = random.Random(random_seed)\n",
      "queue = defaultdict(list)\n",
      "repos_enum = list(enumerate(dataset['repo']))\n",
      "generator.shuffle(repos_enum)\n",
      "\n",
      "for idx, repo in repos_enum:\n",
      "queue[repo].append(idx)\n",
      "\n",
      "queue = list(queue.items())\n",
      "generator.shuffle(queue)\n",
      "\n",
      "train_repos_ids = set(range(len(dataset)))\n",
      "test_repos_ids = set()\n",
      "cur_test_size = 0\n",
      "\n",
      "while cur_test_size != test_size:\n",
      "if queue:\n",
      "repo, ids = queue.pop()\n",
      "else:\n",
      "raise ValueError(\n",
      "'There are not enough data points in the original dataset to satisfy both the '\n",
      "'test_size and upper_bound_per_repo arguments. Try either decreasing the test_size '\n",
      "'or increasing the upper_bound_per_repo.')\n",
      "\n",
      "num_new_samples = min(upper_bound_per_repo, test_size - cur_test_size, len(ids))\n",
      "\n",
      "train_repos_ids.difference_update(ids)\n",
      "test_repos_ids.update(ids[:num_new_samples])\n",
      "cur_test_size += num_new_samples\n",
      "\n",
      "train_ds = dataset.select(train_repos_ids)\n",
      "test_ds = dataset.select(test_repos_ids)\n",
      "\n",
      "return train_ds, test_ds\n",
      "\n",
      "\n",
      "def set_transform(train_ds: Dataset,\n",
      "test_ds: Dataset | None,\n",
      "composer: ComposerBase,\n",
      "preprocessor: PreprocessorBase,\n",
      ") -> None:\n",
      "transform = lambda x: preprocessor(composer.compose_batch(x))\n",
      "train_ds.set_transform(transform)\n",
      "if test_ds is not None:\n",
      "test_ds.set_transform(transform)\n",
      "\n",
      "\n",
      "# ../pipeline/data/datapoint.py\n",
      "from dataclasses import dataclass\n",
      "from typing import TypedDict\n",
      "\n",
      "\n",
      "class CompletionFile(TypedDict):\n",
      "filename: str\n",
      "content: str\n",
      "\n",
      "\n",
      "class CompletionLines(TypedDict, total=False):\n",
      "commited: list[int]\n",
      "common: list[int]\n",
      "infile: list[int]\n",
      "inproject: list[int]\n",
      "non_informative: list[int]\n",
      "random: list[int]\n",
      "other: list[int]\n",
      "\n",
      "\n",
      "class RepoSnapshot(TypedDict):\n",
      "filename: list[str]\n",
      "content: list[str]\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Datapoint:\n",
      "repo: str\n",
      "commit_hash: str\n",
      "completion_file: CompletionFile\n",
      "completion_lines: CompletionLines\n",
      "repo_snapshot: RepoSnapshot\n",
      "completion_lines_raw: CompletionLines | None = None\n",
      "\n",
      "\n",
      "class BatchDatapoint(TypedDict):\n",
      "repo: list[str]\n",
      "commit_hash: list[str]\n",
      "completion_file: list[CompletionFile]\n",
      "completion_lines: list[CompletionLines]\n",
      "repo_snapshot: list[RepoSnapshot]\n",
      "completion_lines_raw: list[CompletionLines]\n",
      "\n",
      "\n",
      "# ../pipeline/data/composed_datapoint.py\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "\n",
      "from typing import TypedDict\n",
      "\n",
      "\n",
      "class ComposedDatapoint(TypedDict):\n",
      "pre_context_prompt: str\n",
      "composed_context: str\n",
      "composed_completion: str\n",
      "completion_lines: CompletionLines\n",
      "\n",
      "\n",
      "class BatchComposedDatapoint(TypedDict):\n",
      "pre_context_prompt: list[str]\n",
      "composed_context: list[str]\n",
      "composed_completion: list[str]\n",
      "completion_lines: list[CompletionLines]\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/file_level_preprocessor.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class FileLevelPreprocessor(CompletionLossPreprocessor):\n",
      "def calc_lens(self,\n",
      "prompt: torch.Tensor,\n",
      "context: torch.Tensor,\n",
      "completion: torch.Tensor,\n",
      ") -> tuple[int, int, int]:\n",
      "prompt_len, _, completion_len = super().calc_lens(prompt, context, completion)\n",
      "return prompt_len, -len(context), completion_len\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessorBase\n",
      "from pipeline.data.preprocessors.preprocessors_registry import PREPROCESSORS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_preprocessor(cls_name: str, loaded_config: DictConfig, **kwargs) -> PreprocessorBase:\n",
      "config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "preprocessor = PREPROCESSORS_REGISTRY[cls_name](**config.dict)\n",
      "return preprocessor\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/preprocessors_registry.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "from pipeline.data.preprocessors.file_level_preprocessor import FileLevelPreprocessor\n",
      "from pipeline.data.preprocessors.lm_preprocessor import LMPreprocessor\n",
      "\n",
      "PREPROCESSORS_REGISTRY = {\n",
      "'completion_loss_preprocessor': CompletionLossPreprocessor,\n",
      "'file_level_preprocessor': FileLevelPreprocessor,\n",
      "'lm_preprocessor': LMPreprocessor,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/completion_loss_preprocessor.py\n",
      "from pipeline.data.categories import CATEGORY2ID, UNDEFINED_CATEGORY_ID\n",
      "from pipeline.data.composed_datapoint import BatchComposedDatapoint\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessedBatch, PreprocessorBase\n",
      "\n",
      "import math\n",
      "import re\n",
      "import warnings\n",
      "\n",
      "import torch\n",
      "from transformers import BatchEncoding, PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class CompletionLossPreprocessor(PreprocessorBase):\n",
      "def __init__(self,\n",
      "tokenizer: PreTrainedTokenizerBase,\n",
      "max_seq_len: int,\n",
      "context_tokens: int | float,\n",
      "loss_ratio: float,\n",
      "num_chars_per_token: int,\n",
      "padding: bool,\n",
      "verbose: bool,\n",
      ") -> None:\n",
      "if not 0 < loss_ratio <= 1:\n",
      "raise ValueError('loss_ratio must be selected from the interval (0, 1]. '\n",
      "f'Got {loss_ratio} instead.')\n",
      "\n",
      "if padding:\n",
      "tokenizer.deprecation_warnings['Asking-to-pad-a-fast-tokenizer'] = True\n",
      "tokenizer.deprecation_warnings['sequence-length-is-longer-than-the-specified-maximum'] = True\n",
      "\n",
      "self.tokenizer = tokenizer\n",
      "self.max_seq_len = max_seq_len\n",
      "\n",
      "if isinstance(context_tokens, float):\n",
      "if not 0 <= context_tokens <= 1:\n",
      "raise ValueError('The context ratio must be between 0 and 1.')\n",
      "\n",
      "context_tokens = int(max_seq_len * context_tokens)\n",
      "self.context_tokens = context_tokens\n",
      "\n",
      "self.loss_ratio = loss_ratio\n",
      "self.num_chars_per_token = num_chars_per_token\n",
      "self.padding = padding\n",
      "self.verbose = verbose\n",
      "\n",
      "def _inc_num_chars_per_token(self) -> None:\n",
      "old_value = self.num_chars_per_token\n",
      "self.num_chars_per_token = math.ceil(1.5 * self.num_chars_per_token)\n",
      "\n",
      "if self.verbose:\n",
      "warnings.warn(\n",
      "f'num_chars_per_token has been increased from {old_value} to {self.num_chars_per_token} '\n",
      "'due to an underestimation of the length of the truncated character sequence.')\n",
      "\n",
      "def tokenize_pre_context_prompt(self, prompts: list[str]) -> BatchEncoding:\n",
      "char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "\n",
      "tokenized_prompts = self.tokenizer(\n",
      "text=[prompt[-char_trunc_upper_bound:] for prompt in prompts],\n",
      "add_special_tokens=False,\n",
      "return_attention_mask=False,\n",
      ")\n",
      "\n",
      "for tokenized_prompt, prompt in zip(tokenized_prompts.input_ids, prompts):\n",
      "overflow_chars = len(prompt) > char_trunc_upper_bound\n",
      "underflow_tokens = len(tokenized_prompt) < self.max_seq_len\n",
      "\n",
      "if overflow_chars and underflow_tokens:\n",
      "self._inc_num_chars_per_token()\n",
      "return self.tokenize_pre_context_prompt(prompts)\n",
      "\n",
      "return tokenized_prompts\n",
      "\n",
      "def tokenize_composed_completion(self, completions: list[str]) -> BatchEncoding:\n",
      "char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "trunc_completions = [completion[:char_trunc_upper_bound] for completion in completions]\n",
      "\n",
      "tokenized_completions = self.tokenizer(\n",
      "text=trunc_completions,\n",
      "add_special_tokens=False,\n",
      "return_attention_mask=False,\n",
      "return_offsets_mapping=True,\n",
      "return_length=True,\n",
      ")\n",
      "\n",
      "tokenized_completions.length = torch.tensor(tokenized_completions.length)\n",
      "overflow_chars = torch.tensor([len(completion) > char_trunc_upper_bound for completion in completions])\n",
      "underflow_tokens = (tokenized_completions.length < self.max_seq_len)\n",
      "\n",
      "if torch.any(overflow_chars & underflow_tokens):\n",
      "self._inc_num_chars_per_token()\n",
      "return self.tokenize_composed_completion(completions)\n",
      "\n",
      "tokenized_completions['newline_positions'] = [\n",
      "[match.start() for match in re.finditer('\\n', completion)]\n",
      "for completion in trunc_completions\n",
      "]\n",
      "\n",
      "return tokenized_completions\n",
      "\n",
      "def tokenize_composed_context(self, contexts: list[str]) -> BatchEncoding:\n",
      "char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "\n",
      "tokenized_contexts = self.tokenizer(\n",
      "text=[ctx[-char_trunc_upper_bound:] for ctx in contexts],\n",
      "add_special_tokens=False,\n",
      "return_attention_mask=False,\n",
      ")\n",
      "\n",
      "for tokenized_ctx, ctx in zip(tokenized_contexts.input_ids, contexts):\n",
      "overflow_chars = len(ctx) > char_trunc_upper_bound\n",
      "underflow_tokens = len(tokenized_ctx) < self.max_seq_len\n",
      "\n",
      "if overflow_chars and underflow_tokens:\n",
      "self._inc_num_chars_per_token()\n",
      "return self.tokenize_composed_context(contexts)\n",
      "\n",
      "if not overflow_chars and len(tokenized_ctx) < self.context_tokens:\n",
      "if not self.padding:\n",
      "raise ValueError('Not enough data to satisfy context_tokens.')\n",
      "elif self.verbose:\n",
      "warnings.warn('Not enough data to satisfy context_tokens.')\n",
      "\n",
      "return tokenized_contexts\n",
      "\n",
      "def calc_lens(self,\n",
      "prompt: torch.Tensor,\n",
      "context: torch.Tensor,\n",
      "completion: torch.Tensor,\n",
      ") -> tuple[int, int, int]:\n",
      "if len(context) >= self.context_tokens:\n",
      "prompt_len = min(len(prompt), self.max_seq_len - self.context_tokens)\n",
      "completion_len = min(len(completion), self.max_seq_len - self.context_tokens - prompt_len)\n",
      "context_len = self.max_seq_len - prompt_len - completion_len\n",
      "else:\n",
      "context_len = len(context)\n",
      "prompt_len = min(len(prompt), self.max_seq_len - context_len)\n",
      "completion_len = self.max_seq_len - prompt_len - context_len\n",
      "\n",
      "return prompt_len, context_len, completion_len\n",
      "\n",
      "@staticmethod\n",
      "def _get_partial_completion_mask(tokenized_completions: BatchEncoding,\n",
      "target_attn_mask: torch.Tensor,\n",
      "ratio: float,\n",
      ") -> torch.Tensor:\n",
      "position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "completions_len = tokenized_completions.length.unsqueeze(-1)\n",
      "num_masked_tokens = (ratio * completions_len).ceil().long()\n",
      "mask = (num_informative_tokens - num_masked_tokens <= position_ids)\n",
      "return mask.logical_and(target_attn_mask)\n",
      "\n",
      "def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "return self._get_partial_completion_mask(*args, **kwargs, ratio=self.loss_ratio)\n",
      "\n",
      "def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "return self._get_partial_completion_mask(*args, **kwargs, ratio=1)\n",
      "\n",
      "@staticmethod\n",
      "def get_category_ids(tokenized_completions: BatchEncoding,\n",
      "completion_lines: list[CompletionLines],\n",
      "target_attn_mask: torch.Tensor,\n",
      ") -> torch.Tensor:\n",
      "category_ids = torch.full_like(target_attn_mask, UNDEFINED_CATEGORY_ID)\n",
      "t_completion_start = (target_attn_mask.sum(dim=-1) - tokenized_completions.length).tolist()\n",
      "batch_size = len(tokenized_completions.length)\n",
      "\n",
      "for sample_idx in range(batch_size):\n",
      "newline_positions = tokenized_completions.newline_positions[sample_idx]\n",
      "offset_mapping = tokenized_completions.offset_mapping[sample_idx]\n",
      "\n",
      "newline_positions.append(float('inf'))\n",
      "line2category = {\n",
      "line_idx: CATEGORY2ID[category]\n",
      "for category, line_category_ids in completion_lines[sample_idx].items()\n",
      "for line_idx in line_category_ids\n",
      "}\n",
      "\n",
      "line_idx = 0\n",
      "category_id = line2category.get(line_idx)\n",
      "\n",
      "for token_idx, (char_start, _) in enumerate(offset_mapping, start=t_completion_start[sample_idx]):\n",
      "if char_start > newline_positions[line_idx]:\n",
      "line_idx += 1\n",
      "category_id = line2category.get(line_idx)\n",
      "\n",
      "if category_id is not None:\n",
      "category_ids[sample_idx, token_idx] = category_id\n",
      "\n",
      "return category_ids\n",
      "\n",
      "def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "tokenized_prompts = self.tokenize_pre_context_prompt(batch['pre_context_prompt'])\n",
      "tokenized_completions = self.tokenize_composed_completion(batch['composed_completion'])\n",
      "tokenized_contexts = self.tokenize_composed_context(batch['composed_context'])\n",
      "\n",
      "tokenized_batch = list()\n",
      "batch_size = len(tokenized_completions.length)\n",
      "\n",
      "for sample_idx in range(batch_size):\n",
      "prompt = tokenized_prompts.input_ids[sample_idx]\n",
      "context = tokenized_contexts.input_ids[sample_idx]\n",
      "completion = tokenized_completions.input_ids[sample_idx]\n",
      "\n",
      "prompt_len, context_len, completion_len = self.calc_lens(prompt, context, completion)\n",
      "\n",
      "prompt = [self.tokenizer.bos_token_id] + prompt[-prompt_len:]\n",
      "context = context[-context_len:]\n",
      "completion = completion[:completion_len]\n",
      "\n",
      "tokenized_completions.offset_mapping[sample_idx] = \\\n",
      "tokenized_completions.offset_mapping[sample_idx][:completion_len]\n",
      "tokenized_completions.length[sample_idx] = len(completion)\n",
      "\n",
      "tokenized_batch.append(prompt + context + completion)\n",
      "\n",
      "self.tokenizer.padding_side = 'right'\n",
      "padded_batch = self.tokenizer.pad(\n",
      "encoded_inputs={'input_ids': tokenized_batch},\n",
      "padding='longest',\n",
      "return_attention_mask=True,\n",
      "return_tensors='pt')\n",
      "input_attn_mask = padded_batch.attention_mask[:, :-1]\n",
      "target_attn_mask = padded_batch.attention_mask[:, 1:]\n",
      "\n",
      "return PreprocessedBatch(\n",
      "input_ids=padded_batch.input_ids[:, :-1],\n",
      "target_ids=padded_batch.input_ids[:, 1:],\n",
      "loss_mask=self.get_loss_mask(tokenized_completions, target_attn_mask),\n",
      "completion_mask=self.get_completion_mask(tokenized_completions, target_attn_mask),\n",
      "category_ids=self.get_category_ids(tokenized_completions, batch['completion_lines'], target_attn_mask),\n",
      "input_attn_mask=input_attn_mask,\n",
      "target_attn_mask=target_attn_mask.bool(),\n",
      ")\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/lm_preprocessor.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "\n",
      "import torch\n",
      "from transformers import BatchEncoding\n",
      "\n",
      "\n",
      "class LMPreprocessor(CompletionLossPreprocessor):\n",
      "def get_loss_mask(self,\n",
      "_tokenized_completions: BatchEncoding,\n",
      "target_attn_mask: torch.Tensor,\n",
      "**_kwargs,\n",
      ") -> torch.Tensor:\n",
      "position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "num_loss_tokens = (self.loss_ratio * num_informative_tokens).ceil().long()\n",
      "loss_mask = (num_informative_tokens - num_loss_tokens <= position_ids)\n",
      "return loss_mask.logical_and(target_attn_mask)\n",
      "\n",
      "\n",
      "# ../pipeline/data/preprocessors/preprocessor_base.py\n",
      "from pipeline.data.composed_datapoint import BatchComposedDatapoint\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class PreprocessedBatch(TypedDict):\n",
      "input_ids: torch.Tensor\n",
      "target_ids: torch.Tensor\n",
      "\n",
      "loss_mask: torch.Tensor\n",
      "completion_mask: torch.Tensor\n",
      "category_ids: torch.Tensor\n",
      "\n",
      "input_attn_mask: torch.Tensor\n",
      "target_attn_mask: torch.Tensor\n",
      "\n",
      "\n",
      "class PreprocessorBase(ABC):\n",
      "@abstractmethod\n",
      "def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "\"\"\"\n",
      "Important note: different number of masked tokens in different\n",
      "micro-batches will break gradient accumulation, in which case\n",
      "the training loop should include corresponding gradient scaling.\n",
      "*or we just don't care :)\n",
      "\"\"\"\n",
      "raise NotImplementedError\n",
      "\n",
      "@abstractmethod\n",
      "def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "raise NotImplementedError\n",
      "\n",
      "@abstractmethod\n",
      "def get_category_ids(self, *args, **kwargs) -> torch.Tensor:\n",
      "raise NotImplementedError\n",
      "\n",
      "@abstractmethod\n",
      "def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "raise NotImplementedError\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.data.composers.blocks.blocks_registry import BLOCKS_REGISTRY\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.composers.composers_registry import COMPOSERS_REGISTRY\n",
      "\n",
      "import os\n",
      "\n",
      "import yaml\n",
      "from omegaconf import DictConfig\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "def init_composer(cls_name: str,\n",
      "loaded_config: DictConfig,\n",
      "configs_dir: str,\n",
      "tokenizer: PreTrainedTokenizerBase,\n",
      "**kwargs,\n",
      ") -> ComposerBase:\n",
      "config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "\n",
      "if cls_name == 'chained_composer':\n",
      "for path in loaded_config.block_configs:\n",
      "full_path = os.path.join(configs_dir, 'composer/chained_composer/blocks', path)\n",
      "block_name = os.path.basename(os.path.dirname(path))\n",
      "\n",
      "with open(full_path) as stream:\n",
      "block_config = yaml.safe_load(stream)\n",
      "\n",
      "if block_config is None:\n",
      "block_config = dict()\n",
      "\n",
      "block_cls = BLOCKS_REGISTRY[block_name]\n",
      "if block_cls.requires_tokenizer:\n",
      "block_config['tokenizer'] = tokenizer\n",
      "\n",
      "block = block_cls(**block_config)\n",
      "config.blocks.append(block)\n",
      "\n",
      "composer = COMPOSERS_REGISTRY[cls_name](**config.dict)\n",
      "return composer\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/chain.py\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from pipeline.data.composers.utils import ReprMixin\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from dataclasses import dataclass, field\n",
      "from typing import Any, Sequence\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class File:\n",
      "content: str\n",
      "metadata: dict[str, Any]\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Chunk:\n",
      "content: str\n",
      "metadata: dict[str, Any]\n",
      "file_ref: File\n",
      "rank: list = field(default_factory=list)  # of comparable elements\n",
      "\n",
      "\n",
      "BlockArgs = Sequence[File] | Sequence[Chunk]\n",
      "\n",
      "\n",
      "class ComposerBlock(ABC, ReprMixin):\n",
      "first_block_permit: bool = False\n",
      "last_block_permit: bool = False\n",
      "requires_tokenizer: bool = False\n",
      "\n",
      "@property\n",
      "@abstractmethod\n",
      "def next_blocks(self) -> tuple[type, ...]:\n",
      "raise NotImplementedError\n",
      "\n",
      "def check_next_block(self, block) -> None:\n",
      "if not isinstance(block, self.next_blocks):\n",
      "raise ValueError(f'{type(block).__name__} cannot be used after {type(self).__name__}.')\n",
      "\n",
      "@abstractmethod\n",
      "def __call__(self, args: BlockArgs, datapoint: Datapoint) -> BlockArgs | str:\n",
      "raise NotImplementedError\n",
      "\n",
      "\n",
      "class ComposerChain:\n",
      "def __init__(self, *blocks: ComposerBlock) -> None:\n",
      "if not blocks:\n",
      "raise ValueError('ComposerChain instance must contain at least one element.')\n",
      "elif not blocks[0].first_block_permit:\n",
      "raise ValueError(f'{type(blocks[0]).__name__} cannot start a chain of blocks.')\n",
      "elif not blocks[-1].last_block_permit:\n",
      "raise ValueError(f'{type(blocks[-1]).__name__} cannot end a chain of blocks.')\n",
      "\n",
      "for block, next_block in zip(blocks[:-1], blocks[1:]):\n",
      "block.check_next_block(next_block)\n",
      "\n",
      "self.blocks = blocks\n",
      "\n",
      "def __call__(self, datapoint: Datapoint) -> str:\n",
      "x = [\n",
      "File(content=cnt, metadata={'filename': fn})\n",
      "for fn, cnt in zip(*datapoint.repo_snapshot.values())\n",
      "]\n",
      "for block in self.blocks:\n",
      "x = block(x, datapoint)\n",
      "return x\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/composer_base.py\n",
      "from pipeline.data.composed_datapoint import ComposedDatapoint, BatchComposedDatapoint\n",
      "from pipeline.data.datapoint import Datapoint, BatchDatapoint\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any\n",
      "\n",
      "from datasets import Dataset\n",
      "\n",
      "\n",
      "class ComposerBase(ABC):\n",
      "def __init__(self,\n",
      "pre_context_prompt: str,\n",
      "post_context_prompt: str,\n",
      "path_comment_template: str,\n",
      "recalculate_random_category: bool,\n",
      ") -> None:\n",
      "self.pre_context_prompt = pre_context_prompt\n",
      "self.post_context_prompt = post_context_prompt\n",
      "self.path_comment_template = path_comment_template\n",
      "self.recalculate_random_category = recalculate_random_category\n",
      "\n",
      "def get_pre_context_prompt(self, datapoint: Datapoint) -> str:\n",
      "return self.pre_context_prompt.format(datapoint.repo)\n",
      "\n",
      "def get_post_context_prompt(self, _datapoint: Datapoint) -> str:\n",
      "return self.post_context_prompt\n",
      "\n",
      "@abstractmethod\n",
      "def compose_context(self, datapoint: Datapoint) -> str:\n",
      "raise NotImplementedError\n",
      "\n",
      "def compose_completion(self, datapoint: Datapoint) -> str:\n",
      "template_with_inserted_path = self.path_comment_template.format(\n",
      "filename=datapoint.completion_file['filename'],\n",
      "content='{content}',\n",
      ")\n",
      "\n",
      "for i, line in enumerate(template_with_inserted_path.split('\\n')):\n",
      "if '{content}' in line:\n",
      "offset = i\n",
      "break\n",
      "else:\n",
      "raise RuntimeError('The path_comment_template does not contain a content field.')\n",
      "\n",
      "for line_category_ids in datapoint.completion_lines.values():\n",
      "for i in range(len(line_category_ids)):\n",
      "line_category_ids[i] += offset\n",
      "\n",
      "completion = template_with_inserted_path.format(**datapoint.completion_file)\n",
      "if not completion.endswith('\\n'):\n",
      "completion += '\\n'  # instead of EOS token\n",
      "\n",
      "return completion\n",
      "\n",
      "def compose(self, datapoint: dict[str, Any]) -> ComposedDatapoint:\n",
      "datapoint = Datapoint(**datapoint)\n",
      "\n",
      "if self.recalculate_random_category:\n",
      "non_categorized_lines = set(range(datapoint.completion_file['content'].count('\\n') + 1))\n",
      "for category, lines in datapoint.completion_lines.items():\n",
      "if category != 'random':\n",
      "non_categorized_lines.difference_update(lines)\n",
      "datapoint.completion_lines['random'] = list(non_categorized_lines)\n",
      "\n",
      "return ComposedDatapoint(\n",
      "pre_context_prompt=self.get_pre_context_prompt(datapoint),\n",
      "composed_context=self.compose_context(datapoint) + self.get_post_context_prompt(datapoint),\n",
      "composed_completion=self.compose_completion(datapoint),\n",
      "completion_lines=datapoint.completion_lines,\n",
      ")\n",
      "\n",
      "def compose_batch(self, batch: BatchDatapoint) -> BatchComposedDatapoint:\n",
      "batch_keys = batch.keys()\n",
      "composed_batch_keys = BatchComposedDatapoint.__required_keys__\n",
      "# transpose and compose\n",
      "batch = [self.compose(dict(zip(batch_keys, data))) for data in zip(*batch.values())]\n",
      "# transpose back\n",
      "batch = {key: list(map(lambda x: x.get(key), batch)) for key in composed_batch_keys}\n",
      "return batch\n",
      "\n",
      "def compose_dataset(self,\n",
      "dataset: Dataset,\n",
      "writer_batch_size: int = 128,\n",
      "num_proc: int = 4,\n",
      "**map_kwargs,\n",
      ") -> Dataset:\n",
      "return dataset.map(\n",
      "function=self.compose,\n",
      "remove_columns=map_kwargs.pop('remove_columns', dataset.column_names),\n",
      "# created cache files consume a lot of disk space\n",
      "load_from_cache_file=map_kwargs.pop('load_from_cache_file', False),\n",
      "writer_batch_size=writer_batch_size,\n",
      "num_proc=num_proc,\n",
      "desc=map_kwargs.pop('desc', f'Applying {type(self).__name__} to a given dataset'),\n",
      "**map_kwargs,\n",
      ")\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/chained_composer.py\n",
      "from pipeline.data.composers.chain import ComposerBlock, ComposerChain\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.composers.utils import ReprMixin\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from typing import Sequence\n",
      "\n",
      "\n",
      "class ChainedComposer(ComposerBase, ComposerChain, ReprMixin):\n",
      "def __init__(self, blocks: Sequence[ComposerBlock], *args, **kwargs) -> None:\n",
      "ComposerBase.__init__(self, *args, **kwargs)\n",
      "ComposerChain.__init__(self, *blocks)\n",
      "\n",
      "def compose_context(self, datapoint: Datapoint) -> str:\n",
      "return self.__call__(datapoint)\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/composers_registry.py\n",
      "from pipeline.data.composers.chained_composer import ChainedComposer\n",
      "\n",
      "COMPOSERS_REGISTRY = {\n",
      "'chained_composer': ChainedComposer,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/utils.py\n",
      "class ReprMixin:\n",
      "_init_args = None\n",
      "_init_kwargs = None\n",
      "\n",
      "def __init_subclass__(cls, **kwargs) -> None:\n",
      "super().__init_subclass__(**kwargs)\n",
      "original_init = cls.__init__\n",
      "\n",
      "def wrapped_init(self, *init_args, **init_kwargs) -> None:\n",
      "if cls == type(self):\n",
      "self._init_args = init_args\n",
      "self._init_kwargs = init_kwargs\n",
      "original_init(self, *init_args, **init_kwargs)\n",
      "\n",
      "cls.__init__ = wrapped_init\n",
      "\n",
      "def __repr__(self) -> str:\n",
      "args_str = ', '.join(\n",
      "[\n",
      "f\"'{arg}'\" if isinstance(arg, str) else repr(arg)\n",
      "for arg in self._init_args\n",
      "] + [\n",
      "f\"{key}='{value}'\" if isinstance(value, str) else f'{key}={value!r}'\n",
      "for key, value in self._init_kwargs.items()\n",
      "])\n",
      "return f'{type(self).__name__}({args_str})'\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/context_postprocessing.py\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "import random\n",
      "from abc import ABC\n",
      "from typing import Type\n",
      "\n",
      "\n",
      "class ContextPostprocessor(ComposerBlock, ABC):\n",
      "last_block_permit = True\n",
      "\n",
      "@property\n",
      "def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "return ContextPostprocessor,\n",
      "\n",
      "\n",
      "class PartialMemoryPostprocessor(ContextPostprocessor):\n",
      "def __init__(self, dropout: float, random_seed: int | None) -> None:\n",
      "if not 0 <= dropout <= 1:\n",
      "raise ValueError('dropout must be selected from the interval [0, 1]. '\n",
      "f'Got {dropout} instead.')\n",
      "self.dropout = dropout\n",
      "self.generator = random.Random(random_seed)\n",
      "\n",
      "def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "# dropping of path comments can occasionally happen\n",
      "return '\\n'.join(line for line in context.split('\\n') if self.generator.random() >= self.dropout)\n",
      "\n",
      "\n",
      "class LineLengthPostprocessor(ContextPostprocessor):\n",
      "def __init__(self, min_len: int, max_len: int) -> None:\n",
      "self.min_len = min_len\n",
      "self.max_len = max_len\n",
      "\n",
      "def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "return '\\n'.join(line for line in context.split('\\n') if self.min_len <= len(line) <= self.max_len)\n",
      "\n",
      "\n",
      "class LineStripPostprocessor(ContextPostprocessor):\n",
      "def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "return '\\n'.join(line.strip() for line in context.split('\\n'))\n",
      "\n",
      "\n",
      "class InverseFrequencyMemoryPostprocessor(ContextPostprocessor):\n",
      "def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "# TODO concerns:\n",
      "# 1. L1 or softmax normalization?\n",
      "# 2. Equivalence groups by line.strip() transformation?\n",
      "return context\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_sorting.py\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "\n",
      "class ChunkSorter(ComposerBlock, ABC):\n",
      "@property\n",
      "def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "return ChunkSorter, ChunkHarvester\n",
      "\n",
      "\n",
      "class LexicographicSorter(ChunkSorter):\n",
      "def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "return sorted(chunks, key=lambda c: c.rank)\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_harvesting.py\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "\n",
      "class ChunkHarvester(ComposerBlock, ABC):\n",
      "last_block_permit = True\n",
      "\n",
      "@property\n",
      "def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "from pipeline.data.composers.blocks.context_postprocessing import ContextPostprocessor\n",
      "return ContextPostprocessor,\n",
      "\n",
      "\n",
      "class JoiningHarvester(ChunkHarvester):\n",
      "def __init__(self, chunks_sep: str) -> None:\n",
      "self.chunks_sep = chunks_sep\n",
      "\n",
      "def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> str:\n",
      "return self.chunks_sep.join(chunk.content for chunk in chunks)\n",
      "\n",
      "\n",
      "class PathCommentHarvester(JoiningHarvester):\n",
      "def __init__(self, chunks_sep: str, path_comment_template: str) -> None:\n",
      "super().__init__(chunks_sep)\n",
      "self.path_comment_template = path_comment_template\n",
      "\n",
      "def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> str:\n",
      "for chunk in chunks:\n",
      "chunk.content = self.path_comment_template.format(\n",
      "filename=chunk.file_ref.metadata['filename'], content=chunk.content)\n",
      "return super().__call__(chunks, datapoint)\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_preprocessing.py\n",
      "from pipeline.data.composers.chain import File, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "import warnings\n",
      "\n",
      "\n",
      "class FilePreprocessor(ComposerBlock, ABC):\n",
      "first_block_permit = True\n",
      "\n",
      "@property\n",
      "def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "from pipeline.data.composers.blocks.file_chunking import FileChunker\n",
      "from pipeline.data.composers.blocks.file_filtering import FileFilter\n",
      "return FileFilter, FilePreprocessor, FileChunker\n",
      "\n",
      "\n",
      "class EmptyLinesRemovalPreprocessor(FilePreprocessor):\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "for file in files:\n",
      "file.content = '\\n'.join(line for line in file.content.split('\\n') if line.strip())\n",
      "return files\n",
      "\n",
      "\n",
      "class DeclarationOnlyPreprocessor(FilePreprocessor):\n",
      "ENCODING = 'utf8'\n",
      "\n",
      "def __init__(self) -> None:\n",
      "py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[File]:\n",
      "for file in files:\n",
      "if not file.metadata['filename'].endswith('.py'):\n",
      "continue\n",
      "\n",
      "bytecode = bytes(file.content, self.ENCODING)\n",
      "queue = [self.parser.parse(bytecode).root_node]\n",
      "declarations = list()\n",
      "\n",
      "while queue:\n",
      "node = queue.pop()\n",
      "queue.extend(reversed(node.children))\n",
      "\n",
      "if node.type not in ('function_definition', 'class_definition'):\n",
      "continue\n",
      "\n",
      "start = bytecode[:node.start_byte].rfind(b'\\n') + 1\n",
      "for child in node.children:\n",
      "if child.type == ':':\n",
      "end = child.end_byte\n",
      "break\n",
      "else:\n",
      "warnings.warn(f'A corrupted {file.metadata[\"filename\"]} file structure '\n",
      "f'has been detected in the {datapoint.repo} repository.')\n",
      "end = node.end_byte\n",
      "\n",
      "declaration = bytecode[start:end]\n",
      "declaration = declaration.decode('utf8') + ' ...'\n",
      "declarations.append(declaration)\n",
      "\n",
      "file.content = '\\n'.join(declarations)\n",
      "return files\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/chunk_ranking.py\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "import os\n",
      "import random\n",
      "import warnings\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "\n",
      "\n",
      "class ChunkRanker(ComposerBlock, ABC):\n",
      "@property\n",
      "def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "from pipeline.data.composers.blocks.chunk_sorting import ChunkSorter\n",
      "return ChunkRanker, ChunkSorter\n",
      "\n",
      "\n",
      "class NegativePathDistanceRanker(ChunkRanker):\n",
      "@staticmethod\n",
      "def _path_distance(path_from: str, path_to: str) -> int:\n",
      "path_from = os.path.normpath(path_from)\n",
      "path_to = os.path.normpath(path_to)\n",
      "\n",
      "if path_from == path_to:\n",
      "warnings.warn(f'Data leakage: the {path_from} completion file is contained in the repo snapshot.')\n",
      "\n",
      "divided_path_from = path_from.split(os.path.sep)\n",
      "divided_path_to = path_to.split(os.path.sep)\n",
      "\n",
      "common_len = 0\n",
      "for segment_from, segment_to in zip(divided_path_from, divided_path_to):\n",
      "if segment_from == segment_to:\n",
      "common_len += 1\n",
      "else:\n",
      "break\n",
      "\n",
      "num_residuals_from = len(divided_path_from) - common_len - 1\n",
      "num_residuals_to = len(divided_path_to) - common_len - 1\n",
      "\n",
      "return num_residuals_from + num_residuals_to\n",
      "\n",
      "def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "path_to = datapoint.completion_file['filename']\n",
      "for chunk in chunks:\n",
      "dist = self._path_distance(chunk.file_ref.metadata['filename'], path_to)\n",
      "chunk.rank.append(-dist)\n",
      "return chunks\n",
      "\n",
      "\n",
      "class FileExtensionRanker(ChunkRanker):\n",
      "def __init__(self, ordered_groups: list[list[str]]) -> None:\n",
      "self.group_weights = {\n",
      "extension: weight\n",
      "for weight, group in enumerate(ordered_groups)\n",
      "for extension in group\n",
      "}\n",
      "\n",
      "def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "for chunk in chunks:\n",
      "extension = '.' + chunk.file_ref.metadata['filename'].split('.')[-1]\n",
      "chunk.rank.append(self.group_weights.get(extension, -1))\n",
      "return chunks\n",
      "\n",
      "\n",
      "class FunctionCallRanker(ChunkRanker):\n",
      "ENCODING = 'utf8'\n",
      "\n",
      "def __init__(self, is_relative: bool) -> None:\n",
      "self.is_relative = is_relative\n",
      "\n",
      "py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "def dfs_count(self, node: tree_sitter.Node) -> int:\n",
      "return (node.type == 'call') + sum(self.dfs_count(child) for child in node.children)\n",
      "\n",
      "def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "for chunk in chunks:\n",
      "if chunk.file_ref.metadata['filename'].endswith('.py'):\n",
      "bytecode = bytes(chunk.content, self.ENCODING)\n",
      "tree = self.parser.parse(bytecode)\n",
      "num_calls = self.dfs_count(tree.root_node)\n",
      "else:\n",
      "num_calls = 0\n",
      "\n",
      "if self.is_relative:\n",
      "num_calls /= len(chunk.content)\n",
      "\n",
      "chunk.rank.append(num_calls)\n",
      "return chunks\n",
      "\n",
      "\n",
      "class RandomRanker(ChunkRanker):\n",
      "def __init__(self, random_seed: int | None) -> None:\n",
      "self.generator = random.Random(random_seed)\n",
      "\n",
      "def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "ranks = list(range(len(chunks)))\n",
      "self.generator.shuffle(ranks)\n",
      "for rank, chunk in zip(ranks, chunks):\n",
      "chunk.rank.append(rank)\n",
      "return chunks\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/blocks_registry.py\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import (\n",
      "JoiningHarvester,\n",
      "PathCommentHarvester,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_ranking import (\n",
      "NegativePathDistanceRanker,\n",
      "FunctionCallRanker,\n",
      "FileExtensionRanker,\n",
      "RandomRanker,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_sorting import (\n",
      "LexicographicSorter,\n",
      ")\n",
      "from pipeline.data.composers.blocks.context_postprocessing import (\n",
      "PartialMemoryPostprocessor,\n",
      "LineLengthPostprocessor,\n",
      "LineStripPostprocessor,\n",
      "InverseFrequencyMemoryPostprocessor,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_chunking import (\n",
      "FileGrainedChunker,\n",
      "CodeSegmentGrainedChunker,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_filtering import (\n",
      "InclusiveFileExtensionFilter,\n",
      "ExclusiveFileExtensionFilter,\n",
      "EmptyFileFilter,\n",
      "FileLengthFilter,\n",
      "TokenizedFileLengthFilter,\n",
      "CharTokenRatioFilter,\n",
      ")\n",
      "from pipeline.data.composers.blocks.file_preprocessing import (\n",
      "EmptyLinesRemovalPreprocessor,\n",
      "DeclarationOnlyPreprocessor,\n",
      ")\n",
      "\n",
      "BLOCKS_REGISTRY = {\n",
      "# file_filtering\n",
      "'inclusive_file_extension_filter': InclusiveFileExtensionFilter,\n",
      "'exclusive_file_extension_filter': ExclusiveFileExtensionFilter,\n",
      "'empty_file_filter': EmptyFileFilter,\n",
      "'file_length_filter': FileLengthFilter,\n",
      "'tokenized_file_length_filter': TokenizedFileLengthFilter,\n",
      "'char_token_ratio_filter': CharTokenRatioFilter,\n",
      "\n",
      "# file_preprocessing\n",
      "'empty_lines_removal_preprocessor': EmptyLinesRemovalPreprocessor,\n",
      "'declaration_only_preprocessor': DeclarationOnlyPreprocessor,\n",
      "\n",
      "# file_chunking\n",
      "'file_grained_chunker': FileGrainedChunker,\n",
      "'code_segment_grained_chunker': CodeSegmentGrainedChunker,\n",
      "\n",
      "# chunk_ranking\n",
      "'negative_path_distance_ranker': NegativePathDistanceRanker,\n",
      "'function_call_ranker': FunctionCallRanker,\n",
      "'file_extension_ranker': FileExtensionRanker,\n",
      "'random_ranker': RandomRanker,\n",
      "\n",
      "# chunk_sorting\n",
      "'lexicographic_sorter': LexicographicSorter,\n",
      "\n",
      "# chunk_harvesting\n",
      "'joining_harvester': JoiningHarvester,\n",
      "'path_comment_harvester': PathCommentHarvester,\n",
      "\n",
      "# context_postprocessing\n",
      "'partial_memory_postprocessor': PartialMemoryPostprocessor,\n",
      "'line_length_postprocessor': LineLengthPostprocessor,\n",
      "'line_strip_postprocessor': LineStripPostprocessor,\n",
      "'inverse_frequency_memory_postprocessor': InverseFrequencyMemoryPostprocessor,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_filtering.py\n",
      "from pipeline.data.composers.chain import File, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "import random\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class FileFilter(ComposerBlock, ABC):\n",
      "first_block_permit = True\n",
      "\n",
      "@property\n",
      "def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "from pipeline.data.composers.blocks.file_chunking import FileChunker\n",
      "from pipeline.data.composers.blocks.file_preprocessing import FilePreprocessor\n",
      "return FileFilter, FilePreprocessor, FileChunker\n",
      "\n",
      "\n",
      "class InclusiveFileExtensionFilter(FileFilter):\n",
      "def __init__(self, whitelist: list[str]) -> None:\n",
      "self.whitelist = tuple(whitelist)\n",
      "\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "return [file for file in files if file.metadata['filename'].endswith(self.whitelist)]\n",
      "\n",
      "\n",
      "class ExclusiveFileExtensionFilter(FileFilter):\n",
      "def __init__(self, blacklist: list[str]) -> None:\n",
      "self.blacklist = tuple(blacklist)\n",
      "\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "return [file for file in files if not file.metadata['filename'].endswith(self.blacklist)]\n",
      "\n",
      "\n",
      "class EmptyFileFilter(FileFilter):\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "return [file for file in files if file.content.strip()]\n",
      "\n",
      "\n",
      "class FileLengthFilter(FileFilter):\n",
      "def __init__(self, min_len: int, max_len: int) -> None:\n",
      "self.min_len = min_len\n",
      "self.max_len = max_len\n",
      "\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "return [file for file in files if self.min_len <= len(file.content) <= self.max_len]\n",
      "\n",
      "\n",
      "class TokenizedFileLengthFilter(FileFilter):\n",
      "requires_tokenizer = True\n",
      "\n",
      "def __init__(self, tokenizer: PreTrainedTokenizerBase, min_len: int, max_len: int) -> None:\n",
      "self.tokenizer = tokenizer\n",
      "self.min_len = min_len\n",
      "self.max_len = max_len\n",
      "\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "filtered_files = list()\n",
      "\n",
      "for file in files:\n",
      "if 'num_tokens' not in file.metadata:\n",
      "tokenized_file = self.tokenizer(file.content, return_attention_mask=False).input_ids\n",
      "file.metadata['num_tokens'] = len(tokenized_file)\n",
      "\n",
      "if self.min_len <= file.metadata['num_tokens'] <= self.max_len:\n",
      "filtered_files.append(file)\n",
      "\n",
      "return filtered_files\n",
      "\n",
      "\n",
      "class CharTokenRatioFilter(FileFilter):\n",
      "requires_tokenizer = True\n",
      "\n",
      "def __init__(self,\n",
      "tokenizer: PreTrainedTokenizerBase,\n",
      "min_ratio: float,\n",
      "max_ratio: float,\n",
      "subsequence_len: int,\n",
      "random_seed: int | None,\n",
      ") -> None:\n",
      "self.tokenizer = tokenizer\n",
      "self.min_ratio = min_ratio\n",
      "self.max_ratio = max_ratio\n",
      "self.subsequence_len = subsequence_len\n",
      "self.generator = random.Random(random_seed)\n",
      "\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "filtered_files = list()\n",
      "\n",
      "for file in files:\n",
      "if len(file.content) <= self.subsequence_len:\n",
      "subsequence = file.content\n",
      "else:\n",
      "# N.B. this algorithm does NOT preserve the uniformity of token sampling\n",
      "# only the uniformity of subsequences\n",
      "start_idx = self.generator.randrange(len(file.content) - self.subsequence_len + 1)\n",
      "subsequence = file.content[start_idx:start_idx + self.subsequence_len]\n",
      "\n",
      "tokenized_subsequence = self.tokenizer(subsequence, return_attention_mask=False).input_ids\n",
      "ratio = len(subsequence) / len(tokenized_subsequence)\n",
      "\n",
      "if self.min_ratio <= ratio <= self.max_ratio:\n",
      "filtered_files.append(file)\n",
      "\n",
      "return filtered_files\n",
      "\n",
      "# ../pipeline/data/composers/blocks/file_chunking.py\n",
      "from pipeline.data.composers.chain import File, Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from enum import Enum\n",
      "from string import whitespace\n",
      "from typing import Callable, NamedTuple, Sequence, TypeVar, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "\n",
      "class FileChunker(ComposerBlock, ABC):\n",
      "first_block_permit = True\n",
      "\n",
      "@property\n",
      "def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "from pipeline.data.composers.blocks.chunk_ranking import ChunkRanker\n",
      "return ChunkRanker, ChunkHarvester\n",
      "\n",
      "\n",
      "class FileGrainedChunker(FileChunker):  # identity chunker\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "return [Chunk(content=file.content, metadata=file.metadata, file_ref=file) for file in files\n",
      "# TODO: remove temporary hardcoded solution for data leakage\n",
      "if file.metadata['filename'] != 'tinygrad/llops/ops_llvm.py']\n",
      "\n",
      "\n",
      "class CodeSegment(str, Enum):\n",
      "COMMENT = 'comment_segment'\n",
      "DOCSTRING = 'docstring_segment'\n",
      "IMPORT = 'import_segment'\n",
      "CODE = 'code_segment'\n",
      "UNDEFINED = 'undefined_segment'\n",
      "\n",
      "@classmethod\n",
      "def from_node(cls: Type[T], node: tree_sitter.Node) -> T:\n",
      "if 'comment' in node.type.lower():\n",
      "return cls.COMMENT\n",
      "elif node.type == 'string' and node.text.startswith(CodeSegmentGrainedChunker.DOCSTRING_PREFIX):\n",
      "return cls.DOCSTRING\n",
      "elif 'import' in node.type.lower():\n",
      "return cls.IMPORT\n",
      "elif node.child_count == 0:\n",
      "return cls.CODE\n",
      "else:\n",
      "return cls.UNDEFINED\n",
      "\n",
      "\n",
      "class Segment(NamedTuple):\n",
      "start_byte: int\n",
      "type: CodeSegment\n",
      "\n",
      "\n",
      "class CodeSegmentGrainedChunker(FileChunker):\n",
      "ENCODING = 'utf8'\n",
      "DOCSTRING_PREFIX = (bytes(\"'''\", ENCODING), bytes('\"\"\"', ENCODING))\n",
      "\n",
      "def __init__(self) -> None:\n",
      "py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "@staticmethod\n",
      "def dfs_segmentation(root_node: tree_sitter.Node) -> list[Segment]:\n",
      "segments = list()\n",
      "queue = [root_node]\n",
      "\n",
      "while queue:\n",
      "node = queue.pop()\n",
      "segment_type = CodeSegment.from_node(node)\n",
      "\n",
      "if segment_type != CodeSegment.UNDEFINED:\n",
      "if len(segments) == 0 or segment_type != segments[-1].type:\n",
      "segments.append(Segment(node.start_byte, segment_type))\n",
      "else:\n",
      "queue.extend(reversed(node.children))\n",
      "\n",
      "return segments\n",
      "\n",
      "@staticmethod\n",
      "def strip_lines(string: str, strip_func: Callable[[str], str]) -> str:\n",
      "return '\\n'.join(map(strip_func, string.split('\\n')))\n",
      "\n",
      "def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "chunks = list()\n",
      "\n",
      "for file in files:\n",
      "if not file.metadata['filename'].endswith('.py'):\n",
      "chunks.append(Chunk(\n",
      "content=file.content,\n",
      "metadata=file.metadata | {'segment_type': CodeSegment.UNDEFINED},\n",
      "file_ref=file,\n",
      "))\n",
      "continue\n",
      "# TODO: remove temporary hardcoded solution for data leakage\n",
      "if file.metadata['filename'] == 'tinygrad/llops/ops_llvm.py':\n",
      "continue\n",
      "\n",
      "bytecode = bytes(file.content, self.ENCODING)\n",
      "tree = self.parser.parse(bytecode)\n",
      "segments = self.dfs_segmentation(tree.root_node)\n",
      "\n",
      "dummy_segment = Segment(len(bytecode), CodeSegment.UNDEFINED)\n",
      "segments.append(dummy_segment)\n",
      "\n",
      "comments_chunk = Chunk(\n",
      "content='', metadata=file.metadata | {'segment_type': CodeSegment.COMMENT}, file_ref=file)\n",
      "docstrings_chunk = Chunk(\n",
      "content='', metadata=file.metadata | {'segment_type': CodeSegment.DOCSTRING}, file_ref=file)\n",
      "imports_chunk = Chunk(\n",
      "content='', metadata=file.metadata | {'segment_type': CodeSegment.IMPORT}, file_ref=file)\n",
      "code_chunk = Chunk(\n",
      "content='', metadata=file.metadata | {'segment_type': CodeSegment.CODE}, file_ref=file)\n",
      "prev_edited_chunk = None\n",
      "\n",
      "for i in range(len(segments) - 1):\n",
      "start = segments[i].start_byte\n",
      "end = segments[i + 1].start_byte\n",
      "segment_str = bytecode[start:end].decode(self.ENCODING)\n",
      "segment_type = segments[i].type\n",
      "\n",
      "match segment_type:\n",
      "case CodeSegment.COMMENT:\n",
      "# inline comment newline fix\n",
      "if prev_edited_chunk is not None and not prev_edited_chunk.content.rstrip(\n",
      "whitespace.replace('\\n', '')).endswith('\\n'):\n",
      "prev_edited_chunk.content += '\\n' + segment_str.split('\\n')[-1]\n",
      "\n",
      "if segment_str.count('\\n') >= 2:\n",
      "comments_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "prev_edited_chunk = comments_chunk\n",
      "\n",
      "case CodeSegment.DOCSTRING:\n",
      "docstrings_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "prev_edited_chunk = docstrings_chunk\n",
      "\n",
      "case CodeSegment.IMPORT:\n",
      "imports_chunk.content += segment_str\n",
      "prev_edited_chunk = imports_chunk\n",
      "\n",
      "case CodeSegment.CODE:\n",
      "code_chunk.content += segment_str\n",
      "prev_edited_chunk = code_chunk\n",
      "\n",
      "case _:\n",
      "raise RuntimeError  # indicates a bug\n",
      "\n",
      "for chunk in (comments_chunk, docstrings_chunk, imports_chunk, code_chunk):\n",
      "if chunk.content.strip():\n",
      "chunk.content = self.strip_lines(chunk.content.rstrip(), str.rstrip)\n",
      "chunks.append(chunk)\n",
      "\n",
      "return chunks\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/cross_entropy.py\n",
      "from pipeline.outputs.metrics.metric_base import MetricValue, OptimizationMode, MetricBase\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class CrossEntropy(MetricBase):\n",
      "mode = OptimizationMode.MIN\n",
      "\n",
      "def __init__(self) -> None:\n",
      "self.mean_loss = 0\n",
      "self.num_tokens = 0\n",
      "\n",
      "@torch.inference_mode\n",
      "def micro_batch_update(self, loss_per_token: torch.Tensor, mask: torch.Tensor, **_kwargs) -> None:\n",
      "loss_update = torch.nan_to_num(loss_per_token[mask].mean()).item()\n",
      "num_tokens_update = mask.sum().item()\n",
      "\n",
      "# loss correction w.r.t. number of masked tokens (for unbalanced batches)\n",
      "if not self.num_tokens:\n",
      "self.mean_loss += loss_update\n",
      "self.num_tokens = 0\n",
      "else:\n",
      "tokens_ratio = num_tokens_update / self.num_tokens\n",
      "self.mean_loss += tokens_ratio * loss_update\n",
      "self.mean_loss /= tokens_ratio + 1\n",
      "\n",
      "self.num_tokens += num_tokens_update\n",
      "\n",
      "def batch_commit(self) -> MetricValue:\n",
      "batch_metric = float('nan') if not self.num_tokens else self.mean_loss\n",
      "self.mean_loss = 0\n",
      "self.num_tokens = 0\n",
      "return batch_metric\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/counters.py\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticBase\n",
      "\n",
      "from typing import TypeVar, Type\n",
      "\n",
      "import torch\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "# avoiding cyclical imports\n",
      "FullFineTuningTrainer = TypeVar('FullFineTuningTrainer')\n",
      "\n",
      "\n",
      "class EpochCounter(StatisticBase):\n",
      "_instance = None  # singleton pattern\n",
      "\n",
      "def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "if cls._instance is None:\n",
      "cls._instance = super().__new__(cls)\n",
      "return cls._instance\n",
      "\n",
      "def __init__(self) -> None:\n",
      "self.init_epoch = 0  # for resumption\n",
      "self.samples = 0\n",
      "self.ds_length = 1\n",
      "\n",
      "def reinit(self, init_epoch: float | None) -> None:\n",
      "if init_epoch is not None:\n",
      "self.init_epoch = init_epoch\n",
      "\n",
      "def micro_batch_update(self, input_ids: torch.Tensor, trainer: FullFineTuningTrainer, **_kwargs) -> None:\n",
      "if trainer.model.training:  # ignores validation samples\n",
      "self.samples += input_ids.shape[0]\n",
      "self.ds_length = len(trainer.train_dl.dataset)\n",
      "\n",
      "def batch_commit(self) -> StatisticValue:\n",
      "return self.init_epoch + self.samples / self.ds_length\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/statistic_base.py\n",
      "# TODO: grad norm, number of (masked) tokens, speed [tok/sec]?\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Type\n",
      "\n",
      "import torch\n",
      "\n",
      "StatisticValue = int | float\n",
      "\n",
      "\n",
      "class StatisticBase(ABC):\n",
      "def reinit(self, prev_value: StatisticValue | None) -> None:\n",
      "pass  # default behavior\n",
      "\n",
      "@abstractmethod\n",
      "@torch.inference_mode\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "raise NotImplementedError\n",
      "\n",
      "@abstractmethod\n",
      "def batch_commit(self) -> StatisticValue:\n",
      "raise NotImplementedError\n",
      "\n",
      "\n",
      "def ema_factory(statistic_cls: Type[StatisticBase]) -> Type[StatisticBase]:\n",
      "class EMAStatistic(statistic_cls, ABC):\n",
      "def __init__(self, ema_alpha: float) -> None:\n",
      "super().__init__()\n",
      "self.ema_alpha = ema_alpha\n",
      "self.ema_state = None\n",
      "\n",
      "def reinit(self, ema_state: float | None) -> None:\n",
      "self.ema_state = ema_state\n",
      "\n",
      "def batch_commit(self) -> StatisticValue:\n",
      "batch_metric = super().batch_commit()\n",
      "if self.ema_state is None:\n",
      "self.ema_state = batch_metric\n",
      "else:\n",
      "self.ema_state += self.ema_alpha * (batch_metric - self.ema_state)\n",
      "return self.ema_state\n",
      "\n",
      "return EMAStatistic\n",
      "\n",
      "\n",
      "def lazy_statistic_factory(statistic_name: str) -> Type[StatisticBase]:\n",
      "class LazyStatistic(StatisticBase):\n",
      "def __init__(self) -> None:\n",
      "self.value = None\n",
      "\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "self.value = kwargs.get(statistic_name)\n",
      "\n",
      "def batch_commit(self) -> StatisticValue:\n",
      "batch_statistic = self.value\n",
      "self.value = None\n",
      "return batch_statistic\n",
      "\n",
      "return LazyStatistic\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/metric_base.py\n",
      "from pipeline.data.categories import CategoryType, CATEGORY2ID\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticBase\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from enum import Enum\n",
      "from typing import Type\n",
      "\n",
      "MetricName = str\n",
      "MetricValue = StatisticValue\n",
      "\n",
      "\n",
      "class OptimizationMode(str, Enum):\n",
      "MIN = 'minimization'\n",
      "MAX = 'maximization'\n",
      "\n",
      "\n",
      "class MetricBase(StatisticBase, ABC):\n",
      "@property\n",
      "@abstractmethod\n",
      "def mode(self) -> OptimizationMode:\n",
      "raise NotImplementedError\n",
      "\n",
      "\n",
      "def loss_based_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "class LossBasedMetric(metric_cls, ABC):\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "kwargs['mask'] = kwargs['loss_mask']\n",
      "return super().micro_batch_update(**kwargs)\n",
      "\n",
      "return LossBasedMetric\n",
      "\n",
      "\n",
      "def detached_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "class DetachedMetric(metric_cls, ABC):\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "kwargs['mask'] = ~kwargs['loss_mask'] & kwargs['target_attn_mask']\n",
      "return super().micro_batch_update(**kwargs)\n",
      "\n",
      "return DetachedMetric\n",
      "\n",
      "\n",
      "def completion_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "class FullMetric(metric_cls, ABC):\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "kwargs['mask'] = kwargs['completion_mask']\n",
      "return super().micro_batch_update(**kwargs)\n",
      "\n",
      "return FullMetric\n",
      "\n",
      "\n",
      "def context_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "class FullMetric(metric_cls, ABC):\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "kwargs['mask'] = ~kwargs['completion_mask'] & kwargs['target_attn_mask']\n",
      "return super().micro_batch_update(**kwargs)\n",
      "\n",
      "return FullMetric\n",
      "\n",
      "\n",
      "def full_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "class FullMetric(metric_cls, ABC):\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "kwargs['mask'] = kwargs['target_attn_mask']\n",
      "return super().micro_batch_update(**kwargs)\n",
      "\n",
      "return FullMetric\n",
      "\n",
      "\n",
      "def categorized_metric_factory(metric_cls: Type[MetricBase], category: CategoryType) -> Type[MetricBase]:\n",
      "class CategorizedMetric(metric_cls, ABC):\n",
      "def micro_batch_update(self, **kwargs) -> None:\n",
      "kwargs['mask'] = (kwargs['category_ids'] == CATEGORY2ID[category])\n",
      "return super().micro_batch_update(**kwargs)\n",
      "\n",
      "return CategorizedMetric\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/metrics/metrics_registry.py\n",
      "from pipeline.outputs.metrics.cross_entropy import CrossEntropy\n",
      "from pipeline.outputs.metrics.metric_base import (\n",
      "loss_based_metric_factory,\n",
      "detached_metric_factory,\n",
      "completion_metric_factory,\n",
      "context_metric_factory,\n",
      "full_metric_factory,\n",
      "categorized_metric_factory,\n",
      ")\n",
      "from pipeline.outputs.metrics.statistic_base import ema_factory, lazy_statistic_factory\n",
      "from pipeline.outputs.metrics.counters import EpochCounter\n",
      "\n",
      "METRICS_REGISTRY = {\n",
      "'cross_entropy': loss_based_metric_factory(CrossEntropy),\n",
      "\n",
      "'detached_cross_entropy': detached_metric_factory(CrossEntropy),\n",
      "'completion_cross_entropy': completion_metric_factory(CrossEntropy),\n",
      "'context_cross_entropy': context_metric_factory(CrossEntropy),\n",
      "'full_cross_entropy': full_metric_factory(CrossEntropy),\n",
      "'commited_cross_entropy': categorized_metric_factory(CrossEntropy, 'commited'),\n",
      "'common_cross_entropy': categorized_metric_factory(CrossEntropy, 'common'),\n",
      "'infile_cross_entropy': categorized_metric_factory(CrossEntropy, 'infile'),\n",
      "'inproject_cross_entropy': categorized_metric_factory(CrossEntropy, 'inproject'),\n",
      "'non_informative_cross_entropy': categorized_metric_factory(CrossEntropy, 'non_informative'),\n",
      "'random_cross_entropy': categorized_metric_factory(CrossEntropy, 'random'),\n",
      "'other_cross_entropy': categorized_metric_factory(CrossEntropy, 'other'),\n",
      "\n",
      "# in training only\n",
      "'epoch': EpochCounter,\n",
      "'learning_rate': lazy_statistic_factory('learning_rate'),\n",
      "}\n",
      "METRICS_REGISTRY.update({  # useless due to W&B native support :(\n",
      "f'ema_{name}': ema_factory(cls) for name, cls in METRICS_REGISTRY.items()\n",
      "})\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/top_k_checkpointer.py\n",
      "from pipeline.outputs.checkpointers.data_structures import Checkpoint\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "\n",
      "import os\n",
      "import shutil\n",
      "\n",
      "\n",
      "class TopKCheckpointManager(CheckpointManager):\n",
      "def __init__(self, max_checkpoints_num: int, *args, **kwargs) -> None:\n",
      "super().__init__(*args, **kwargs)\n",
      "self.max_checkpoints_num = max_checkpoints_num\n",
      "\n",
      "def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "super().save_checkpoint(checkpoint)\n",
      "\n",
      "checkpoints = next(os.walk(self.directory))[1]\n",
      "checkpoints = sorted(checkpoints, key=self.get_checkpoint_score)\n",
      "\n",
      "while len(checkpoints) > self.max_checkpoints_num:\n",
      "checkpoint2del = checkpoints.pop()\n",
      "checkpoint2del = os.path.join(self.directory, checkpoint2del)\n",
      "shutil.rmtree(checkpoint2del)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/checkpointer.py\n",
      "from pipeline.outputs.checkpointers.data_structures import LoadingMode, Checkpoint\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue, OptimizationMode, MetricBase\n",
      "from pipeline.outputs.metrics.metrics_registry import METRICS_REGISTRY\n",
      "\n",
      "import json\n",
      "import os\n",
      "import warnings\n",
      "\n",
      "from typing import Callable, Literal\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class CheckpointManager:  # aka checkpointer\n",
      "def __init__(self,\n",
      "init_from: LoadingMode | str,\n",
      "main_metric: MetricName,\n",
      "directory: str,\n",
      "checkpoint_directory_template: str,\n",
      "extract_iteration_number: Callable[[str], int],\n",
      "model_subdirectory: str,\n",
      "optim_state_filename: str,\n",
      "metrics_filename: str,\n",
      ") -> None:\n",
      "if main_metric not in METRICS_REGISTRY:\n",
      "raise ValueError('The specified main_metric is not contained in the registry.')\n",
      "\n",
      "self.init_from = init_from\n",
      "self.main_metric_name = main_metric\n",
      "self.main_metric = METRICS_REGISTRY[main_metric]\n",
      "self.directory = directory\n",
      "\n",
      "self._checkpoint_directory_template = checkpoint_directory_template\n",
      "self._extract_iteration_number = extract_iteration_number\n",
      "self._model_subdirectory = model_subdirectory\n",
      "self._optim_state_filename = optim_state_filename\n",
      "self._metrics_filename = metrics_filename\n",
      "\n",
      "def get_wandb_resume_mode(self) -> Literal['allow', 'never'] | None:\n",
      "match self.init_from:\n",
      "case LoadingMode.SCRATCH:\n",
      "return None\n",
      "case LoadingMode.RESUME:\n",
      "return 'allow'\n",
      "case _:\n",
      "return 'never'\n",
      "\n",
      "def load_metrics(self, checkpoint_dir: str) -> Log:\n",
      "metrics_file = os.path.join(checkpoint_dir, self._metrics_filename)\n",
      "with open(metrics_file) as stream:\n",
      "return Log(**json.load(stream))\n",
      "\n",
      "def get_checkpoint_score(self, checkpoint_dir: str) -> MetricValue:\n",
      "checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "metrics = self.load_metrics(checkpoint_dir)\n",
      "metric_value = metrics.get('valid_metrics', metrics['train_metrics']).get(self.main_metric_name)\n",
      "\n",
      "if metric_value is None:\n",
      "raise RuntimeError(f'The {checkpoint_dir} does not contain information '\n",
      "'about the specified main_metric.')\n",
      "elif self.main_metric.mode == OptimizationMode.MIN:\n",
      "return metric_value\n",
      "else:\n",
      "return -metric_value\n",
      "\n",
      "def get_checkpoint_directory(self) -> str | None:\n",
      "match self.init_from:\n",
      "case LoadingMode.SCRATCH:\n",
      "return None\n",
      "case LoadingMode.RESUME:\n",
      "return max(\n",
      "next(os.walk(self.directory))[1],\n",
      "key=self._extract_iteration_number,\n",
      "default=None,\n",
      ")\n",
      "case LoadingMode.BEST:\n",
      "return min(\n",
      "next(os.walk(self.directory))[1],\n",
      "key=self.get_checkpoint_score,\n",
      "default=None,\n",
      ")\n",
      "case _:  # user-defined checkpoint directory\n",
      "return self.init_from\n",
      "\n",
      "def get_iteration_number(self) -> int:\n",
      "checkpoint_dir = self.get_checkpoint_directory()\n",
      "if checkpoint_dir is not None:\n",
      "return self._extract_iteration_number(checkpoint_dir)\n",
      "else:\n",
      "return 0\n",
      "\n",
      "def get_model_subdirectory(self) -> str | None:\n",
      "checkpoint_dir = self.get_checkpoint_directory()\n",
      "if checkpoint_dir is not None:\n",
      "return os.path.join(self.directory, checkpoint_dir, self._model_subdirectory)\n",
      "else:\n",
      "return None\n",
      "\n",
      "def init_optimizer(self, optimizer: torch.optim.AdamW) -> None:\n",
      "checkpoint_dir = self.get_checkpoint_directory()\n",
      "if checkpoint_dir is not None:\n",
      "optim_file = os.path.join(self.directory, checkpoint_dir, self._optim_state_filename)\n",
      "optimizer.load_state_dict(torch.load(optim_file))\n",
      "\n",
      "def init_metrics(self,\n",
      "group: Literal['train_metrics', 'valid_metrics'],\n",
      "metrics: list[MetricName],\n",
      "ema_alpha: float,\n",
      ") -> dict[MetricName, MetricBase]:\n",
      "checkpoint_dir = self.get_checkpoint_directory()\n",
      "metrics_dict = dict()\n",
      "\n",
      "if checkpoint_dir is None:\n",
      "metrics_states = dict()\n",
      "else:\n",
      "checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "metrics_states = self.load_metrics(checkpoint_dir)[group]\n",
      "\n",
      "for name in metrics:\n",
      "init_args = [ema_alpha] if name.startswith('ema_') else list()\n",
      "metrics_dict[name] = METRICS_REGISTRY[name](*init_args)\n",
      "metrics_dict[name].reinit(metrics_states.get(name))\n",
      "\n",
      "return metrics_dict\n",
      "\n",
      "def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "checkpoint_dir = os.path.join(\n",
      "self.directory,\n",
      "self._checkpoint_directory_template.format(\n",
      "iteration_number=checkpoint.metrics['iteration_number']),\n",
      ")\n",
      "\n",
      "if os.path.exists(checkpoint_dir):\n",
      "warnings.warn(f'The contents of the checkpoint {checkpoint_dir} have been overwritten.')\n",
      "\n",
      "model_save_dir, optim_file, metrics_file = map(\n",
      "lambda x: os.path.join(checkpoint_dir, x),\n",
      "[self._model_subdirectory, self._optim_state_filename, self._metrics_filename],\n",
      ")\n",
      "\n",
      "checkpoint.model.save_pretrained(model_save_dir)\n",
      "torch.save(checkpoint.optimizer_state, optim_file)\n",
      "\n",
      "with open(metrics_file, 'w') as stream:\n",
      "json.dump(checkpoint.metrics, stream, indent=4)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/data_structures.py\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from enum import Enum\n",
      "\n",
      "from transformers import PreTrainedModel\n",
      "\n",
      "\n",
      "class LoadingMode(str, Enum):\n",
      "SCRATCH = 'scratch'\n",
      "RESUME = 'resume'\n",
      "BEST = 'best'\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Checkpoint:\n",
      "metrics: Log\n",
      "model: PreTrainedModel\n",
      "optimizer_state: dict\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.checkpointers_registry import CHECKPOINTERS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_checkpointer(cls_name: str, loaded_config: DictConfig, **kwargs) -> CheckpointManager:\n",
      "config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "checkpointer = CHECKPOINTERS_REGISTRY[cls_name](**config.dict)\n",
      "return checkpointer\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/checkpointers/checkpointers_registry.py\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.top_k_checkpointer import TopKCheckpointManager\n",
      "\n",
      "CHECKPOINTERS_REGISTRY = {\n",
      "'checkpointer': CheckpointManager,\n",
      "'top_k_checkpointer': TopKCheckpointManager,\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/dummy_logger.py\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "\n",
      "\n",
      "class DummyLogger(LoggerBase):\n",
      "def __init__(self, *_args, **_kwargs) -> None:\n",
      "pass\n",
      "\n",
      "def log(self, metrics: Log) -> Log:\n",
      "return metrics\n",
      "\n",
      "def message(self, message: Message) -> Message:\n",
      "return message\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/local_logger.py\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "\n",
      "import csv\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import sys\n",
      "import traceback\n",
      "import warnings\n",
      "from types import TracebackType\n",
      "from typing import NoReturn\n",
      "\n",
      "import datasets.utils.logging\n",
      "import transformers.utils.logging\n",
      "\n",
      "\n",
      "class JsonFormatter(logging.Formatter):\n",
      "def format(self, record: logging.LogRecord) -> str:\n",
      "message_dict = {\n",
      "'timestamp': self.formatTime(record, self.datefmt),\n",
      "'level': record.levelname,\n",
      "'content': record.msg,\n",
      "}\n",
      "\n",
      "indent = '    '\n",
      "json_string = json.dumps(message_dict, indent=4)\n",
      "json_string = indent.join(json_string.splitlines(keepends=True))\n",
      "json_string = indent + json_string\n",
      "\n",
      "return json_string\n",
      "\n",
      "\n",
      "class JsonHandler(logging.FileHandler):\n",
      "def emit(self, record: logging.LogRecord) -> None:\n",
      "if not os.path.exists(self.baseFilename) or os.stat(self.baseFilename).st_size == 0:\n",
      "self.stream.write('[\\n')\n",
      "else:\n",
      "self.stream.seek(self.stream.tell() - 1)\n",
      "self.stream.truncate()\n",
      "self.stream.write(',\\n')\n",
      "\n",
      "super().emit(record)\n",
      "\n",
      "def close(self) -> None:\n",
      "self.stream.seek(self.stream.tell() - 1)\n",
      "self.stream.write(']')\n",
      "\n",
      "super().close()\n",
      "\n",
      "\n",
      "class LocalLogger(LoggerBase):\n",
      "def __init__(self,\n",
      "train_csv: str,\n",
      "valid_csv: str,\n",
      "stdout_file: str,\n",
      "stderr_file: str,\n",
      "directory: str,\n",
      ") -> None:\n",
      "if train_csv == valid_csv:\n",
      "raise ValueError('The names of the train_csv and valid_csv files must be different.')\n",
      "\n",
      "train_csv, valid_csv, stdout_file, stderr_file = map(\n",
      "lambda x: os.path.join(directory, x),\n",
      "[train_csv, valid_csv, stdout_file, stderr_file],\n",
      ")\n",
      "\n",
      "if os.path.exists(train_csv):\n",
      "with open(train_csv) as stream:\n",
      "self.last_logged_iter = max(map(lambda x: int(x.split(',')[0]), stream.readlines()[1:]))\n",
      "else:\n",
      "self.last_logged_iter = -1\n",
      "\n",
      "self.train_csv = train_csv\n",
      "self.valid_csv = valid_csv\n",
      "\n",
      "self.logger = logging.getLogger(__name__)\n",
      "self.logger.propagate = False\n",
      "self.logger.setLevel(logging.DEBUG)\n",
      "formatter = JsonFormatter()\n",
      "\n",
      "stdout_handler = JsonHandler(stdout_file)\n",
      "stdout_handler.setLevel(logging.INFO)\n",
      "stdout_handler.setFormatter(formatter)\n",
      "stdout_handler.addFilter(lambda record: record.levelno < logging.WARNING)\n",
      "\n",
      "if stderr_file == stdout_file:\n",
      "stderr_handler = stdout_handler\n",
      "else:  # TODO: large number of processes + high call frequency breaks the json formatting structure (bug)\n",
      "stderr_handler = JsonHandler(stderr_file)\n",
      "stderr_handler.setLevel(logging.WARNING)\n",
      "stderr_handler.setFormatter(formatter)\n",
      "stderr_handler.addFilter(lambda record: record.levelno >= logging.WARNING)\n",
      "\n",
      "# self.logger.handlers.clear()\n",
      "self.logger.addHandler(stdout_handler)\n",
      "self.logger.addHandler(stderr_handler)\n",
      "\n",
      "warnings.showwarning = self.warning_handler\n",
      "sys.excepthook = self.exception_handler\n",
      "\n",
      "# redirect all HF logs (at least datasets and transformers)\n",
      "datasets_logger = datasets.utils.logging.get_logger()\n",
      "transformers_logger = transformers.utils.logging.get_logger()\n",
      "\n",
      "datasets_logger.handlers = self.logger.handlers\n",
      "transformers_logger.handlers = self.logger.handlers\n",
      "\n",
      "@staticmethod\n",
      "def write_metrics_to_csv(metrics: dict[MetricName, MetricValue], path: str) -> None:\n",
      "with open(path, mode='a', newline='') as stream:\n",
      "writer = csv.DictWriter(stream, fieldnames=metrics.keys())\n",
      "if stream.tell() == 0:\n",
      "writer.writeheader()\n",
      "writer.writerow(metrics)\n",
      "\n",
      "def log(self, metrics: Log) -> Log:\n",
      "if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "return metrics  # repeated iterations between checkpoints\n",
      "\n",
      "iter_num = {'iter_num': metrics['iteration_number']}\n",
      "\n",
      "if 'train_metrics' in metrics:\n",
      "self.write_metrics_to_csv(iter_num | metrics['train_metrics'], self.train_csv)\n",
      "if 'valid_metrics' in metrics:\n",
      "self.write_metrics_to_csv(iter_num | metrics['valid_metrics'], self.valid_csv)\n",
      "\n",
      "return metrics\n",
      "\n",
      "def message(self, message: Message) -> Message:\n",
      "self.logger.info(message)\n",
      "return message\n",
      "\n",
      "def warning_handler(self, message: Warning, category: type, path: str, lineno: int, *_kwargs) -> None:\n",
      "self.logger.warning({\n",
      "'category': category.__name__,\n",
      "'location': f'{path}:{lineno}',\n",
      "'message': str(message),\n",
      "})\n",
      "\n",
      "def exception_handler(self, exc_type: type, exc_value: Exception, exc_traceback: TracebackType) -> NoReturn:\n",
      "if issubclass(exc_type, KeyboardInterrupt):\n",
      "self.message('Process was stopped due to a keyboard interrupt.')\n",
      "else:\n",
      "self.logger.error({\n",
      "'category': exc_type.__name__,\n",
      "'traceback': [{\n",
      "'location': f'{filename}:{lineno} in {func_name}',\n",
      "'line': line,\n",
      "} for filename, lineno, func_name, line in traceback.extract_tb(exc_traceback)],\n",
      "'message': str(exc_value),\n",
      "})\n",
      "self.message('Process finished with a non-zero exit code.')\n",
      "sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/logger_base.py\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict, TypeVar, Type\n",
      "from typing_extensions import NotRequired\n",
      "\n",
      "T = TypeVar('T')\n",
      "JsonAllowedTypes = dict | list | tuple | str | int | float | bool | None\n",
      "Message = str | int | float | dict[str, JsonAllowedTypes]\n",
      "\n",
      "\n",
      "class Log(TypedDict):  # TODO: replace with dataclass\n",
      "iteration_number: int\n",
      "train_metrics: NotRequired[dict[MetricName, MetricValue]]\n",
      "valid_metrics: NotRequired[dict[MetricName, MetricValue]]\n",
      "\n",
      "\n",
      "class LoggerBase(ABC):\n",
      "_instance = None  # singleton pattern\n",
      "\n",
      "def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "if cls._instance is None:\n",
      "cls._instance = super().__new__(cls)\n",
      "return cls._instance\n",
      "\n",
      "@abstractmethod\n",
      "def log(self, metrics: Log) -> Log:\n",
      "raise NotImplementedError\n",
      "\n",
      "@abstractmethod\n",
      "def message(self, message: Message) -> Message:\n",
      "raise NotImplementedError\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.outputs.loggers.logger_base import LoggerBase\n",
      "from pipeline.outputs.loggers.loggers_registry import LOGGERS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_logger(cls_name: str, loaded_config: DictConfig, **kwargs) -> LoggerBase:\n",
      "config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "logger = LOGGERS_REGISTRY[cls_name](**config.dict)\n",
      "return logger\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/wandb_logger.py\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "\n",
      "import wandb\n",
      "\n",
      "\n",
      "class WandbLogger(LocalLogger):\n",
      "def __init__(self,\n",
      "checkpointer: CheckpointManager,\n",
      "train_csv: str,\n",
      "valid_csv: str,\n",
      "stdout_file: str,\n",
      "stderr_file: str,\n",
      "directory: str,\n",
      "**wandb_init_kwargs,\n",
      ") -> None:\n",
      "super().__init__(train_csv, valid_csv, stdout_file, stderr_file, directory)\n",
      "wandb_init_kwargs['resume'] = wandb_init_kwargs.get('resume', checkpointer.get_wandb_resume_mode())\n",
      "wandb_init_kwargs['id'] = wandb_init_kwargs.get('id', wandb_init_kwargs['name'])\n",
      "wandb.init(**wandb_init_kwargs)\n",
      "\n",
      "def log(self, metrics: Log) -> Log:\n",
      "if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "return super().log(metrics)  # repeated iterations between checkpoints\n",
      "\n",
      "wandb_log = dict()\n",
      "if 'train_metrics' in metrics:\n",
      "wandb_log['train'] = metrics['train_metrics']\n",
      "if 'valid_metrics' in metrics:\n",
      "wandb_log['validation'] = metrics['valid_metrics']\n",
      "\n",
      "wandb.log(wandb_log, step=metrics['iteration_number'])\n",
      "return super().log(metrics)\n",
      "\n",
      "\n",
      "# ../pipeline/outputs/loggers/loggers_registry.py\n",
      "from pipeline.outputs.loggers.dummy_logger import DummyLogger\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.wandb_logger import WandbLogger\n",
      "\n",
      "LOGGERS_REGISTRY = {\n",
      "'dummy': DummyLogger,\n",
      "'local': LocalLogger,\n",
      "'wandb': WandbLogger,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/configs/configs_registry.py\n",
      "from pipeline.configs.checkpointer_config import (\n",
      "CheckpointManagerConfig,\n",
      "TopKCheckpointManagerConfig,\n",
      ")\n",
      "from pipeline.configs.composer_config import ChainedComposerConfig\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.configs.logger_config import (\n",
      "LocalLoggerConfig,\n",
      "WandbLoggerConfig,\n",
      ")\n",
      "from pipeline.configs.preprocessor_config import PreprocessorConfig\n",
      "from pipeline.configs.trainer_config import FullFineTuningTrainerConfig\n",
      "\n",
      "CONFIGS_REGISTRY = {\n",
      "# checkpointers\n",
      "'checkpointer': CheckpointManagerConfig,\n",
      "'top_k_checkpointer': TopKCheckpointManagerConfig,\n",
      "\n",
      "# loggers\n",
      "'dummy': ConfigBase,\n",
      "'local': LocalLoggerConfig,\n",
      "'wandb': WandbLoggerConfig,\n",
      "\n",
      "# composers\n",
      "'chained_composer': ChainedComposerConfig,\n",
      "\n",
      "# preprocessors\n",
      "'completion_loss_preprocessor': PreprocessorConfig,\n",
      "'file_level_preprocessor': PreprocessorConfig,\n",
      "'lm_preprocessor': PreprocessorConfig,\n",
      "\n",
      "# trainers\n",
      "'full_finetuning_trainer': FullFineTuningTrainerConfig,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/configs/model_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Literal\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class ModelConfig(ConfigBase):\n",
      "tokenizer_name: str\n",
      "model_name: str\n",
      "trust_remote_code: bool\n",
      "load_from: str | None\n",
      "\n",
      "use_cache: bool = False\n",
      "device: torch.device | None = None\n",
      "dtype: torch.dtype | None = None\n",
      "attn_implementation: Literal['flash_attention_2', 'sdpa', 'eager'] | None = None\n",
      "compile: bool = True\n",
      "\n",
      "def __post_init__(self) -> None:\n",
      "if isinstance(self.device, str):\n",
      "self.device = torch.device(self.device)\n",
      "\n",
      "if isinstance(self.dtype, str):\n",
      "self.dtype = getattr(torch, self.dtype)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/logger_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Any\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class LocalLoggerConfig(ConfigBase):\n",
      "train_csv: str\n",
      "valid_csv: str\n",
      "stdout_file: str\n",
      "stderr_file: str\n",
      "directory: str\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class WandbLoggerConfig(LocalLoggerConfig):\n",
      "checkpointer: CheckpointManager\n",
      "project: str\n",
      "name: str\n",
      "config: dict[str, Any] | None = None\n",
      "group: str | None = None\n",
      "notes: str | None = None\n",
      "\n",
      "\n",
      "# ../pipeline/configs/composer_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "\n",
      "from dataclasses import dataclass, field\n",
      "from typing import Sequence\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class ChainedComposerConfig(ConfigBase):\n",
      "pre_context_prompt: str\n",
      "post_context_prompt: str\n",
      "path_comment_template: str\n",
      "recalculate_random_category: bool\n",
      "blocks: Sequence[ComposerBlock] = field(default_factory=list)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/checkpointer_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.data_structures import LoadingMode\n",
      "from pipeline.outputs.metrics.metric_base import MetricName\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Callable\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class CheckpointManagerConfig(ConfigBase):\n",
      "init_from: LoadingMode | str\n",
      "main_metric: MetricName\n",
      "directory: str\n",
      "\n",
      "# if you want to change it, override the following function accordingly\n",
      "checkpoint_directory_template: str = '{iteration_number:04d}'\n",
      "extract_iteration_number: Callable[[str], int] = staticmethod(int)\n",
      "\n",
      "model_subdirectory: str = 'model'\n",
      "optim_state_filename: str = 'optim.pt'\n",
      "metrics_filename: str = 'metrics.json'  # should be .json\n",
      "\n",
      "def __post_init__(self) -> None:\n",
      "if self.init_from in set(LoadingMode):\n",
      "self.init_from = LoadingMode(self.init_from)\n",
      "\n",
      "\n",
      "@dataclass(kw_only=True)\n",
      "class TopKCheckpointManagerConfig(CheckpointManagerConfig):\n",
      "max_checkpoints_num: int\n",
      "\n",
      "\n",
      "# ../pipeline/configs/preprocessor_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class PreprocessorConfig(ConfigBase):\n",
      "tokenizer: PreTrainedTokenizerBase\n",
      "max_seq_len: int\n",
      "context_tokens: int | float\n",
      "loss_ratio: float\n",
      "num_chars_per_token: int\n",
      "padding: bool\n",
      "verbose: bool = True\n",
      "\n",
      "\n",
      "# ../pipeline/configs/dataset_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "\n",
      "from datasets import config\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class DatasetConfig(ConfigBase):\n",
      "path: str\n",
      "name: str | None = None\n",
      "data_dir: str | None = None\n",
      "split: str | None = None\n",
      "cache_dir: str = str(config.HF_DATASETS_CACHE)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/config_base.py\n",
      "from dataclasses import asdict, dataclass, fields\n",
      "from pprint import pformat\n",
      "from typing import Any, TypeVar, Type\n",
      "\n",
      "import yaml\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class ConfigBase:\n",
      "def __str__(self) -> str:\n",
      "return pformat(self)\n",
      "\n",
      "@classmethod\n",
      "def from_dict(cls: Type[T], dictionary: dict[str, Any]) -> T:\n",
      "config_fields = set(field.name for field in fields(cls))\n",
      "kwargs = {key: value for key, value in dictionary.items() if key in config_fields}\n",
      "return cls(**kwargs)  # noqa: PyCharm bug?\n",
      "\n",
      "@classmethod\n",
      "def from_yaml(cls: Type[T], path: str | None = None) -> T:\n",
      "if path is None:\n",
      "path = cls._default_path\n",
      "\n",
      "with open(path) as stream:\n",
      "return cls(**yaml.safe_load(stream))  # noqa: PyCharm bug?\n",
      "\n",
      "dict = property(vars)\n",
      "\n",
      "\n",
      "# ../pipeline/configs/trainer_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.logger_base import LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import Literal\n",
      "\n",
      "from datasets import Dataset\n",
      "from transformers import PreTrainedModel, PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class FullFineTuningTrainerConfig(ConfigBase):\n",
      "model: PreTrainedModel\n",
      "tokenizer: PreTrainedTokenizerBase\n",
      "train_ds: Dataset\n",
      "valid_ds: Dataset | None\n",
      "\n",
      "# Auxiliary objects\n",
      "checkpointer: CheckpointManager\n",
      "logger: LoggerBase\n",
      "\n",
      "# Iteration parameters\n",
      "max_iters: int\n",
      "valid_freq: int | None  # None means no validation at all\n",
      "checkpointing_freq: int | None  # None means no checkpointing at all\n",
      "gradient_accumulation_steps: int\n",
      "micro_batch_size: int\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: float\n",
      "beta_1: float\n",
      "beta_2: float\n",
      "weight_decay: float\n",
      "max_grad_norm: float\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: int | None\n",
      "lr_decay_iters: int | None\n",
      "min_lr: float | None\n",
      "\n",
      "# Metrics (see METRICS_REGISTRY in pipeline/outputs/metrics/metrics_registry.py)\n",
      "train_metrics: list[MetricName]\n",
      "train_ema_alpha: float  # (see ema_factory in pipeline/outputs/metrics/statistic_base.py)\n",
      "valid_metrics: list[MetricName]  # empty list means no validation at all\n",
      "valid_ema_alpha: float | None  # if None, will be calculated as 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "\n",
      "# DataLoader\n",
      "shuffle: bool\n",
      "drop_last: bool\n",
      "num_workers: int\n",
      "prefetch_factor: int | None\n",
      "random_seed: int | None\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: Literal['highest', 'high', 'medium']\n",
      "\n",
      "\n",
      "# ../pipeline/configs/split_config.py\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "\n",
      "from dataclasses import dataclass\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class SplitConfig(ConfigBase):\n",
      "test_size: int  # 0 means no validation at all\n",
      "upper_bound_per_repo: int\n",
      "random_seed: int | None\n",
      "\n",
      "\n",
      "# ../pipeline/model/init.py\n",
      "from pipeline.configs.model_config import ModelConfig\n",
      "from pipeline.environment.hardware import get_free_device, get_optimal_dtype\n",
      "\n",
      "from enum import Enum\n",
      "\n",
      "import torch\n",
      "from omegaconf import DictConfig\n",
      "from transformers.models.auto import MODEL_FOR_CAUSAL_LM_MAPPING\n",
      "from transformers.utils import is_flash_attn_2_available, is_torch_sdpa_available\n",
      "from transformers import (\n",
      "AutoTokenizer,\n",
      "AutoModelForCausalLM,\n",
      "AutoConfig,\n",
      "PreTrainedModel,\n",
      "PreTrainedTokenizerBase,\n",
      ")\n",
      "\n",
      "\n",
      "class AttentionImplementation(str, Enum):\n",
      "# nondeterministic\n",
      "FA2 = 'flash_attention_2'\n",
      "SDPA = 'sdpa'\n",
      "# deterministic\n",
      "EAGER = 'eager'\n",
      "\n",
      "\n",
      "def init_tokenizer(config: ModelConfig) -> PreTrainedTokenizerBase:\n",
      "return AutoTokenizer.from_pretrained(\n",
      "pretrained_model_name_or_path=config.tokenizer_name,\n",
      "trust_remote_code=config.trust_remote_code,\n",
      ")\n",
      "\n",
      "\n",
      "def get_optimal_attn(model_name: str, device: torch.device, dtype: torch.dtype) -> AttentionImplementation:\n",
      "hf_model_config = AutoConfig.from_pretrained(model_name)\n",
      "model_cls = MODEL_FOR_CAUSAL_LM_MAPPING[type(hf_model_config)]\n",
      "\n",
      "fa2_supported = (\n",
      "is_flash_attn_2_available() and\n",
      "model_cls._supports_flash_attn_2 and  # noqa: HF doesn't have an API for this case\n",
      "device.type == 'cuda' and\n",
      "dtype in (torch.float16, torch.bfloat16)\n",
      ")\n",
      "\n",
      "if fa2_supported:\n",
      "return AttentionImplementation.FA2\n",
      "elif is_torch_sdpa_available() and model_cls._supports_sdpa:  # noqa: same\n",
      "return AttentionImplementation.SDPA\n",
      "else:\n",
      "return AttentionImplementation.EAGER\n",
      "\n",
      "\n",
      "def init_model(config: ModelConfig) -> PreTrainedModel:\n",
      "if config.device is None:\n",
      "config.device = get_free_device()\n",
      "if config.dtype is None:\n",
      "config.dtype = get_optimal_dtype()\n",
      "if config.attn_implementation is None:\n",
      "config.attn_implementation = get_optimal_attn(config.model_name, config.device, config.dtype)\n",
      "if config.load_from is None:\n",
      "config.load_from = config.model_name\n",
      "\n",
      "model = AutoModelForCausalLM.from_pretrained(\n",
      "pretrained_model_name_or_path=config.load_from,\n",
      "trust_remote_code=config.trust_remote_code,\n",
      "device_map=config.device,\n",
      "torch_dtype=config.dtype,\n",
      "attn_implementation=config.attn_implementation,\n",
      "use_cache=config.use_cache,\n",
      ")\n",
      "\n",
      "if config.compile:\n",
      "model = torch.compile(model)\n",
      "return model\n",
      "\n",
      "\n",
      "def init_tokenizer_model(loaded_config: DictConfig, **kwargs) -> tuple[PreTrainedTokenizerBase, PreTrainedModel]:\n",
      "config = ModelConfig.from_dict(dict(loaded_config) | kwargs)\n",
      "return init_tokenizer(config), init_model(config)\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/init.py\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.trainers_registry import TRAINERS_REGISTRY\n",
      "\n",
      "from omegaconf import DictConfig\n",
      "\n",
      "\n",
      "def init_trainer(cls_name: str, loaded_config: DictConfig, **kwargs) -> TrainerBase:\n",
      "config = CONFIGS_REGISTRY[cls_name].from_dict(dict(loaded_config) | kwargs)\n",
      "trainer = TRAINERS_REGISTRY[cls_name](**config.dict)\n",
      "return trainer\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/full_finetuning_trainer.py\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.data_structures import Checkpoint\n",
      "from pipeline.outputs.loggers.logger_base import Log, LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.utils.fused_sampler import FusedSampler\n",
      "from pipeline.trainers.utils.schedulers import get_lr_from_cosine_scheduler_with_linear_warmup\n",
      "\n",
      "import warnings\n",
      "from functools import partial\n",
      "from typing import Literal\n",
      "\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from datasets import Dataset\n",
      "from torch.utils.data import DataLoader\n",
      "from tqdm.auto import trange, tqdm\n",
      "from transformers import PreTrainedModel, PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class FullFineTuningTrainer(TrainerBase):\n",
      "def __init__(self,\n",
      "model: PreTrainedModel,\n",
      "tokenizer: PreTrainedTokenizerBase,\n",
      "train_ds: Dataset,\n",
      "valid_ds: Dataset | None,\n",
      "# auxiliary objects\n",
      "checkpointer: CheckpointManager,\n",
      "logger: LoggerBase,\n",
      "# iteration parameters\n",
      "max_iters: int,\n",
      "valid_freq: int | None,\n",
      "checkpointing_freq: int | None,\n",
      "gradient_accumulation_steps: int,\n",
      "micro_batch_size: int,\n",
      "# optimizer\n",
      "learning_rate: float,\n",
      "beta_1: float,\n",
      "beta_2: float,\n",
      "weight_decay: float,\n",
      "max_grad_norm: float,\n",
      "# scheduler\n",
      "warmup_iters: int | None,\n",
      "lr_decay_iters: int | None,\n",
      "min_lr: float | None,\n",
      "# metrics\n",
      "train_metrics: list[MetricName],\n",
      "train_ema_alpha: float,\n",
      "valid_metrics: list[MetricName],\n",
      "valid_ema_alpha: float | None,\n",
      "# DataLoader\n",
      "shuffle: bool,\n",
      "drop_last: bool,\n",
      "num_workers: int,\n",
      "prefetch_factor: int,\n",
      "random_seed: int | None,\n",
      "# Floating point\n",
      "fp32_matmul_precision: Literal['highest', 'high', 'medium'],\n",
      ") -> None:\n",
      "# main objects\n",
      "self.model = model\n",
      "self.tokenizer = tokenizer\n",
      "self.checkpointer = checkpointer\n",
      "self.logger = logger\n",
      "\n",
      "# iterations\n",
      "self.checkpointing_freq = checkpointing_freq\n",
      "\n",
      "if checkpointing_freq is None:\n",
      "self.checkpointing_freq = float('inf')\n",
      "self.logger.message('Checkpointing is disabled.')\n",
      "elif valid_freq is not None and valid_freq != checkpointing_freq:\n",
      "warnings.warn('Validation and checkpointing are not synchronized (valid_freq != checkpointing_freq). '\n",
      "'Resulting checkpoints will not contain validation metrics.')\n",
      "\n",
      "self.start_iter = checkpointer.get_iteration_number()\n",
      "self.max_iters = max_iters\n",
      "self.gradient_accumulation_steps = gradient_accumulation_steps\n",
      "self.batch_size = gradient_accumulation_steps * micro_batch_size\n",
      "\n",
      "# environment\n",
      "self.is_on_cuda = (model.device.type == 'cuda')\n",
      "if random_seed is not None:\n",
      "torch.manual_seed(random_seed)\n",
      "torch.set_float32_matmul_precision(fp32_matmul_precision)\n",
      "logger.message(f\"Set the FP32 matrix multiplication precision to '{fp32_matmul_precision}'.\")\n",
      "\n",
      "# validation\n",
      "if valid_ds is None and valid_freq is None and not valid_metrics:\n",
      "self.valid_freq = float('inf')\n",
      "self.valid_dl = None\n",
      "self.logger.message('Validation is disabled.')\n",
      "elif valid_ds is not None and valid_freq is not None and valid_metrics:\n",
      "self.valid_freq = valid_freq\n",
      "self.valid_dl = DataLoader(\n",
      "dataset=valid_ds,\n",
      "batch_size=micro_batch_size,\n",
      "shuffle=False,\n",
      "num_workers=num_workers,\n",
      "pin_memory=self.is_on_cuda,\n",
      "drop_last=False,\n",
      "prefetch_factor=prefetch_factor,\n",
      "persistent_workers=(valid_freq > max_iters),\n",
      "pin_memory_device=str(model.device),\n",
      ")\n",
      "\n",
      "if valid_ema_alpha is None:\n",
      "valid_ema_alpha = 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "self.logger.message(f'valid_ema_alpha automatically set to {valid_ema_alpha:.05f}.')\n",
      "\n",
      "else:\n",
      "raise ValueError('The valid_ds, valid_freq and valid_metrics arguments do not match each other.')\n",
      "\n",
      "# training dataset\n",
      "sampler = FusedSampler(\n",
      "start_sample_idx=(self.batch_size * self.start_iter),\n",
      "end_sample_idx=(self.batch_size * max_iters),\n",
      "dataset_length=len(train_ds),\n",
      ") if shuffle else None\n",
      "\n",
      "self.train_dl = DataLoader(\n",
      "dataset=train_ds,\n",
      "batch_size=micro_batch_size,\n",
      "sampler=sampler,\n",
      "num_workers=num_workers,\n",
      "pin_memory=self.is_on_cuda,\n",
      "drop_last=drop_last,\n",
      "prefetch_factor=prefetch_factor,\n",
      "pin_memory_device=str(model.device),\n",
      ")\n",
      "\n",
      "# optimizer initialization\n",
      "self.optimizer = self._init_adamw(learning_rate, beta_1, beta_2, weight_decay)\n",
      "\n",
      "# gradient utilities\n",
      "self.grad_scaler = torch.cuda.amp.GradScaler(enabled=(model.dtype == torch.float16))\n",
      "self.max_grad_norm = max_grad_norm\n",
      "\n",
      "# scheduler initialization\n",
      "if warmup_iters is None and lr_decay_iters is None and min_lr is None:\n",
      "self.get_lr = lambda _: learning_rate\n",
      "elif warmup_iters is not None and lr_decay_iters is not None and min_lr is not None:\n",
      "self.get_lr = partial(\n",
      "get_lr_from_cosine_scheduler_with_linear_warmup,\n",
      "min_lr=min_lr,\n",
      "max_lr=learning_rate,\n",
      "warmup_iters=warmup_iters,\n",
      "lr_decay_iters=lr_decay_iters,\n",
      ")\n",
      "else:\n",
      "raise ValueError('The warmup_iters, lr_decay_iters and min_lr arguments do not match each other.')\n",
      "\n",
      "# metrics\n",
      "self.train_metrics = self.checkpointer.init_metrics('train_metrics', train_metrics, train_ema_alpha)\n",
      "self.valid_metrics = self.checkpointer.init_metrics('valid_metrics', valid_metrics, valid_ema_alpha)\n",
      "\n",
      "def _init_adamw(self,\n",
      "learning_rate: float,\n",
      "beta_1: float,\n",
      "beta_2: float,\n",
      "weight_decay: float,\n",
      ") -> torch.optim.AdamW:\n",
      "decay_params = [p for p in self.model.parameters() if p.dim() >= 2]\n",
      "no_decay_params = [p for p in self.model.parameters() if p.dim() < 2]\n",
      "params = [\n",
      "{'params': decay_params, 'weight_decay': weight_decay},\n",
      "{'params': no_decay_params, 'weight_decay': 0},\n",
      "]\n",
      "\n",
      "optimizer = torch.optim.AdamW(\n",
      "params=params,\n",
      "lr=learning_rate,\n",
      "betas=(beta_1, beta_2),\n",
      "fused=self.is_on_cuda)\n",
      "self.checkpointer.init_optimizer(optimizer)\n",
      "\n",
      "return optimizer\n",
      "\n",
      "@torch.inference_mode\n",
      "def validate(self, verbose: bool = True) -> dict[MetricName, MetricValue]:\n",
      "training = self.model.training\n",
      "self.model.eval()\n",
      "\n",
      "valid_iter = tqdm(\n",
      "iterable=self.valid_dl,\n",
      "desc='Validation steps',\n",
      "position=1,\n",
      "leave=None,\n",
      "disable=not verbose,\n",
      ")\n",
      "\n",
      "for micro_batch in valid_iter:\n",
      "(input_ids, target_ids,\n",
      "loss_mask, completion_mask, category_ids,\n",
      "input_attn_mask, target_attn_mask,\n",
      ") = (t.to(self.model.device) for t in micro_batch.values())\n",
      "\n",
      "model_output = self.model(input_ids, attention_mask=input_attn_mask)\n",
      "loss_per_token = F.cross_entropy(\n",
      "input=model_output.logits.flatten(0, 1),\n",
      "target=target_ids.flatten(0, 1),\n",
      "reduction='none',\n",
      ").view_as(target_ids)\n",
      "\n",
      "locals_copy = locals().copy()\n",
      "locals_copy['trainer'] = locals_copy.pop('self')\n",
      "[metric.micro_batch_update(**locals_copy) for metric in self.valid_metrics.values()]\n",
      "del locals_copy\n",
      "\n",
      "valid_log = {name: metric.batch_commit() for name, metric in self.valid_metrics.items()}\n",
      "\n",
      "self.model.train(training)\n",
      "return valid_log\n",
      "\n",
      "def train(self, verbose: bool = True) -> None:\n",
      "self.model.train()\n",
      "\n",
      "train_iter = iter(self.train_dl)\n",
      "pbar_iter = trange(\n",
      "self.start_iter, self.max_iters,\n",
      "desc='Optimization steps',\n",
      "initial=self.start_iter,\n",
      "total=self.max_iters,\n",
      "position=0,\n",
      "disable=not verbose,\n",
      ")\n",
      "pbar_accumulation = trange(\n",
      "self.gradient_accumulation_steps,\n",
      "desc='Gradient accumulation steps',\n",
      "position=1,\n",
      "leave=None,\n",
      "disable=not verbose,\n",
      ")\n",
      "\n",
      "if self.start_iter == 0 and self.valid_dl is not None:\n",
      "log = Log(iteration_number=0, valid_metrics=self.validate(verbose))\n",
      "self.logger.log(log)\n",
      "\n",
      "for iter_num in pbar_iter:\n",
      "pbar_accumulation.reset()\n",
      "\n",
      "learning_rate = self.get_lr(iter_num)\n",
      "for param_group in self.optimizer.param_groups:\n",
      "param_group['lr'] = learning_rate\n",
      "\n",
      "for _ in range(self.gradient_accumulation_steps):\n",
      "(input_ids, target_ids,\n",
      "loss_mask, completion_mask, category_ids,\n",
      "input_attn_mask, target_attn_mask,\n",
      ") = (t.to(self.model.device) for t in next(train_iter).values())\n",
      "\n",
      "model_output = self.model(input_ids, attention_mask=input_attn_mask)\n",
      "loss_per_token = F.cross_entropy(\n",
      "input=model_output.logits.flatten(0, 1),\n",
      "target=target_ids.flatten(0, 1),\n",
      "reduction='none',\n",
      ").view_as(target_ids)\n",
      "# not accurate if drop_last=False and micro_batch_size != 1\n",
      "# see also PreprocessorBase.get_loss_mask comment in pipeline/data/preprocessors/preprocessor_base.py\n",
      "loss = loss_per_token[loss_mask].mean() / self.gradient_accumulation_steps\n",
      "\n",
      "self.grad_scaler.scale(loss).backward()\n",
      "\n",
      "locals_copy = locals().copy()\n",
      "locals_copy['trainer'] = locals_copy.pop('self')\n",
      "[metric.micro_batch_update(**locals_copy) for metric in self.train_metrics.values()]\n",
      "del locals_copy\n",
      "\n",
      "pbar_accumulation.update()\n",
      "\n",
      "if self.max_grad_norm != 0:\n",
      "self.grad_scaler.unscale_(self.optimizer)\n",
      "grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
      "\n",
      "self.grad_scaler.step(self.optimizer)\n",
      "self.grad_scaler.update()\n",
      "self.optimizer.zero_grad(set_to_none=True)\n",
      "\n",
      "log = Log(\n",
      "iteration_number=iter_num + 1,\n",
      "train_metrics={name: metric.batch_commit() for name, metric in self.train_metrics.items()},\n",
      ")\n",
      "if (iter_num + 1) % self.valid_freq == 0:\n",
      "log['valid_metrics'] = self.validate(verbose)\n",
      "self.logger.log(log)\n",
      "\n",
      "if (iter_num + 1) % self.checkpointing_freq == 0:\n",
      "self.checkpointer.save_checkpoint(Checkpoint(\n",
      "metrics=log,\n",
      "model=self.model,\n",
      "optimizer_state=self.optimizer.state_dict(),\n",
      "))\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/trainer_base.py\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class TrainerBase(ABC):\n",
      "@abstractmethod\n",
      "@torch.inference_mode\n",
      "def validate(self, *args, **kwargs) -> dict[MetricName, MetricValue]:\n",
      "raise NotImplementedError\n",
      "\n",
      "@abstractmethod\n",
      "def train(self, *args, **kwargs) -> None:\n",
      "raise NotImplementedError\n",
      "\n",
      "# ../pipeline/trainers/trainers_registry.py\n",
      "from pipeline.trainers.full_finetuning_trainer import FullFineTuningTrainer\n",
      "\n",
      "TRAINERS_REGISTRY = {\n",
      "'full_finetuning_trainer': FullFineTuningTrainer,\n",
      "}\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/utils/fused_sampler.py\n",
      "import math\n",
      "from typing import Iterator\n",
      "\n",
      "import torch\n",
      "from torch.utils.data import Sampler\n",
      "\n",
      "\n",
      "class FusedSampler(Sampler[int]):\n",
      "def __init__(self,\n",
      "start_sample_idx: int,\n",
      "end_sample_idx: int,\n",
      "dataset_length: int,\n",
      "generator: torch.Generator | None = None,\n",
      ") -> None:\n",
      "super().__init__()\n",
      "\n",
      "self.start_sample_idx = start_sample_idx\n",
      "self.end_sample_idx = end_sample_idx\n",
      "self.dataset_length = dataset_length\n",
      "self.max_epochs = math.ceil(end_sample_idx / dataset_length)\n",
      "self.generator = generator\n",
      "\n",
      "def __iter__(self) -> Iterator[int]:\n",
      "fused_weights = torch.rand(self.max_epochs, self.dataset_length, generator=self.generator)\n",
      "fused_indices = torch.argsort(fused_weights, dim=-1).flatten().tolist()\n",
      "yield from fused_indices[self.start_sample_idx:self.end_sample_idx]\n",
      "\n",
      "def __len__(self) -> int:\n",
      "return self.end_sample_idx - self.start_sample_idx\n",
      "\n",
      "\n",
      "# ../pipeline/trainers/utils/schedulers.py\n",
      "import math\n",
      "\n",
      "\n",
      "def get_lr_from_cosine_scheduler_with_linear_warmup(iter_num: int,\n",
      "min_lr: float,\n",
      "max_lr: float,\n",
      "warmup_iters: int,\n",
      "lr_decay_iters: int,\n",
      ") -> float:\n",
      "if iter_num < warmup_iters:  # warmup\n",
      "return max_lr * (iter_num + 1) / warmup_iters\n",
      "elif iter_num > lr_decay_iters:  # constant lr\n",
      "return min_lr\n",
      "else:  # cosine wave\n",
      "decay_ratio = (iter_num - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
      "return min_lr + (max_lr - min_lr) / 2 * (1 + math.cos(math.pi * decay_ratio))\n",
      "\n",
      "\n",
      "# ../configs/defaults.yaml\n",
      "run_name: ???\n",
      "\n",
      "defaults:\n",
      "- checkpointer: top_k_checkpointer/top_3\n",
      "- composer: chained_composer/standard\n",
      "- dataset: train_A100_server\n",
      "- logger: wandb/wandb\n",
      "- model: dseek1p3\n",
      "- preprocessor: completion_loss_preprocessor/full_completion_loss_16k\n",
      "- split: '256_5'\n",
      "- trainer: full_finetuning_trainer/medium_lr\n",
      "\n",
      "- _self_\n",
      "- override hydra/hydra_logging: disabled\n",
      "- override hydra/job_logging: disabled\n",
      "\n",
      "hydra:\n",
      "output_subdir: null\n",
      "run:\n",
      "dir: .\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/completion_loss_preprocessor/full_completion_loss_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/completion_loss_preprocessor/no_import_and_license_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 0.9\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/completion_loss_preprocessor/debugging.yaml\n",
      "max_seq_len: 1024\n",
      "context_tokens: 512\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/lm_preprocessor/full_input_loss_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/preprocessor/file_level_preprocessor/full_completion_loss_16k.yaml\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/high_lr.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 7.0e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 25\n",
      "lr_decay_iters: 600\n",
      "min_lr: 1.0e-7\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/more_workers.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 32\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/medium_lr.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 600\n",
      "valid_freq: 25\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/trainer/full_finetuning_trainer/debugging.yaml\n",
      "# Iteration parameters\n",
      "max_iters: 20\n",
      "valid_freq: 5\n",
      "checkpointing_freq: null\n",
      "gradient_accumulation_steps: 16\n",
      "micro_batch_size: 1\n",
      "\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "min_lr: 5.0e-8\n",
      "\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "cross_entropy,\n",
      "detached_cross_entropy,\n",
      "completion_cross_entropy,\n",
      "context_cross_entropy,\n",
      "full_cross_entropy,\n",
      "commited_cross_entropy,\n",
      "common_cross_entropy,\n",
      "infile_cross_entropy,\n",
      "inproject_cross_entropy,\n",
      "non_informative_cross_entropy,\n",
      "random_cross_entropy,\n",
      "epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "\n",
      "# DataLoader\n",
      "shuffle: True\n",
      "drop_last: False\n",
      "num_workers: 8\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/empty.yaml\n",
      "pre_context_prompt: ''\n",
      "post_context_prompt: ''\n",
      "path_comment_template: '{content}'\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/empty.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/no_long_files.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_filtering/file_length_filter/0_20k.yaml,\n",
      "file_preprocessing/empty_lines_removal_preprocessor/no_args.yaml,\n",
      "file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/standard.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/strip.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "context_postprocessing/line_strip_postprocessor/no_args.yaml,\n",
      "context_postprocessing/line_length_postprocessor/10_200.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/most_absolute_callable.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/random_declarations.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "file_preprocessing/declaration_only_preprocessor/no_args.yaml,\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/random_ranker/1337.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/low_tokens_ratio_filtering.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_filtering/char_token_ratio_filter/1p5_inf.yaml,\n",
      "file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/most_relative_callable.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/function_call_ranker/relative.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/func_calls_with_strip.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "context_postprocessing/line_strip_postprocessor/no_args.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/nearest_declarations.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "file_preprocessing/declaration_only_preprocessor/no_args.yaml,\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/half_memory.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "context_postprocessing/partial_memory_postprocessor/half_memory.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/grouped_text_files.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/file_extension_ranker/text_files.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/python_files.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/pure_func_calls.yaml\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "\n",
      "block_configs: [\n",
      "file_filtering/empty_file_filter/no_args.yaml,\n",
      "file_chunking/file_grained_chunker/no_args.yaml,\n",
      "chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_preprocessing/empty_lines_removal_preprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_preprocessing/declaration_only_preprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_chunking/file_grained_chunker/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_chunking/code_segment_grained_chunker/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_harvesting/joining_harvester/double_newline.yaml\n",
      "chunks_sep: \"\\n\\n\"\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_harvesting/path_comment_harvester/empty.yaml\n",
      "chunks_sep: \"\\n\\n\"\n",
      "path_comment_template: '{content}'\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_harvesting/path_comment_harvester/standard.yaml\n",
      "chunks_sep: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_sorting/lexicographic_sorter/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/inverse_frequency_memory_postprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/partial_memory_postprocessor/half_memory.yaml\n",
      "dropout: 0.5\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/line_strip_postprocessor/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/context_postprocessing/line_length_postprocessor/10_200.yaml\n",
      "min_len: 10\n",
      "max_len: 200\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/file_extension_ranker/text_files.yaml\n",
      "ordered_groups: [[.json], [.yaml, .yml], [.sh], [.md, .txt, .rst]]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/negative_path_distance_ranker/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/function_call_ranker/absolute.yaml\n",
      "is_relative: False\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/function_call_ranker/relative.yaml\n",
      "is_relative: True\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/chunk_ranking/random_ranker/1337.yaml\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/file_length_filter/0_20k.yaml\n",
      "min_len: 0\n",
      "max_len: 20000\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/file_length_filter/no_effect.yaml\n",
      "min_len: 0\n",
      "max_len: !!float .inf\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/empty_file_filter/no_args.yaml\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/tokenized_file_length_filter/no_effect.yaml\n",
      "min_len: 0\n",
      "max_len: !!float .inf\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/inclusive_file_extension_filter/python_files.yaml\n",
      "whitelist: [.py]\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/char_token_ratio_filter/3_6.yaml\n",
      "min_ratio: 3\n",
      "max_ratio: 6\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/char_token_ratio_filter/1p5_inf.yaml\n",
      "min_ratio: 1.5\n",
      "max_ratio: !!float .inf\n",
      "subsequence_len: 2048\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/composer/chained_composer/blocks/file_filtering/exclusive_file_extension_filter/empty.yaml\n",
      "blacklist: []\n",
      "\n",
      "\n",
      "# ../configs/model/dseek1p3.yaml\n",
      "tokenizer_name: deepseek-ai/deepseek-coder-1.3b-base\n",
      "model_name: deepseek-ai/deepseek-coder-1.3b-base\n",
      "trust_remote_code: True\n",
      "compile: False\n",
      "\n",
      "\n",
      "# ../configs/split/256_5.yaml\n",
      "test_size: 256\n",
      "upper_bound_per_repo: 5\n",
      "random_seed: 1337\n",
      "\n",
      "\n",
      "# ../configs/checkpointer/top_k_checkpointer/top_3.yaml\n",
      "init_from: resume\n",
      "main_metric: cross_entropy\n",
      "max_checkpoints_num: 3\n",
      "\n",
      "\n",
      "# ../configs/checkpointer/checkpointer/standard.yaml\n",
      "init_from: resume\n",
      "main_metric: cross_entropy\n",
      "\n",
      "\n",
      "# ../configs/dataset/small.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: small_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../configs/dataset/huge.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: huge_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../configs/dataset/train_A100_server.yaml\n",
      "path: JetBrains-Research/lca-codegen-train\n",
      "data_dir: train\n",
      "split: train\n",
      "\n",
      "\n",
      "# ../configs/dataset/train.yaml\n",
      "path: JetBrains-Research/lca-codegen-train\n",
      "data_dir: train\n",
      "split: train\n",
      "cache_dir: /mnt/data2/shared-data/lca/hf_cache/\n",
      "\n",
      "\n",
      "# ../configs/dataset/large.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: large_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../configs/dataset/medium.yaml\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: medium_context\n",
      "split: test\n",
      "\n",
      "\n",
      "# ../configs/logger/wandb/wandb.yaml\n",
      "train_csv: train.csv\n",
      "valid_csv: valid.csv\n",
      "stdout_file: stdout.json\n",
      "stderr_file: stderr.json\n",
      "project: LCA Context Composers\n",
      "\n",
      "\n",
      "# ../configs/logger/local/local.yaml\n",
      "train_csv: train.csv\n",
      "valid_csv: valid.csv\n",
      "stdout_file: stdout.json\n",
      "stderr_file: stderr.json\n",
      "\n",
      "\n",
      "# ../configs/logger/dummy/debugging.yaml\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa34e05-caf4-479e-a318-3a6708d6e501",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Half-Memory Composer without Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6becd9a7-b5d5-49fa-b4df-edb13fb39920",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ChainedComposer([\n",
    "    EmptyLinesRemovalPreprocessor(),\n",
    "    FileGrainedChunker(),\n",
    "    JoiningHarvester(chunks_sep='\\n'),\n",
    "    PartialMemoryPostprocessor(dropout=0.5, random_seed=42),\n",
    "],\n",
    "    **composer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d326c91-54e5-487b-b00a-7a328816ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import subprocess\n",
      "    if hasattr(get_free_device, 'allocated'):\n",
      "        return get_free_device.allocated\n",
      "    for gpu_index in range(torch.cuda.device_count()):\n",
      "            'nvidia-smi', f'-i={gpu_index}', '--query-gpu=memory.used,memory.total', '--format=csv,noheader',\n",
      "        if not gpu_pid_stats and mem_used / mem_total <= used_memory_upper_bound:\n",
      "            get_free_device.allocated = torch.device(f'cuda:{gpu_index}')\n",
      "    warnings.warn('No CUDA devices were found. CPU will be used.')\n",
      "    return torch.device('cpu')\n",
      "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
      "        return torch.bfloat16\n",
      "                      'with gradient scaling will be used instead.')\n",
      "ID2CATEGORY = [\n",
      "    'commited',\n",
      "    'common',\n",
      "    'infile',\n",
      "    'inproject',\n",
      "    'non_informative',\n",
      "    'other',\n",
      "]\n",
      "CATEGORY2ID = {category: i for i, category in enumerate(ID2CATEGORY)}\n",
      "UNDEFINED_CATEGORY_ID = -1\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessorBase\n",
      "                     ) -> tuple[Dataset, Dataset | None]:\n",
      "    repos_enum = list(enumerate(dataset['repo']))\n",
      "    generator.shuffle(repos_enum)\n",
      "    for idx, repo in repos_enum:\n",
      "    queue = list(queue.items())\n",
      "    test_repos_ids = set()\n",
      "    cur_test_size = 0\n",
      "    while cur_test_size != test_size:\n",
      "        if queue:\n",
      "            repo, ids = queue.pop()\n",
      "        else:\n",
      "        train_repos_ids.difference_update(ids)\n",
      "        test_repos_ids.update(ids[:num_new_samples])\n",
      "    train_ds = dataset.select(train_repos_ids)\n",
      "    return train_ds, test_ds\n",
      "                  preprocessor: PreprocessorBase,\n",
      "    transform = lambda x: preprocessor(composer.compose_batch(x))\n",
      "    train_ds.set_transform(transform)\n",
      "from dataclasses import dataclass\n",
      "from typing import TypedDict\n",
      "class CompletionLines(TypedDict, total=False):\n",
      "    commited: list[int]\n",
      "    non_informative: list[int]\n",
      "    random: list[int]\n",
      "    other: list[int]\n",
      "class RepoSnapshot(TypedDict):\n",
      "    content: list[str]\n",
      "@dataclass\n",
      "class Datapoint:\n",
      "    commit_hash: str\n",
      "    completion_lines_raw: CompletionLines | None = None\n",
      "class BatchDatapoint(TypedDict):\n",
      "    commit_hash: list[str]\n",
      "    completion_lines: list[CompletionLines]\n",
      "    repo_snapshot: list[RepoSnapshot]\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "from typing import TypedDict\n",
      "    pre_context_prompt: str\n",
      "    composed_context: str\n",
      "    composed_completion: str\n",
      "    completion_lines: CompletionLines\n",
      "    composed_completion: list[str]\n",
      "    completion_lines: list[CompletionLines]\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "    def calc_lens(self,\n",
      "                  prompt: torch.Tensor,\n",
      "        prompt_len, _, completion_len = super().calc_lens(prompt, context, completion)\n",
      "        return prompt_len, -len(context), completion_len\n",
      "from pipeline.data.preprocessors.preprocessors_registry import PREPROCESSORS_REGISTRY\n",
      "def init_preprocessor(cls_name: str, loaded_config: DictConfig, **kwargs) -> PreprocessorBase:\n",
      "    return preprocessor\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "PREPROCESSORS_REGISTRY = {\n",
      "    'completion_loss_preprocessor': CompletionLossPreprocessor,\n",
      "    'lm_preprocessor': LMPreprocessor,\n",
      "from pipeline.data.datapoint import CompletionLines\n",
      "import warnings\n",
      "from transformers import BatchEncoding, PreTrainedTokenizerBase\n",
      "class CompletionLossPreprocessor(PreprocessorBase):\n",
      "                 max_seq_len: int,\n",
      "                 num_chars_per_token: int,\n",
      "                 padding: bool,\n",
      "                 ) -> None:\n",
      "        if not 0 < loss_ratio <= 1:\n",
      "        self.tokenizer = tokenizer\n",
      "        self.max_seq_len = max_seq_len\n",
      "        if isinstance(context_tokens, float):\n",
      "        self.context_tokens = context_tokens\n",
      "        self.num_chars_per_token = math.ceil(1.5 * self.num_chars_per_token)\n",
      "            warnings.warn(\n",
      "                f'num_chars_per_token has been increased from {old_value} to {self.num_chars_per_token} '\n",
      "    def tokenize_pre_context_prompt(self, prompts: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "        tokenized_prompts = self.tokenizer(\n",
      "            text=[prompt[-char_trunc_upper_bound:] for prompt in prompts],\n",
      "            add_special_tokens=False,\n",
      "                self._inc_num_chars_per_token()\n",
      "        return tokenized_prompts\n",
      "        trunc_completions = [completion[:char_trunc_upper_bound] for completion in completions]\n",
      "        tokenized_completions = self.tokenizer(\n",
      "            text=trunc_completions,\n",
      "            add_special_tokens=False,\n",
      "            return_length=True,\n",
      "        )\n",
      "        tokenized_completions.length = torch.tensor(tokenized_completions.length)\n",
      "        overflow_chars = torch.tensor([len(completion) > char_trunc_upper_bound for completion in completions])\n",
      "        if torch.any(overflow_chars & underflow_tokens):\n",
      "            self._inc_num_chars_per_token()\n",
      "            return self.tokenize_composed_completion(completions)\n",
      "            [match.start() for match in re.finditer('\\n', completion)]\n",
      "        return tokenized_completions\n",
      "    def tokenize_composed_context(self, contexts: list[str]) -> BatchEncoding:\n",
      "            text=[ctx[-char_trunc_upper_bound:] for ctx in contexts],\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "            overflow_chars = len(ctx) > char_trunc_upper_bound\n",
      "            underflow_tokens = len(tokenized_ctx) < self.max_seq_len\n",
      "            if overflow_chars and underflow_tokens:\n",
      "                return self.tokenize_composed_context(contexts)\n",
      "                    raise ValueError('Not enough data to satisfy context_tokens.')\n",
      "        return tokenized_contexts\n",
      "                  context: torch.Tensor,\n",
      "                  completion: torch.Tensor,\n",
      "            completion_len = min(len(completion), self.max_seq_len - self.context_tokens - prompt_len)\n",
      "            context_len = self.max_seq_len - prompt_len - completion_len\n",
      "        else:\n",
      "            completion_len = self.max_seq_len - prompt_len - context_len\n",
      "        return prompt_len, context_len, completion_len\n",
      "    @staticmethod\n",
      "    def _get_partial_completion_mask(tokenized_completions: BatchEncoding,\n",
      "                                     target_attn_mask: torch.Tensor,\n",
      "                                     ) -> torch.Tensor:\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        completions_len = tokenized_completions.length.unsqueeze(-1)\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        return self._get_partial_completion_mask(*args, **kwargs, ratio=1)\n",
      "    def get_category_ids(tokenized_completions: BatchEncoding,\n",
      "                         ) -> torch.Tensor:\n",
      "        category_ids = torch.full_like(target_attn_mask, UNDEFINED_CATEGORY_ID)\n",
      "            offset_mapping = tokenized_completions.offset_mapping[sample_idx]\n",
      "            newline_positions.append(float('inf'))\n",
      "                line_idx: CATEGORY2ID[category]\n",
      "                for category, line_category_ids in completion_lines[sample_idx].items()\n",
      "            category_id = line2category.get(line_idx)\n",
      "            for token_idx, (char_start, _) in enumerate(offset_mapping, start=t_completion_start[sample_idx]):\n",
      "                if char_start > newline_positions[line_idx]:\n",
      "                    line_idx += 1\n",
      "                    category_id = line2category.get(line_idx)\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "        tokenized_prompts = self.tokenize_pre_context_prompt(batch['pre_context_prompt'])\n",
      "        tokenized_completions = self.tokenize_composed_completion(batch['composed_completion'])\n",
      "        tokenized_contexts = self.tokenize_composed_context(batch['composed_context'])\n",
      "            prompt = tokenized_prompts.input_ids[sample_idx]\n",
      "            context = tokenized_contexts.input_ids[sample_idx]\n",
      "            prompt_len, context_len, completion_len = self.calc_lens(prompt, context, completion)\n",
      "            context = context[-context_len:]\n",
      "            completion = completion[:completion_len]\n",
      "            tokenized_completions.offset_mapping[sample_idx] = \\\n",
      "                tokenized_completions.offset_mapping[sample_idx][:completion_len]\n",
      "            tokenized_completions.length[sample_idx] = len(completion)\n",
      "        self.tokenizer.padding_side = 'right'\n",
      "            encoded_inputs={'input_ids': tokenized_batch},\n",
      "            padding='longest',\n",
      "            return_attention_mask=True,\n",
      "            return_tensors='pt')\n",
      "        target_attn_mask = padded_batch.attention_mask[:, 1:]\n",
      "            input_ids=padded_batch.input_ids[:, :-1],\n",
      "            target_ids=padded_batch.input_ids[:, 1:],\n",
      "            completion_mask=self.get_completion_mask(tokenized_completions, target_attn_mask),\n",
      "            target_attn_mask=target_attn_mask.bool(),\n",
      "class LMPreprocessor(CompletionLossPreprocessor):\n",
      "    def get_loss_mask(self,\n",
      "                      target_attn_mask: torch.Tensor,\n",
      "                      ) -> torch.Tensor:\n",
      "        position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        loss_mask = (num_informative_tokens - num_loss_tokens <= position_ids)\n",
      "from pipeline.data.composed_datapoint import BatchComposedDatapoint\n",
      "class PreprocessedBatch(TypedDict):\n",
      "    target_ids: torch.Tensor\n",
      "    loss_mask: torch.Tensor\n",
      "    category_ids: torch.Tensor\n",
      "    target_attn_mask: torch.Tensor\n",
      "    @abstractmethod\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Important note: different number of masked tokens in different\n",
      "        micro-batches will break gradient accumulation, in which case\n",
      "        \"\"\"\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        raise NotImplementedError\n",
      "from pipeline.data.composers.blocks.blocks_registry import BLOCKS_REGISTRY\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.composers.composers_registry import COMPOSERS_REGISTRY\n",
      "import os\n",
      "from omegaconf import DictConfig\n",
      "                  configs_dir: str,\n",
      "                  tokenizer: PreTrainedTokenizerBase,\n",
      "        for path in loaded_config.block_configs:\n",
      "            full_path = os.path.join(configs_dir, 'composer/chained_composer/blocks', path)\n",
      "                block_config = yaml.safe_load(stream)\n",
      "            if block_config is None:\n",
      "            block_cls = BLOCKS_REGISTRY[block_name]\n",
      "            if block_cls.requires_tokenizer:\n",
      "                block_config['tokenizer'] = tokenizer\n",
      "from pipeline.data.composers.utils import ReprMixin\n",
      "from typing import Any, Sequence\n",
      "class File:\n",
      "@dataclass\n",
      "    content: str\n",
      "    metadata: dict[str, Any]\n",
      "class ComposerBlock(ABC, ReprMixin):\n",
      "    first_block_permit: bool = False\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[type, ...]:\n",
      "        raise NotImplementedError\n",
      "    def check_next_block(self, block) -> None:\n",
      "        if not isinstance(block, self.next_blocks):\n",
      "            raise ValueError(f'{type(block).__name__} cannot be used after {type(self).__name__}.')\n",
      "    @abstractmethod\n",
      "    def __call__(self, args: BlockArgs, datapoint: Datapoint) -> BlockArgs | str:\n",
      "        raise NotImplementedError\n",
      "class ComposerChain:\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None:\n",
      "        if not blocks:\n",
      "            raise ValueError('ComposerChain instance must contain at least one element.')\n",
      "        elif not blocks[0].first_block_permit:\n",
      "        for block, next_block in zip(blocks[:-1], blocks[1:]):\n",
      "            block.check_next_block(next_block)\n",
      "        self.blocks = blocks\n",
      "    def __call__(self, datapoint: Datapoint) -> str:\n",
      "            x = block(x, datapoint)\n",
      "from pipeline.data.datapoint import Datapoint, BatchDatapoint\n",
      "from abc import ABC, abstractmethod\n",
      "class ComposerBase(ABC):\n",
      "                 path_comment_template: str,\n",
      "                 recalculate_random_category: bool,\n",
      "                 ) -> None:\n",
      "        self.pre_context_prompt = pre_context_prompt\n",
      "        self.post_context_prompt = post_context_prompt\n",
      "        return self.pre_context_prompt.format(datapoint.repo)\n",
      "    def get_post_context_prompt(self, _datapoint: Datapoint) -> str:\n",
      "        return self.post_context_prompt\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        raise NotImplementedError\n",
      "    def compose_completion(self, datapoint: Datapoint) -> str:\n",
      "            if '{content}' in line:\n",
      "        for line_category_ids in datapoint.completion_lines.values():\n",
      "        completion = template_with_inserted_path.format(**datapoint.completion_file)\n",
      "            completion += '\\n'  # instead of EOS token\n",
      "                if category != 'random':\n",
      "            datapoint.completion_lines['random'] = list(non_categorized_lines)\n",
      "        return ComposedDatapoint(\n",
      "            completion_lines=datapoint.completion_lines,\n",
      "        )\n",
      "        batch_keys = batch.keys()\n",
      "        composed_batch_keys = BatchComposedDatapoint.__required_keys__\n",
      "        # transpose and compose\n",
      "        batch = [self.compose(dict(zip(batch_keys, data))) for data in zip(*batch.values())]\n",
      "        # transpose back\n",
      "                        writer_batch_size: int = 128,\n",
      "                        num_proc: int = 4,\n",
      "                        ) -> Dataset:\n",
      "        return dataset.map(\n",
      "            remove_columns=map_kwargs.pop('remove_columns', dataset.column_names),\n",
      "            # created cache files consume a lot of disk space\n",
      "            writer_batch_size=writer_batch_size,\n",
      "            num_proc=num_proc,\n",
      "from pipeline.data.composers.chain import ComposerBlock, ComposerChain\n",
      "from pipeline.data.composers.composer_base import ComposerBase\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "class ChainedComposer(ComposerBase, ComposerChain, ReprMixin):\n",
      "    def __init__(self, blocks: Sequence[ComposerBlock], *args, **kwargs) -> None:\n",
      "        ComposerChain.__init__(self, *blocks)\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        return self.__call__(datapoint)\n",
      "COMPOSERS_REGISTRY = {\n",
      "    'chained_composer': ChainedComposer,\n",
      "    _init_kwargs = None\n",
      "        super().__init_subclass__(**kwargs)\n",
      "        original_init = cls.__init__\n",
      "            if cls == type(self):\n",
      "                self._init_args = init_args\n",
      "                self._init_kwargs = init_kwargs\n",
      "            original_init(self, *init_args, **init_kwargs)\n",
      "    def __repr__(self) -> str:\n",
      "        args_str = ', '.join(\n",
      "                f\"'{arg}'\" if isinstance(arg, str) else repr(arg)\n",
      "                for arg in self._init_args\n",
      "                for key, value in self._init_kwargs.items()\n",
      "        return f'{type(self).__name__}({args_str})'\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "import random\n",
      "class ContextPostprocessor(ComposerBlock, ABC):\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "    def __init__(self, dropout: float, random_seed: int | None) -> None:\n",
      "            raise ValueError('dropout must be selected from the interval [0, 1]. '\n",
      "                             f'Got {dropout} instead.')\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.generator.random() >= self.dropout)\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.min_len <= len(line) <= self.max_len)\n",
      "        return '\\n'.join(line.strip() for line in context.split('\\n'))\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        # 1. L1 or softmax normalization?\n",
      "        return context\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "        from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "        return ChunkSorter, ChunkHarvester\n",
      "from pipeline.data.composers.chain import Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from abc import ABC\n",
      "        return ContextPostprocessor,\n",
      "    def __init__(self, chunks_sep: str) -> None:\n",
      "        self.chunks_sep = chunks_sep\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> str:\n",
      "class PathCommentHarvester(JoiningHarvester):\n",
      "        super().__init__(chunks_sep)\n",
      "        self.path_comment_template = path_comment_template\n",
      "        return super().__call__(chunks, datapoint)\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "import tree_sitter\n",
      "class FilePreprocessor(ComposerBlock, ABC):\n",
      "    @property\n",
      "        from pipeline.data.composers.blocks.file_chunking import FileChunker\n",
      "        from pipeline.data.composers.blocks.file_filtering import FileFilter\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return files\n",
      "class DeclarationOnlyPreprocessor(FilePreprocessor):\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[File]:\n",
      "                continue\n",
      "                queue.extend(reversed(node.children))\n",
      "                start = bytecode[:node.start_byte].rfind(b'\\n') + 1\n",
      "                for child in node.children:\n",
      "                        end = child.end_byte\n",
      "                        break\n",
      "                else:\n",
      "                    warnings.warn(f'A corrupted {file.metadata[\"filename\"]} file structure '\n",
      "                                  f'has been detected in the {datapoint.repo} repository.')\n",
      "                    end = node.end_byte\n",
      "                declaration = declaration.decode('utf8') + ' ...'\n",
      "                declarations.append(declaration)\n",
      "            file.content = '\\n'.join(declarations)\n",
      "        return files\n",
      "import random\n",
      "import warnings\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "class ChunkRanker(ComposerBlock, ABC):\n",
      "    @property\n",
      "        path_to = os.path.normpath(path_to)\n",
      "        if path_from == path_to:\n",
      "            warnings.warn(f'Data leakage: the {path_from} completion file is contained in the repo snapshot.')\n",
      "        divided_path_from = path_from.split(os.path.sep)\n",
      "        divided_path_to = path_to.split(os.path.sep)\n",
      "        common_len = 0\n",
      "                common_len += 1\n",
      "                break\n",
      "        num_residuals_from = len(divided_path_from) - common_len - 1\n",
      "        return num_residuals_from + num_residuals_to\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        return chunks\n",
      "class FileExtensionRanker(ChunkRanker):\n",
      "        self.group_weights = {\n",
      "            for weight, group in enumerate(ordered_groups)\n",
      "            for extension in group\n",
      "        }\n",
      "            chunk.rank.append(self.group_weights.get(extension, -1))\n",
      "class FunctionCallRanker(ChunkRanker):\n",
      "    ENCODING = 'utf8'\n",
      "    def __init__(self, is_relative: bool) -> None:\n",
      "        self.is_relative = is_relative\n",
      "        return (node.type == 'call') + sum(self.dfs_count(child) for child in node.children)\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        for chunk in chunks:\n",
      "                bytecode = bytes(chunk.content, self.ENCODING)\n",
      "                tree = self.parser.parse(bytecode)\n",
      "            else:\n",
      "            if self.is_relative:\n",
      "                num_calls /= len(chunk.content)\n",
      "class RandomRanker(ChunkRanker):\n",
      "    def __init__(self, random_seed: int | None) -> None:\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        ranks = list(range(len(chunks)))\n",
      "            chunk.rank.append(rank)\n",
      "from pipeline.data.composers.blocks.chunk_harvesting import (\n",
      "    JoiningHarvester,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_ranking import (\n",
      "    FunctionCallRanker,\n",
      "    RandomRanker,\n",
      ")\n",
      "from pipeline.data.composers.blocks.chunk_sorting import (\n",
      "    LexicographicSorter,\n",
      "from pipeline.data.composers.blocks.context_postprocessing import (\n",
      "    LineLengthPostprocessor,\n",
      "    LineStripPostprocessor,\n",
      "    InverseFrequencyMemoryPostprocessor,\n",
      "    FileGrainedChunker,\n",
      "    CodeSegmentGrainedChunker,\n",
      "    InclusiveFileExtensionFilter,\n",
      "    EmptyFileFilter,\n",
      "    FileLengthFilter,\n",
      "from pipeline.data.composers.blocks.file_preprocessing import (\n",
      "    EmptyLinesRemovalPreprocessor,\n",
      ")\n",
      "    # file_filtering\n",
      "    'inclusive_file_extension_filter': InclusiveFileExtensionFilter,\n",
      "    'exclusive_file_extension_filter': ExclusiveFileExtensionFilter,\n",
      "    'file_length_filter': FileLengthFilter,\n",
      "    'tokenized_file_length_filter': TokenizedFileLengthFilter,\n",
      "    'char_token_ratio_filter': CharTokenRatioFilter,\n",
      "    'declaration_only_preprocessor': DeclarationOnlyPreprocessor,\n",
      "    # file_chunking\n",
      "    'file_grained_chunker': FileGrainedChunker,\n",
      "    'code_segment_grained_chunker': CodeSegmentGrainedChunker,\n",
      "    'negative_path_distance_ranker': NegativePathDistanceRanker,\n",
      "    'file_extension_ranker': FileExtensionRanker,\n",
      "    # chunk_sorting\n",
      "    'joining_harvester': JoiningHarvester,\n",
      "    # context_postprocessing\n",
      "    'partial_memory_postprocessor': PartialMemoryPostprocessor,\n",
      "    'line_length_postprocessor': LineLengthPostprocessor,\n",
      "    'line_strip_postprocessor': LineStripPostprocessor,\n",
      "    'inverse_frequency_memory_postprocessor': InverseFrequencyMemoryPostprocessor,\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "import random\n",
      "from abc import ABC\n",
      "class FileFilter(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "class InclusiveFileExtensionFilter(FileFilter):\n",
      "        self.whitelist = tuple(whitelist)\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "class ExclusiveFileExtensionFilter(FileFilter):\n",
      "        return [file for file in files if not file.metadata['filename'].endswith(self.blacklist)]\n",
      "class EmptyFileFilter(FileFilter):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "                tokenized_file = self.tokenizer(file.content, return_attention_mask=False).input_ids\n",
      "                file.metadata['num_tokens'] = len(tokenized_file)\n",
      "        return filtered_files\n",
      "                 min_ratio: float,\n",
      "                 max_ratio: float,\n",
      "                 subsequence_len: int,\n",
      "                 ) -> None:\n",
      "        self.tokenizer = tokenizer\n",
      "        self.max_ratio = max_ratio\n",
      "        self.subsequence_len = subsequence_len\n",
      "        self.generator = random.Random(random_seed)\n",
      "        filtered_files = list()\n",
      "            if len(file.content) <= self.subsequence_len:\n",
      "            else:\n",
      "                # N.B. this algorithm does NOT preserve the uniformity of token sampling\n",
      "                start_idx = self.generator.randrange(len(file.content) - self.subsequence_len + 1)\n",
      "                subsequence = file.content[start_idx:start_idx + self.subsequence_len]\n",
      "            tokenized_subsequence = self.tokenizer(subsequence, return_attention_mask=False).input_ids\n",
      "            ratio = len(subsequence) / len(tokenized_subsequence)\n",
      "            if self.min_ratio <= ratio <= self.max_ratio:\n",
      "                filtered_files.append(file)\n",
      "        return filtered_files\n",
      "from pipeline.data.composers.chain import File, Chunk, ComposerBlock\n",
      "from pipeline.data.datapoint import Datapoint\n",
      "from string import whitespace\n",
      "from typing import Callable, NamedTuple, Sequence, TypeVar, Type\n",
      "T = TypeVar('T')\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from pipeline.data.composers.blocks.chunk_harvesting import ChunkHarvester\n",
      "        from pipeline.data.composers.blocks.chunk_ranking import ChunkRanker\n",
      "        return ChunkRanker, ChunkHarvester\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "                # TODO: remove temporary hardcoded solution for data leakage\n",
      "                if file.metadata['filename'] != 'tinygrad/llops/ops_llvm.py']\n",
      "    DOCSTRING = 'docstring_segment'\n",
      "    CODE = 'code_segment'\n",
      "    UNDEFINED = 'undefined_segment'\n",
      "    @classmethod\n",
      "    def from_node(cls: Type[T], node: tree_sitter.Node) -> T:\n",
      "        if 'comment' in node.type.lower():\n",
      "            return cls.COMMENT\n",
      "            return cls.DOCSTRING\n",
      "            return cls.IMPORT\n",
      "            return cls.CODE\n",
      "        else:\n",
      "            return cls.UNDEFINED\n",
      "class Segment(NamedTuple):\n",
      "    start_byte: int\n",
      "    DOCSTRING_PREFIX = (bytes(\"'''\", ENCODING), bytes('\"\"\"', ENCODING))\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "    def dfs_segmentation(root_node: tree_sitter.Node) -> list[Segment]:\n",
      "        segments = list()\n",
      "            segment_type = CodeSegment.from_node(node)\n",
      "            else:\n",
      "    @staticmethod\n",
      "    def strip_lines(string: str, strip_func: Callable[[str], str]) -> str:\n",
      "        return '\\n'.join(map(strip_func, string.split('\\n')))\n",
      "        chunks = list()\n",
      "                    file_ref=file,\n",
      "            if file.metadata['filename'] == 'tinygrad/llops/ops_llvm.py':\n",
      "                continue\n",
      "            tree = self.parser.parse(bytecode)\n",
      "            segments = self.dfs_segmentation(tree.root_node)\n",
      "            dummy_segment = Segment(len(bytecode), CodeSegment.UNDEFINED)\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.DOCSTRING}, file_ref=file)\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.IMPORT}, file_ref=file)\n",
      "            code_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.CODE}, file_ref=file)\n",
      "            for i in range(len(segments) - 1):\n",
      "                segment_str = bytecode[start:end].decode(self.ENCODING)\n",
      "                match segment_type:\n",
      "                        if prev_edited_chunk is not None and not prev_edited_chunk.content.rstrip(\n",
      "                        if segment_str.count('\\n') >= 2:\n",
      "                            prev_edited_chunk = comments_chunk\n",
      "                        imports_chunk.content += segment_str\n",
      "                        code_chunk.content += segment_str\n",
      "                if chunk.content.strip():\n",
      "                    chunk.content = self.strip_lines(chunk.content.rstrip(), str.rstrip)\n",
      "                    chunks.append(chunk)\n",
      "from pipeline.outputs.metrics.metric_base import MetricValue, OptimizationMode, MetricBase\n",
      "import torch\n",
      "    mode = OptimizationMode.MIN\n",
      "    def __init__(self) -> None:\n",
      "        self.num_tokens = 0\n",
      "    @torch.inference_mode\n",
      "    def micro_batch_update(self, loss_per_token: torch.Tensor, mask: torch.Tensor, **_kwargs) -> None:\n",
      "        num_tokens_update = mask.sum().item()\n",
      "            self.num_tokens = 0\n",
      "            tokens_ratio = num_tokens_update / self.num_tokens\n",
      "        self.num_tokens += num_tokens_update\n",
      "        self.mean_loss = 0\n",
      "        self.num_tokens = 0\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticBase\n",
      "from typing import TypeVar, Type\n",
      "T = TypeVar('T')\n",
      "FullFineTuningTrainer = TypeVar('FullFineTuningTrainer')\n",
      "class EpochCounter(StatisticBase):\n",
      "    _instance = None  # singleton pattern\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "        if cls._instance is None:\n",
      "            self.init_epoch = init_epoch\n",
      "            self.samples += input_ids.shape[0]\n",
      "    def batch_commit(self) -> StatisticValue:\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Type\n",
      "import torch\n",
      "StatisticValue = int | float\n",
      "class StatisticBase(ABC):\n",
      "    @torch.inference_mode\n",
      "    def micro_batch_update(self, **kwargs) -> None:\n",
      "        raise NotImplementedError\n",
      "    @abstractmethod\n",
      "    def batch_commit(self) -> StatisticValue:\n",
      "        raise NotImplementedError\n",
      "    class EMAStatistic(statistic_cls, ABC):\n",
      "            super().__init__()\n",
      "        def reinit(self, ema_state: float | None) -> None:\n",
      "        def batch_commit(self) -> StatisticValue:\n",
      "            batch_metric = super().batch_commit()\n",
      "            if self.ema_state is None:\n",
      "                self.ema_state = batch_metric\n",
      "            else:\n",
      "                self.ema_state += self.ema_alpha * (batch_metric - self.ema_state)\n",
      "            return self.ema_state\n",
      "    return EMAStatistic\n",
      "    class LazyStatistic(StatisticBase):\n",
      "        def __init__(self) -> None:\n",
      "            self.value = kwargs.get(statistic_name)\n",
      "            return batch_statistic\n",
      "    return LazyStatistic\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Type\n",
      "    MAX = 'maximization'\n",
      "class MetricBase(StatisticBase, ABC):\n",
      "    @property\n",
      "def loss_based_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "    class LossBasedMetric(metric_cls, ABC):\n",
      "            kwargs['mask'] = kwargs['loss_mask']\n",
      "    class DetachedMetric(metric_cls, ABC):\n",
      "    return DetachedMetric\n",
      "    class FullMetric(metric_cls, ABC):\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "def full_metric_factory(metric_cls: Type[MetricBase]) -> Type[MetricBase]:\n",
      "            kwargs['mask'] = kwargs['target_attn_mask']\n",
      "            return super().micro_batch_update(**kwargs)\n",
      "    return FullMetric\n",
      "def categorized_metric_factory(metric_cls: Type[MetricBase], category: CategoryType) -> Type[MetricBase]:\n",
      "        def micro_batch_update(self, **kwargs) -> None:\n",
      "    return CategorizedMetric\n",
      "from pipeline.outputs.metrics.cross_entropy import CrossEntropy\n",
      "from pipeline.outputs.metrics.metric_base import (\n",
      "    loss_based_metric_factory,\n",
      "    detached_metric_factory,\n",
      ")\n",
      "from pipeline.outputs.metrics.statistic_base import ema_factory, lazy_statistic_factory\n",
      "from pipeline.outputs.metrics.counters import EpochCounter\n",
      "METRICS_REGISTRY = {\n",
      "    'detached_cross_entropy': detached_metric_factory(CrossEntropy),\n",
      "    'context_cross_entropy': context_metric_factory(CrossEntropy),\n",
      "    'full_cross_entropy': full_metric_factory(CrossEntropy),\n",
      "    'random_cross_entropy': categorized_metric_factory(CrossEntropy, 'random'),\n",
      "    # in training only\n",
      "    'epoch': EpochCounter,\n",
      "}\n",
      "METRICS_REGISTRY.update({  # useless due to W&B native support :(\n",
      "    f'ema_{name}': ema_factory(cls) for name, cls in METRICS_REGISTRY.items()\n",
      "import os\n",
      "import shutil\n",
      "class TopKCheckpointManager(CheckpointManager):\n",
      "        super().__init__(*args, **kwargs)\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "        super().save_checkpoint(checkpoint)\n",
      "        checkpoints = sorted(checkpoints, key=self.get_checkpoint_score)\n",
      "        while len(checkpoints) > self.max_checkpoints_num:\n",
      "            checkpoint2del = checkpoints.pop()\n",
      "            checkpoint2del = os.path.join(self.directory, checkpoint2del)\n",
      "            shutil.rmtree(checkpoint2del)\n",
      "from pipeline.outputs.checkpointers.data_structures import LoadingMode, Checkpoint\n",
      "from typing import Callable, Literal\n",
      "                 init_from: LoadingMode | str,\n",
      "                 directory: str,\n",
      "                 checkpoint_directory_template: str,\n",
      "                 extract_iteration_number: Callable[[str], int],\n",
      "                 model_subdirectory: str,\n",
      "                 metrics_filename: str,\n",
      "                 ) -> None:\n",
      "        if main_metric not in METRICS_REGISTRY:\n",
      "        self.init_from = init_from\n",
      "        self.main_metric_name = main_metric\n",
      "        self._optim_state_filename = optim_state_filename\n",
      "    def get_wandb_resume_mode(self) -> Literal['allow', 'never'] | None:\n",
      "        match self.init_from:\n",
      "            case _:\n",
      "    def get_checkpoint_score(self, checkpoint_dir: str) -> MetricValue:\n",
      "        checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "        metrics = self.load_metrics(checkpoint_dir)\n",
      "            raise RuntimeError(f'The {checkpoint_dir} does not contain information '\n",
      "        elif self.main_metric.mode == OptimizationMode.MIN:\n",
      "            return metric_value\n",
      "        else:\n",
      "            return -metric_value\n",
      "        match self.init_from:\n",
      "            case LoadingMode.RESUME:\n",
      "                return max(\n",
      "                    key=self._extract_iteration_number,\n",
      "                    default=None,\n",
      "                return min(\n",
      "                    next(os.walk(self.directory))[1],\n",
      "                    key=self.get_checkpoint_score,\n",
      "                    default=None,\n",
      "                )\n",
      "            case _:  # user-defined checkpoint directory\n",
      "                return self.init_from\n",
      "    def get_iteration_number(self) -> int:\n",
      "    def get_model_subdirectory(self) -> str | None:\n",
      "            return None\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        if checkpoint_dir is not None:\n",
      "            optim_file = os.path.join(self.directory, checkpoint_dir, self._optim_state_filename)\n",
      "                     group: Literal['train_metrics', 'valid_metrics'],\n",
      "        checkpoint_dir = self.get_checkpoint_directory()\n",
      "        metrics_dict = dict()\n",
      "        if checkpoint_dir is None:\n",
      "            metrics_states = self.load_metrics(checkpoint_dir)[group]\n",
      "            metrics_dict[name].reinit(metrics_states.get(name))\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "            self.directory,\n",
      "                iteration_number=checkpoint.metrics['iteration_number']),\n",
      "        if os.path.exists(checkpoint_dir):\n",
      "            warnings.warn(f'The contents of the checkpoint {checkpoint_dir} have been overwritten.')\n",
      "        )\n",
      "        checkpoint.model.save_pretrained(model_save_dir)\n",
      "        torch.save(checkpoint.optimizer_state, optim_file)\n",
      "        with open(metrics_file, 'w') as stream:\n",
      "from dataclasses import dataclass\n",
      "from enum import Enum\n",
      "from transformers import PreTrainedModel\n",
      "    SCRATCH = 'scratch'\n",
      "    RESUME = 'resume'\n",
      "@dataclass\n",
      "    metrics: Log\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "    checkpointer = CHECKPOINTERS_REGISTRY[cls_name](**config.dict)\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "    'checkpointer': CheckpointManager,\n",
      "    'top_k_checkpointer': TopKCheckpointManager,\n",
      "}\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "        pass\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "    def message(self, message: Message) -> Message:\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import sys\n",
      "import transformers.utils.logging\n",
      "        message_dict = {\n",
      "            'timestamp': self.formatTime(record, self.datefmt),\n",
      "            'content': record.msg,\n",
      "        json_string = indent.join(json_string.splitlines(keepends=True))\n",
      "class JsonHandler(logging.FileHandler):\n",
      "        if not os.path.exists(self.baseFilename) or os.stat(self.baseFilename).st_size == 0:\n",
      "        else:\n",
      "            self.stream.seek(self.stream.tell() - 1)\n",
      "            self.stream.truncate()\n",
      "            self.stream.write(',\\n')\n",
      "        self.stream.seek(self.stream.tell() - 1)\n",
      "        self.stream.write(']')\n",
      "    def __init__(self,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "            raise ValueError('The names of the train_csv and valid_csv files must be different.')\n",
      "        train_csv, valid_csv, stdout_file, stderr_file = map(\n",
      "            [train_csv, valid_csv, stdout_file, stderr_file],\n",
      "        if os.path.exists(train_csv):\n",
      "            with open(train_csv) as stream:\n",
      "                self.last_logged_iter = max(map(lambda x: int(x.split(',')[0]), stream.readlines()[1:]))\n",
      "            self.last_logged_iter = -1\n",
      "        formatter = JsonFormatter()\n",
      "        stdout_handler = JsonHandler(stdout_file)\n",
      "        stdout_handler.setLevel(logging.INFO)\n",
      "        stdout_handler.setFormatter(formatter)\n",
      "        if stderr_file == stdout_file:\n",
      "            stderr_handler = JsonHandler(stderr_file)\n",
      "            stderr_handler.setLevel(logging.WARNING)\n",
      "        self.logger.addHandler(stdout_handler)\n",
      "        self.logger.addHandler(stderr_handler)\n",
      "        warnings.showwarning = self.warning_handler\n",
      "        # redirect all HF logs (at least datasets and transformers)\n",
      "        datasets_logger.handlers = self.logger.handlers\n",
      "        transformers_logger.handlers = self.logger.handlers\n",
      "    @staticmethod\n",
      "    def write_metrics_to_csv(metrics: dict[MetricName, MetricValue], path: str) -> None:\n",
      "            writer = csv.DictWriter(stream, fieldnames=metrics.keys())\n",
      "            if stream.tell() == 0:\n",
      "                writer.writeheader()\n",
      "        if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "        iter_num = {'iter_num': metrics['iteration_number']}\n",
      "            self.write_metrics_to_csv(iter_num | metrics['train_metrics'], self.train_csv)\n",
      "        return metrics\n",
      "        self.logger.info(message)\n",
      "    def warning_handler(self, message: Warning, category: type, path: str, lineno: int, *_kwargs) -> None:\n",
      "        self.logger.warning({\n",
      "            'location': f'{path}:{lineno}',\n",
      "        })\n",
      "    def exception_handler(self, exc_type: type, exc_value: Exception, exc_traceback: TracebackType) -> NoReturn:\n",
      "        if issubclass(exc_type, KeyboardInterrupt):\n",
      "        else:\n",
      "            self.logger.error({\n",
      "                    'location': f'{filename}:{lineno} in {func_name}',\n",
      "                'message': str(exc_value),\n",
      "            })\n",
      "            self.message('Process finished with a non-zero exit code.')\n",
      "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict, TypeVar, Type\n",
      "from typing_extensions import NotRequired\n",
      "JsonAllowedTypes = dict | list | tuple | str | int | float | bool | None\n",
      "    iteration_number: int\n",
      "class LoggerBase(ABC):\n",
      "            cls._instance = super().__new__(cls)\n",
      "    @abstractmethod\n",
      "    @abstractmethod\n",
      "        raise NotImplementedError\n",
      "from pipeline.outputs.loggers.loggers_registry import LOGGERS_REGISTRY\n",
      "from omegaconf import DictConfig\n",
      "    return logger\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "import wandb\n",
      "class WandbLogger(LocalLogger):\n",
      "    def __init__(self,\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 stderr_file: str,\n",
      "                 **wandb_init_kwargs,\n",
      "        super().__init__(train_csv, valid_csv, stdout_file, stderr_file, directory)\n",
      "        wandb_init_kwargs['resume'] = wandb_init_kwargs.get('resume', checkpointer.get_wandb_resume_mode())\n",
      "        wandb_init_kwargs['id'] = wandb_init_kwargs.get('id', wandb_init_kwargs['name'])\n",
      "        if metrics['iteration_number'] <= self.last_logged_iter:\n",
      "            return super().log(metrics)  # repeated iterations between checkpoints\n",
      "        wandb_log = dict()\n",
      "        if 'train_metrics' in metrics:\n",
      "            wandb_log['train'] = metrics['train_metrics']\n",
      "            wandb_log['validation'] = metrics['valid_metrics']\n",
      "        wandb.log(wandb_log, step=metrics['iteration_number'])\n",
      "from pipeline.outputs.loggers.dummy_logger import DummyLogger\n",
      "from pipeline.outputs.loggers.wandb_logger import WandbLogger\n",
      "LOGGERS_REGISTRY = {\n",
      "    'dummy': DummyLogger,\n",
      "    'wandb': WandbLogger,\n",
      "from pipeline.configs.checkpointer_config import (\n",
      "from pipeline.configs.logger_config import (\n",
      "    WandbLoggerConfig,\n",
      ")\n",
      "from pipeline.configs.preprocessor_config import PreprocessorConfig\n",
      "CONFIGS_REGISTRY = {\n",
      "    # checkpointers\n",
      "    # loggers\n",
      "    'dummy': ConfigBase,\n",
      "    'wandb': WandbLoggerConfig,\n",
      "    'chained_composer': ChainedComposerConfig,\n",
      "    # preprocessors\n",
      "    'completion_loss_preprocessor': PreprocessorConfig,\n",
      "    'file_level_preprocessor': PreprocessorConfig,\n",
      "    'lm_preprocessor': PreprocessorConfig,\n",
      "    # trainers\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from dataclasses import dataclass\n",
      "from typing import Literal\n",
      "import torch\n",
      "class ModelConfig(ConfigBase):\n",
      "    model_name: str\n",
      "    load_from: str | None\n",
      "    device: torch.device | None = None\n",
      "    dtype: torch.dtype | None = None\n",
      "            self.dtype = getattr(torch, self.dtype)\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from dataclasses import dataclass\n",
      "from typing import Any\n",
      "@dataclass\n",
      "    valid_csv: str\n",
      "    name: str\n",
      "    group: str | None = None\n",
      "from pipeline.data.composers.chain import ComposerBlock\n",
      "from typing import Sequence\n",
      "class ChainedComposerConfig(ConfigBase):\n",
      "    recalculate_random_category: bool\n",
      "    blocks: Sequence[ComposerBlock] = field(default_factory=list)\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "@dataclass\n",
      "class CheckpointManagerConfig(ConfigBase):\n",
      "    main_metric: MetricName\n",
      "    directory: str\n",
      "    checkpoint_directory_template: str = '{iteration_number:04d}'\n",
      "    extract_iteration_number: Callable[[str], int] = staticmethod(int)\n",
      "    model_subdirectory: str = 'model'\n",
      "    def __post_init__(self) -> None:\n",
      "            self.init_from = LoadingMode(self.init_from)\n",
      "class TopKCheckpointManagerConfig(CheckpointManagerConfig):\n",
      "    max_checkpoints_num: int\n",
      "from dataclasses import dataclass\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "class PreprocessorConfig(ConfigBase):\n",
      "    max_seq_len: int\n",
      "    loss_ratio: float\n",
      "    num_chars_per_token: int\n",
      "    verbose: bool = True\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "    name: str | None = None\n",
      "    data_dir: str | None = None\n",
      "    cache_dir: str = str(config.HF_DATASETS_CACHE)\n",
      "from pprint import pformat\n",
      "from typing import Any, TypeVar, Type\n",
      "@dataclass\n",
      "class ConfigBase:\n",
      "    def __str__(self) -> str:\n",
      "    @classmethod\n",
      "        config_fields = set(field.name for field in fields(cls))\n",
      "        kwargs = {key: value for key, value in dictionary.items() if key in config_fields}\n",
      "        return cls(**kwargs)  # noqa: PyCharm bug?\n",
      "    @classmethod\n",
      "    def from_yaml(cls: Type[T], path: str | None = None) -> T:\n",
      "        if path is None:\n",
      "            return cls(**yaml.safe_load(stream))  # noqa: PyCharm bug?\n",
      "    dict = property(vars)\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.logger_base import LoggerBase\n",
      "from pipeline.outputs.metrics.metric_base import MetricName\n",
      "from typing import Literal\n",
      "from datasets import Dataset\n",
      "from transformers import PreTrainedModel, PreTrainedTokenizerBase\n",
      "class FullFineTuningTrainerConfig(ConfigBase):\n",
      "    tokenizer: PreTrainedTokenizerBase\n",
      "    logger: LoggerBase\n",
      "    max_iters: int\n",
      "    valid_freq: int | None  # None means no validation at all\n",
      "    checkpointing_freq: int | None  # None means no checkpointing at all\n",
      "    gradient_accumulation_steps: int\n",
      "    beta_2: float\n",
      "    weight_decay: float\n",
      "    warmup_iters: int | None\n",
      "    # Metrics (see METRICS_REGISTRY in pipeline/outputs/metrics/metrics_registry.py)\n",
      "    train_metrics: list[MetricName]\n",
      "    train_ema_alpha: float  # (see ema_factory in pipeline/outputs/metrics/statistic_base.py)\n",
      "    valid_metrics: list[MetricName]  # empty list means no validation at all\n",
      "    valid_ema_alpha: float | None  # if None, will be calculated as 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "    drop_last: bool\n",
      "    prefetch_factor: int | None\n",
      "from pipeline.configs.config_base import ConfigBase\n",
      "class SplitConfig(ConfigBase):\n",
      "    test_size: int  # 0 means no validation at all\n",
      "from pipeline.configs.model_config import ModelConfig\n",
      "from enum import Enum\n",
      "import torch\n",
      "from omegaconf import DictConfig\n",
      "from transformers.models.auto import MODEL_FOR_CAUSAL_LM_MAPPING\n",
      "    AutoTokenizer,\n",
      "class AttentionImplementation(str, Enum):\n",
      "    # nondeterministic\n",
      "    FA2 = 'flash_attention_2'\n",
      "    # deterministic\n",
      "    EAGER = 'eager'\n",
      "    return AutoTokenizer.from_pretrained(\n",
      "        pretrained_model_name_or_path=config.tokenizer_name,\n",
      "        trust_remote_code=config.trust_remote_code,\n",
      "    hf_model_config = AutoConfig.from_pretrained(model_name)\n",
      "    fa2_supported = (\n",
      "            model_cls._supports_flash_attn_2 and  # noqa: HF doesn't have an API for this case\n",
      "            device.type == 'cuda' and\n",
      "    )\n",
      "    if fa2_supported:\n",
      "        return AttentionImplementation.SDPA\n",
      "        return AttentionImplementation.EAGER\n",
      "def init_model(config: ModelConfig) -> PreTrainedModel:\n",
      "        config.device = get_free_device()\n",
      "    if config.dtype is None:\n",
      "        config.dtype = get_optimal_dtype()\n",
      "    if config.attn_implementation is None:\n",
      "        config.attn_implementation = get_optimal_attn(config.model_name, config.device, config.dtype)\n",
      "        config.load_from = config.model_name\n",
      "        pretrained_model_name_or_path=config.load_from,\n",
      "        trust_remote_code=config.trust_remote_code,\n",
      "        attn_implementation=config.attn_implementation,\n",
      "        use_cache=config.use_cache,\n",
      "    )\n",
      "    if config.compile:\n",
      "    return model\n",
      "    config = ModelConfig.from_dict(dict(loaded_config) | kwargs)\n",
      "from pipeline.configs.configs_registry import CONFIGS_REGISTRY\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from omegaconf import DictConfig\n",
      "def init_trainer(cls_name: str, loaded_config: DictConfig, **kwargs) -> TrainerBase:\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.utils.fused_sampler import FusedSampler\n",
      "from pipeline.trainers.utils.schedulers import get_lr_from_cosine_scheduler_with_linear_warmup\n",
      "import warnings\n",
      "from typing import Literal\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from datasets import Dataset\n",
      "from tqdm.auto import trange, tqdm\n",
      "                 valid_ds: Dataset | None,\n",
      "                 # auxiliary objects\n",
      "                 logger: LoggerBase,\n",
      "                 max_iters: int,\n",
      "                 valid_freq: int | None,\n",
      "                 learning_rate: float,\n",
      "                 beta_1: float,\n",
      "                 beta_2: float,\n",
      "                 # scheduler\n",
      "                 lr_decay_iters: int | None,\n",
      "                 train_ema_alpha: float,\n",
      "                 valid_metrics: list[MetricName],\n",
      "                 # DataLoader\n",
      "                 drop_last: bool,\n",
      "                 num_workers: int,\n",
      "                 # Floating point\n",
      "                 fp32_matmul_precision: Literal['highest', 'high', 'medium'],\n",
      "        self.model = model\n",
      "        self.checkpointer = checkpointer\n",
      "        # iterations\n",
      "        self.checkpointing_freq = checkpointing_freq\n",
      "        if checkpointing_freq is None:\n",
      "        elif valid_freq is not None and valid_freq != checkpointing_freq:\n",
      "        self.start_iter = checkpointer.get_iteration_number()\n",
      "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
      "        self.batch_size = gradient_accumulation_steps * micro_batch_size\n",
      "        self.is_on_cuda = (model.device.type == 'cuda')\n",
      "        logger.message(f\"Set the FP32 matrix multiplication precision to '{fp32_matmul_precision}'.\")\n",
      "        # validation\n",
      "            self.valid_freq = float('inf')\n",
      "            self.valid_dl = None\n",
      "            self.logger.message('Validation is disabled.')\n",
      "                dataset=valid_ds,\n",
      "                batch_size=micro_batch_size,\n",
      "                num_workers=num_workers,\n",
      "                prefetch_factor=prefetch_factor,\n",
      "                persistent_workers=(valid_freq > max_iters),\n",
      "                pin_memory_device=str(model.device),\n",
      "            )\n",
      "                valid_ema_alpha = 1 - (1 - train_ema_alpha) ** valid_freq\n",
      "        else:\n",
      "            raise ValueError('The valid_ds, valid_freq and valid_metrics arguments do not match each other.')\n",
      "        sampler = FusedSampler(\n",
      "            start_sample_idx=(self.batch_size * self.start_iter),\n",
      "            end_sample_idx=(self.batch_size * max_iters),\n",
      "            dataset_length=len(train_ds),\n",
      "            dataset=train_ds,\n",
      "            batch_size=micro_batch_size,\n",
      "            sampler=sampler,\n",
      "            pin_memory_device=str(model.device),\n",
      "        )\n",
      "        # optimizer initialization\n",
      "        self.optimizer = self._init_adamw(learning_rate, beta_1, beta_2, weight_decay)\n",
      "        # scheduler initialization\n",
      "        if warmup_iters is None and lr_decay_iters is None and min_lr is None:\n",
      "        elif warmup_iters is not None and lr_decay_iters is not None and min_lr is not None:\n",
      "                get_lr_from_cosine_scheduler_with_linear_warmup,\n",
      "                min_lr=min_lr,\n",
      "        else:\n",
      "            raise ValueError('The warmup_iters, lr_decay_iters and min_lr arguments do not match each other.')\n",
      "        self.train_metrics = self.checkpointer.init_metrics('train_metrics', train_metrics, train_ema_alpha)\n",
      "                    beta_1: float,\n",
      "                    weight_decay: float,\n",
      "        decay_params = [p for p in self.model.parameters() if p.dim() >= 2]\n",
      "        no_decay_params = [p for p in self.model.parameters() if p.dim() < 2]\n",
      "            {'params': decay_params, 'weight_decay': weight_decay},\n",
      "            {'params': no_decay_params, 'weight_decay': 0},\n",
      "            lr=learning_rate,\n",
      "        return optimizer\n",
      "    @torch.inference_mode\n",
      "    def validate(self, verbose: bool = True) -> dict[MetricName, MetricValue]:\n",
      "        training = self.model.training\n",
      "            iterable=self.valid_dl,\n",
      "            desc='Validation steps',\n",
      "            position=1,\n",
      "            leave=None,\n",
      "             loss_mask, completion_mask, category_ids,\n",
      "             ) = (t.to(self.model.device) for t in micro_batch.values())\n",
      "            loss_per_token = F.cross_entropy(\n",
      "                input=model_output.logits.flatten(0, 1),\n",
      "                target=target_ids.flatten(0, 1),\n",
      "                reduction='none',\n",
      "            ).view_as(target_ids)\n",
      "            locals_copy = locals().copy()\n",
      "        valid_log = {name: metric.batch_commit() for name, metric in self.valid_metrics.items()}\n",
      "        self.model.train(training)\n",
      "        return valid_log\n",
      "        self.model.train()\n",
      "            self.start_iter, self.max_iters,\n",
      "            desc='Optimization steps',\n",
      "            initial=self.start_iter,\n",
      "            position=0,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "            self.gradient_accumulation_steps,\n",
      "            position=1,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "            log = Log(iteration_number=0, valid_metrics=self.validate(verbose))\n",
      "            pbar_accumulation.reset()\n",
      "            for param_group in self.optimizer.param_groups:\n",
      "                param_group['lr'] = learning_rate\n",
      "            for _ in range(self.gradient_accumulation_steps):\n",
      "                 loss_mask, completion_mask, category_ids,\n",
      "                model_output = self.model(input_ids, attention_mask=input_attn_mask)\n",
      "                    target=target_ids.flatten(0, 1),\n",
      "                ).view_as(target_ids)\n",
      "                # not accurate if drop_last=False and micro_batch_size != 1\n",
      "                self.grad_scaler.scale(loss).backward()\n",
      "                del locals_copy\n",
      "                pbar_accumulation.update()\n",
      "            self.grad_scaler.update()\n",
      "            log = Log(\n",
      "                iteration_number=iter_num + 1,\n",
      "            )\n",
      "            if (iter_num + 1) % self.valid_freq == 0:\n",
      "                log['valid_metrics'] = self.validate(verbose)\n",
      "                self.checkpointer.save_checkpoint(Checkpoint(\n",
      "                    model=self.model,\n",
      "                ))\n",
      "from pipeline.outputs.metrics.metric_base import MetricName, MetricValue\n",
      "from abc import ABC, abstractmethod\n",
      "    @abstractmethod\n",
      "    @torch.inference_mode\n",
      "    def validate(self, *args, **kwargs) -> dict[MetricName, MetricValue]:\n",
      "        raise NotImplementedError\n",
      "    def train(self, *args, **kwargs) -> None:\n",
      "from pipeline.trainers.full_finetuning_trainer import FullFineTuningTrainer\n",
      "    'full_finetuning_trainer': FullFineTuningTrainer,\n",
      "import math\n",
      "from typing import Iterator\n",
      "import torch\n",
      "                 start_sample_idx: int,\n",
      "                 dataset_length: int,\n",
      "                 ) -> None:\n",
      "        self.start_sample_idx = start_sample_idx\n",
      "        self.end_sample_idx = end_sample_idx\n",
      "        self.dataset_length = dataset_length\n",
      "        self.max_epochs = math.ceil(end_sample_idx / dataset_length)\n",
      "        yield from fused_indices[self.start_sample_idx:self.end_sample_idx]\n",
      "    def __len__(self) -> int:\n",
      "                                                    max_lr: float,\n",
      "                                                    warmup_iters: int,\n",
      "                                                    ) -> float:\n",
      "    if iter_num < warmup_iters:  # warmup\n",
      "        return max_lr * (iter_num + 1) / warmup_iters\n",
      "    elif iter_num > lr_decay_iters:  # constant lr\n",
      "        return min_lr\n",
      "        return min_lr + (max_lr - min_lr) / 2 * (1 + math.cos(math.pi * decay_ratio))\n",
      "  - logger: wandb/wandb\n",
      "  - model: dseek1p3\n",
      "  - preprocessor: completion_loss_preprocessor/full_completion_loss_16k\n",
      "  - trainer: full_finetuning_trainer/medium_lr\n",
      "  - override hydra/job_logging: disabled\n",
      "hydra:\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "padding: True\n",
      "context_tokens: 8192\n",
      "loss_ratio: 0.9\n",
      "num_chars_per_token: 6\n",
      "padding: True\n",
      "padding: True\n",
      "context_tokens: 8192\n",
      "num_chars_per_token: 6\n",
      "max_seq_len: 16384\n",
      "context_tokens: 8192\n",
      "loss_ratio: 1\n",
      "num_chars_per_token: 6\n",
      "max_iters: 600\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "# AdamW optimizer\n",
      "beta_2: 0.999\n",
      "# Cosine lr scheduler with warmup\n",
      "lr_decay_iters: 600\n",
      "min_lr: 1.0e-7\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "# DataLoader\n",
      "micro_batch_size: 1\n",
      "# AdamW optimizer\n",
      "weight_decay: 0.01\n",
      "# Cosine lr scheduler with warmup\n",
      "warmup_iters: 50\n",
      "# Metrics\n",
      "train_metrics: [\n",
      "  cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  epoch,\n",
      "train_ema_alpha: 0.01\n",
      "  detached_cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  epoch,\n",
      "]\n",
      "valid_ema_alpha: null\n",
      "drop_last: False\n",
      "prefetch_factor: 8\n",
      "random_seed: 1337\n",
      "# Floating point\n",
      "# Iteration parameters\n",
      "checkpointing_freq: 25\n",
      "gradient_accumulation_steps: 64\n",
      "micro_batch_size: 1\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "beta_2: 0.999\n",
      "weight_decay: 0.01\n",
      "max_grad_norm: 2\n",
      "warmup_iters: 50\n",
      "lr_decay_iters: 600\n",
      "# Metrics\n",
      "  cross_entropy,\n",
      "  detached_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  inproject_cross_entropy,\n",
      "  non_informative_cross_entropy,\n",
      "  random_cross_entropy,\n",
      "  epoch,\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "shuffle: True\n",
      "prefetch_factor: 8\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "# Iteration parameters\n",
      "valid_freq: 5\n",
      "# AdamW optimizer\n",
      "learning_rate: 3.5e-5\n",
      "max_grad_norm: 2\n",
      "lr_decay_iters: 600\n",
      "# Metrics\n",
      "  cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  common_cross_entropy,\n",
      "  epoch,\n",
      "  learning_rate,\n",
      "]\n",
      "train_ema_alpha: 0.01\n",
      "valid_metrics: [\n",
      "  cross_entropy,\n",
      "  completion_cross_entropy,\n",
      "  context_cross_entropy,\n",
      "  full_cross_entropy,\n",
      "  commited_cross_entropy,\n",
      "  infile_cross_entropy,\n",
      "valid_ema_alpha: null\n",
      "# DataLoader\n",
      "random_seed: 1337\n",
      "# Floating point\n",
      "fp32_matmul_precision: high\n",
      "pre_context_prompt: ''\n",
      "post_context_prompt: ''\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "block_configs: [\n",
      "  file_filtering/file_length_filter/0_20k.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  context_postprocessing/line_length_postprocessor/10_200.yaml,\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_chunking/code_segment_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "  file_filtering/inclusive_file_extension_filter/python_files.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "block_configs: [\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_filtering/char_token_ratio_filter/1p5_inf.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "]\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "recalculate_random_category: True\n",
      "  chunk_ranking/function_call_ranker/relative.yaml,\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_ranking/function_call_ranker/absolute.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "  file_filtering/empty_file_filter/no_args.yaml,\n",
      "  file_preprocessing/declaration_only_preprocessor/no_args.yaml,\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "block_configs: [\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "  context_postprocessing/partial_memory_postprocessor/half_memory.yaml,\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "block_configs: [\n",
      "  chunk_ranking/negative_path_distance_ranker/no_args.yaml,\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "path_comment_template: \"# {filename}\\n{content}\"\n",
      "recalculate_random_category: True\n",
      "  chunk_sorting/lexicographic_sorter/no_args.yaml,\n",
      "]\n",
      "pre_context_prompt: \"# {}\\n\"\n",
      "post_context_prompt: \"\\n\\n\"\n",
      "  file_chunking/file_grained_chunker/no_args.yaml,\n",
      "  chunk_harvesting/path_comment_harvester/standard.yaml,\n",
      "\n",
      "\n",
      "\n",
      "chunks_sep: \"\\n\\n\"\n",
      "chunks_sep: \"\\n\\n\"\n",
      "\n",
      "\n",
      "\n",
      "min_len: 10\n",
      "\n",
      "is_relative: False\n",
      "random_seed: 1337\n",
      "\n",
      "min_len: 0\n",
      "max_len: !!float .inf\n",
      "whitelist: [.py]\n",
      "min_ratio: 3\n",
      "max_ratio: 6\n",
      "min_ratio: 1.5\n",
      "subsequence_len: 2048\n",
      "random_seed: 1337\n",
      "blacklist: []\n",
      "trust_remote_code: True\n",
      "compile: False\n",
      "init_from: resume\n",
      "main_metric: cross_entropy\n",
      "max_checkpoints_num: 3\n",
      "init_from: resume\n",
      "main_metric: cross_entropy\n",
      "name: small_context\n",
      "split: test\n",
      "name: huge_context\n",
      "split: test\n",
      "path: JetBrains-Research/lca-codegen-train\n",
      "data_dir: train\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "name: large_context\n",
      "split: test\n",
      "path: JetBrains-Research/lca-project-level-code-completion\n",
      "split: test\n",
      "valid_csv: valid.csv\n",
      "stdout_file: stdout.json\n",
      "train_csv: train.csv\n",
      "stdout_file: stdout.json\n",
      "stderr_file: stderr.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116a9a0-6a86-42a0-b679-7dbf59d164c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9e95f6-6b97-490b-bc58-8b52829b063a",
   "metadata": {},
   "source": [
    "# Base Composer\n",
    "\n",
    "In general, a composer constructs a new _composed_ data point from the raw one. For this purpuse, it devides the data into four main parts:\n",
    "\n",
    "1. Leading prompt, `get_pre_context_prompt` method.\n",
    "2. Composed context, `compose_context` method.\n",
    "3. Prompt following context, `get_post_context_prompt` method.\n",
    "4. Composed completion, `compose_completion` method.\n",
    "\n",
    "In the simplest case, the leading prompt could be an empty string or the repository identifier, and the post-context prompt could be just a separator between the two main parts  context and completion. Now, let's focus on how we can compose context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b0459-5eb2-4816-b5dc-69829cfa4a1f",
   "metadata": {},
   "source": [
    "# Chained Composer\n",
    "\n",
    "A more general approach is to inherit from `ComposerBase` class and implement the corresponding method. It is a quick but not scalable solution in terms of efficient search space exploration. That's why we propose a more robust way of defining the composition pipeline  a chain of individual blocks.\n",
    "\n",
    "Types of such blocks:\n",
    "\n",
    "1. `FileFilter`, **file_filtering** module.\n",
    "2. `FilePreprocessor`, **file_preprocessing** module.\n",
    "3. `FileChunker`, **file_chunking** module.\n",
    "4. `ChunkRanker`, **chunk_ranking** module.\n",
    "5. `ChunkSorter`, **chunk_sorting** module.\n",
    "6. `ChunkHarvester`, **chunk_harvesting** module.\n",
    "7. `ContextPostprocessor`, **context_postprocessing** module.\n",
    "\n",
    "See below for more details.\n",
    "\n",
    "The next graph illustrates:\n",
    "\n",
    "- The available order of blocks,\n",
    "- How optional their use is (the red part indicates optionality),\n",
    "- Data structure transitions: **Files -> Chunks -> Context** (blue vertical lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b29a325aef36cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=2125x955>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.open('../extra/attachments/chained_composer.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159fef0-ab5e-4982-b1f3-464ecf2f5c00",
   "metadata": {},
   "source": [
    "## file_filtering\n",
    "\n",
    "**Abstract class**: `FileFilter`. \\\n",
    "**Purpose**: Filter out unwanted files. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `InclusiveFileExtensionFilter` for selecting files by their extensions,\n",
    "- `ExclusiveFileExtensionFilter` for removing files by their extensions,\n",
    "- `EmptyFileFilter` for removing empty files,\n",
    "- `FileLengthFilter` for removing files that are too short or long (at the character level),\n",
    "- `TokenizedFileLengthFilter` for removing files that are too short or long (at the token level),\n",
    "- `CharTokenRatioFilter` for removing files with a low or high character-to-token ratio.\n",
    "\n",
    "## file_preprocessing\n",
    "\n",
    "**Abstract class**: `FilePreprocessor`. \\\n",
    "**Purpose**: File-level content modification. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `EmptyLinesRemovalPreprocessor` for removing empty lines,\n",
    "- `DeclarationOnlyPreprocessor` for extracting function and class declarations.\n",
    "\n",
    "## file_chunking\n",
    "\n",
    "**Abstract class**: `FileChunker`. \\\n",
    "**Purpose**: Convert a set of files into chunks, change granularity. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `FileGrainedChunker` for assining a one-to-one relationship (can be understood as _no chunking_),\n",
    "- `CodeSegmentGrainedChunker` for splitting one Python file into four blocks: imports, docstrings, 3 lines comments, and code.\n",
    "\n",
    "## chunk_ranking\n",
    "\n",
    "**Abstract class**: `ChunkRanker`. \\\n",
    "**Purpose**: Determine the importance of a chunk. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `NegativePathDistanceRanker` based on the same idea as presented in the LCA paper,\n",
    "- `FileExtensionRanker` for prioritizing some extensions over others,\n",
    "- `FunctionCallRanker` for prioritizing chunks with a higher number of function calls,\n",
    "- `RandomRanker` for shuffling chunks.\n",
    "\n",
    "## chunk_sorting\n",
    "\n",
    "**Abstract class**: `ChunkSorter`. \\\n",
    "**Purpose**: Sort a set of chunks based on their ranks. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `LexicographicSorter` preserves rankers order.\n",
    "\n",
    "## chunk_harvesting\n",
    "\n",
    "**Abstract class**: `ChunkHarvester`. \\\n",
    "**Purpose**: Join sorted chunks. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `JoiningHarvester` uses the provided string as a separator,\n",
    "- `PathCommentHarvester` adds information about the file's position in the project.\n",
    "\n",
    "## context_postprocessing\n",
    "\n",
    "**Abstract class**: `ContextPostprocessor`. \\\n",
    "**Purpose**: Context-level content modification. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `PartialMemoryPostprocessor` for dropping some lines with a given probability,\n",
    "- `LineLengthPostprocessor` for removing lines that are too short or long,\n",
    "- `LineStripPostprocessor` for stripping lines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
